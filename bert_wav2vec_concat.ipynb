{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda\n",
    "# cuda.select_device(2)\n",
    "# # cuda.close()\n",
    "# import torch \n",
    "# torch.cuda.is_available()\n",
    "# torch.cuda.device_count()\n",
    "# import torch\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(60000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [10,20,30]\n",
    "num_classes = len(splits)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henrw/anaconda3/envs/misinfo-engage/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - T001: 0.00015926361083984375 seconds.\n",
      "1 - T003: 0.000850677490234375 seconds.\n",
      "2 - T004: 8.7738037109375e-05 seconds.\n",
      "3 - T006: 9.608268737792969e-05 seconds.\n",
      "4 - T007: 8.940696716308594e-05 seconds.\n",
      "5 - T009: 8.392333984375e-05 seconds.\n",
      "6 - T011: 8.106231689453125e-05 seconds.\n",
      "7 - T013: 0.00010180473327636719 seconds.\n",
      "8 - T015: 0.0001232624053955078 seconds.\n",
      "9 - T016: 8.654594421386719e-05 seconds.\n",
      "10 - T017: 0.00010228157043457031 seconds.\n",
      "11 - T018: 9.34600830078125e-05 seconds.\n",
      "12 - T020: 8.368492126464844e-05 seconds.\n",
      "13 - T021: 7.987022399902344e-05 seconds.\n",
      "14 - T022: 7.224082946777344e-05 seconds.\n",
      "15 - T023: 7.700920104980469e-05 seconds.\n",
      "16 - T024: 7.2479248046875e-05 seconds.\n",
      "17 - T027: 7.081031799316406e-05 seconds.\n",
      "18 - T028: 6.413459777832031e-05 seconds.\n",
      "19 - T031: 6.246566772460938e-05 seconds.\n",
      "20 - T033: 6.270408630371094e-05 seconds.\n",
      "21 - T034: 7.653236389160156e-05 seconds.\n",
      "22 - T035: 6.628036499023438e-05 seconds.\n",
      "23 - T036: 7.414817810058594e-05 seconds.\n",
      "24 - T037: 6.604194641113281e-05 seconds.\n",
      "25 - T038: 6.270408630371094e-05 seconds.\n",
      "26 - T039: 6.341934204101562e-05 seconds.\n",
      "27 - T040: 6.29425048828125e-05 seconds.\n",
      "28 - T041: 6.318092346191406e-05 seconds.\n",
      "29 - T042: 0.000102996826171875 seconds.\n",
      "30 - T043: 8.106231689453125e-05 seconds.\n",
      "31 - T044: 7.939338684082031e-05 seconds.\n",
      "32 - T045: 8.916854858398438e-05 seconds.\n",
      "33 - T046: 7.653236389160156e-05 seconds.\n",
      "34 - T047: 7.939338684082031e-05 seconds.\n",
      "35 - T049: 7.939338684082031e-05 seconds.\n",
      "36 - T050: 7.987022399902344e-05 seconds.\n",
      "37 - T051: 7.987022399902344e-05 seconds.\n",
      "38 - T052: 7.796287536621094e-05 seconds.\n",
      "39 - T053: 7.867813110351562e-05 seconds.\n",
      "40 - T055: 8.106231689453125e-05 seconds.\n",
      "41 - T056: 7.677078247070312e-05 seconds.\n",
      "42 - T060: 8.559226989746094e-05 seconds.\n",
      "43 - T061: 6.198883056640625e-05 seconds.\n",
      "44 - T062: 6.699562072753906e-05 seconds.\n",
      "45 - T063: 6.4849853515625e-05 seconds.\n",
      "46 - T064: 6.461143493652344e-05 seconds.\n",
      "47 - T065: 6.556510925292969e-05 seconds.\n",
      "48 - T067: 6.651878356933594e-05 seconds.\n",
      "49 - T069: 6.961822509765625e-05 seconds.\n",
      "50 - T070: 6.67572021484375e-05 seconds.\n",
      "51 - T072: 6.318092346191406e-05 seconds.\n",
      "52 - T073: 6.532669067382812e-05 seconds.\n",
      "53 - T074: 6.246566772460938e-05 seconds.\n",
      "54 - T075: 6.318092346191406e-05 seconds.\n",
      "55 - T077: 7.772445678710938e-05 seconds.\n",
      "56 - S001: 9.512901306152344e-05 seconds.\n",
      "57 - S002: 9.369850158691406e-05 seconds.\n",
      "58 - S003: 7.867813110351562e-05 seconds.\n",
      "59 - S004: 9.202957153320312e-05 seconds.\n",
      "60 - S005: 8.058547973632812e-05 seconds.\n",
      "61 - S006: 8.153915405273438e-05 seconds.\n",
      "62 - S007: 7.939338684082031e-05 seconds.\n",
      "63 - S009: 8.606910705566406e-05 seconds.\n",
      "64 - S010: 6.318092346191406e-05 seconds.\n",
      "65 - S013: 6.508827209472656e-05 seconds.\n",
      "66 - S014: 7.033348083496094e-05 seconds.\n",
      "67 - S016: 7.43865966796875e-05 seconds.\n",
      "68 - S017: 6.389617919921875e-05 seconds.\n",
      "69 - S018: 6.246566772460938e-05 seconds.\n",
      "70 - S019: 6.4849853515625e-05 seconds.\n",
      "71 - S020: 7.605552673339844e-05 seconds.\n",
      "72 - S021: 6.67572021484375e-05 seconds.\n",
      "73 - S022: 6.151199340820312e-05 seconds.\n",
      "74 - S023: 8.58306884765625e-05 seconds.\n",
      "75 - S024: 7.62939453125e-05 seconds.\n",
      "76 - S025: 8.106231689453125e-05 seconds.\n",
      "77 - S026: 7.677078247070312e-05 seconds.\n",
      "78 - S027: 9.703636169433594e-05 seconds.\n",
      "79 - S028: 7.605552673339844e-05 seconds.\n",
      "80 - S029: 9.131431579589844e-05 seconds.\n",
      "81 - S030: 0.00010204315185546875 seconds.\n",
      "82 - S034: 8.392333984375e-05 seconds.\n",
      "83 - S035: 7.390975952148438e-05 seconds.\n",
      "84 - S036: 6.318092346191406e-05 seconds.\n",
      "85 - S038: 6.532669067382812e-05 seconds.\n",
      "86 - S039: 6.389617919921875e-05 seconds.\n",
      "87 - S043: 7.271766662597656e-05 seconds.\n",
      "88 - S044: 6.651878356933594e-05 seconds.\n",
      "89 - S047: 6.29425048828125e-05 seconds.\n",
      "90 - S048: 5.984306335449219e-05 seconds.\n",
      "91 - S049: 7.009506225585938e-05 seconds.\n",
      "92 - S050: 7.843971252441406e-05 seconds.\n",
      "93 - S051: 6.151199340820312e-05 seconds.\n",
      "94 - S052: 6.365776062011719e-05 seconds.\n",
      "95 - S055: 6.794929504394531e-05 seconds.\n",
      "96 - S057: 6.699562072753906e-05 seconds.\n",
      "97 - S058: 7.033348083496094e-05 seconds.\n",
      "98 - S059: 7.700920104980469e-05 seconds.\n",
      "99 - S061: 7.05718994140625e-05 seconds.\n",
      "100 - S064: 6.461143493652344e-05 seconds.\n",
      "101 - S065: 6.937980651855469e-05 seconds.\n",
      "102 - S067: 7.319450378417969e-05 seconds.\n",
      "103 - S069: 6.914138793945312e-05 seconds.\n",
      "104 - S071: 0.0001227855682373047 seconds.\n",
      "105 - S072: 8.0108642578125e-05 seconds.\n",
      "106 - S073: 8.940696716308594e-05 seconds.\n",
      "107 - S074: 7.653236389160156e-05 seconds.\n",
      "108 - S076: 0.00010037422180175781 seconds.\n",
      "109 - MI0002: 9.131431579589844e-05 seconds.\n",
      "110 - MI0003: 8.58306884765625e-05 seconds.\n",
      "111 - MI0004: 7.891654968261719e-05 seconds.\n",
      "112 - MI0021: 8.893013000488281e-05 seconds.\n",
      "113 - MI0022: 8.0108642578125e-05 seconds.\n",
      "114 - MI0023: 8.726119995117188e-05 seconds.\n",
      "115 - MI0024: 9.584426879882812e-05 seconds.\n",
      "116 - MI0025: 7.081031799316406e-05 seconds.\n",
      "117 - MI0026: 6.151199340820312e-05 seconds.\n",
      "118 - MI0027: 6.270408630371094e-05 seconds.\n",
      "119 - MI0028: 6.866455078125e-05 seconds.\n",
      "120 - MI0029: 7.62939453125e-05 seconds.\n",
      "121 - MI0030: 7.557868957519531e-05 seconds.\n",
      "122 - MI0031: 7.176399230957031e-05 seconds.\n",
      "123 - MI0034: 6.413459777832031e-05 seconds.\n",
      "124 - MI0035: 7.200241088867188e-05 seconds.\n",
      "125 - MI0036: 6.246566772460938e-05 seconds.\n",
      "126 - MI0037: 5.9604644775390625e-05 seconds.\n",
      "127 - MI0038: 6.008148193359375e-05 seconds.\n",
      "128 - MI0039: 8.034706115722656e-05 seconds.\n",
      "129 - MI0040: 6.937980651855469e-05 seconds.\n",
      "130 - MI0041: 6.961822509765625e-05 seconds.\n",
      "131 - MI0042: 5.936622619628906e-05 seconds.\n",
      "132 - MI0043: 7.534027099609375e-05 seconds.\n",
      "133 - MI0046: 6.961822509765625e-05 seconds.\n",
      "134 - MI0047: 6.771087646484375e-05 seconds.\n",
      "135 - MI0048: 6.67572021484375e-05 seconds.\n",
      "136 - MI0049: 7.176399230957031e-05 seconds.\n",
      "137 - MI0050: 6.222724914550781e-05 seconds.\n",
      "138 - MI0051: 7.200241088867188e-05 seconds.\n",
      "139 - MI0052: 6.079673767089844e-05 seconds.\n",
      "140 - MI0053: 6.127357482910156e-05 seconds.\n",
      "141 - MI0054: 6.461143493652344e-05 seconds.\n",
      "142 - MI0057: 6.628036499023438e-05 seconds.\n",
      "143 - MI0058: 6.079673767089844e-05 seconds.\n",
      "144 - MI0059: 6.0558319091796875e-05 seconds.\n",
      "145 - MI0060: 5.936622619628906e-05 seconds.\n",
      "146 - MI0061: 0.00010180473327636719 seconds.\n",
      "147 - MI0062: 9.584426879882812e-05 seconds.\n",
      "148 - MI0064: 9.1552734375e-05 seconds.\n",
      "149 - MI0066: 7.43865966796875e-05 seconds.\n",
      "150 - MI0067: 7.581710815429688e-05 seconds.\n",
      "151 - MI0068: 8.153915405273438e-05 seconds.\n",
      "152 - MI0069: 8.797645568847656e-05 seconds.\n",
      "153 - MI0070: 5.984306335449219e-05 seconds.\n",
      "154 - MI0071: 7.605552673339844e-05 seconds.\n",
      "155 - MI0072: 6.008148193359375e-05 seconds.\n",
      "156 - MI0073: 7.2479248046875e-05 seconds.\n",
      "157 - MI0074: 6.890296936035156e-05 seconds.\n",
      "158 - MI0075: 7.462501525878906e-05 seconds.\n",
      "159 - MI0077: 5.91278076171875e-05 seconds.\n",
      "160 - MI0078: 6.651878356933594e-05 seconds.\n",
      "161 - MI0079: 6.771087646484375e-05 seconds.\n",
      "162 - MI0080: 6.175041198730469e-05 seconds.\n",
      "163 - MI0081: 7.081031799316406e-05 seconds.\n",
      "164 - MI0082: 7.033348083496094e-05 seconds.\n",
      "165 - MI0083: 8.869171142578125e-05 seconds.\n",
      "166 - MI0084: 7.605552673339844e-05 seconds.\n",
      "167 - MI0085: 8.916854858398438e-05 seconds.\n",
      "168 - MI0086: 7.62939453125e-05 seconds.\n",
      "169 - MI0087: 7.796287536621094e-05 seconds.\n",
      "170 - MI0088: 7.843971252441406e-05 seconds.\n",
      "171 - MI0089: 8.320808410644531e-05 seconds.\n",
      "172 - MI0090: 6.842613220214844e-05 seconds.\n",
      "173 - MI0092: 7.367134094238281e-05 seconds.\n",
      "174 - MI0093: 6.747245788574219e-05 seconds.\n",
      "175 - MI0095: 7.390975952148438e-05 seconds.\n",
      "176 - MI0096: 7.152557373046875e-05 seconds.\n",
      "177 - MI0097: 6.961822509765625e-05 seconds.\n",
      "178 - MI0098: 6.723403930664062e-05 seconds.\n",
      "179 - MI0099: 6.67572021484375e-05 seconds.\n",
      "180 - MI0101: 7.200241088867188e-05 seconds.\n",
      "181 - MI0102: 6.651878356933594e-05 seconds.\n",
      "182 - MI0104: 6.747245788574219e-05 seconds.\n",
      "183 - MI0105: 6.604194641113281e-05 seconds.\n",
      "184 - MI0106: 7.915496826171875e-05 seconds.\n",
      "185 - MI0107: 7.653236389160156e-05 seconds.\n",
      "186 - MI0109: 9.655952453613281e-05 seconds.\n",
      "187 - MI0110: 8.463859558105469e-05 seconds.\n",
      "188 - MI0111: 8.7738037109375e-05 seconds.\n",
      "189 - MI0112: 8.440017700195312e-05 seconds.\n",
      "190 - MI0113: 7.462501525878906e-05 seconds.\n",
      "191 - MI0114: 8.368492126464844e-05 seconds.\n",
      "192 - MI0117: 6.437301635742188e-05 seconds.\n",
      "193 - MI0118: 6.103515625e-05 seconds.\n",
      "194 - MI0119: 6.079673767089844e-05 seconds.\n",
      "195 - MI0120: 7.128715515136719e-05 seconds.\n",
      "196 - MI0121: 0.00010895729064941406 seconds.\n",
      "197 - MI0122: 9.322166442871094e-05 seconds.\n",
      "198 - MI0123: 7.653236389160156e-05 seconds.\n",
      "199 - MI0124: 7.319450378417969e-05 seconds.\n",
      "200 - MI0125: 8.678436279296875e-05 seconds.\n",
      "201 - MI0127: 7.700920104980469e-05 seconds.\n",
      "202 - MI0128: 8.630752563476562e-05 seconds.\n",
      "203 - MI0129: 7.104873657226562e-05 seconds.\n",
      "204 - MI0130: 6.580352783203125e-05 seconds.\n",
      "205 - MI0132: 6.175041198730469e-05 seconds.\n",
      "206 - MI0133: 7.62939453125e-05 seconds.\n",
      "207 - MI0134: 5.841255187988281e-05 seconds.\n",
      "208 - MI0135: 7.581710815429688e-05 seconds.\n",
      "209 - MI0136: 6.0558319091796875e-05 seconds.\n",
      "210 - MI0138: 6.079673767089844e-05 seconds.\n"
     ]
    }
   ],
   "source": [
    "from dataset import YouTubeDataset\n",
    "dataset = YouTubeDataset(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from models.multi_modality_classifiers import RobertaWav2VecClassifier\n",
    "from torch import nn\n",
    "model = RobertaWav2VecClassifier(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.audio = dataset.audio.to(device)\n",
    "dataset.tokens = dataset.tokens.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from inference import eval_text_audio, get_scores\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def train_model(model, dataset, learning_rate, lr_decay, weight_decay, batch_size, num_epochs, device, isCheckpoint=False, train_val_split = None, isVerbose=True):\n",
    "    loss_history = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer, lambda epoch: lr_decay ** epoch\n",
    "    )\n",
    "\n",
    "    # sample minibatch data\n",
    "    if not train_val_split:\n",
    "      train_ids = [i for i in range(len(dataset))]\n",
    "      val_ids = None\n",
    "    else:\n",
    "      train_ids, val_ids = train_val_split\n",
    "\n",
    "    iter_per_epoch = math.ceil(len(train_ids) // batch_size)\n",
    "    class_weights = torch.tensor(compute_class_weight(class_weight='balanced', classes=np.arange(model.num_classes), y=dataset.label[train_ids].numpy()), dtype=torch.float, device='cuda:3')\n",
    "    loss_fn = torch.nn.NLLLoss(weight = class_weights)\n",
    "    # loss_fn = cross_entropy\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        start_t = time.time()\n",
    "        local_hist = []\n",
    "        correct_cnt = 0\n",
    "        y_preds = torch.empty((0,),device='cpu')\n",
    "        y_trues = torch.empty((0,),device='cuda:3')\n",
    "        for j in range(iter_per_epoch):\n",
    "            tokens, waveforms, y_true = dataset[train_ids[j * batch_size: (j + 1) * batch_size]]\n",
    "            y_true = y_true.to('cuda:3')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            digits = model(tokens, waveforms)\n",
    "            y_preds = torch.hstack([y_preds,digits.argmax(dim=1).to('cpu')])\n",
    "            y_trues = torch.hstack([y_trues,y_true])\n",
    "\n",
    "            probs = torch.nn.LogSoftmax(dim=1)(digits)\n",
    "            loss = loss_fn(probs,y_true)\n",
    "            loss.backward()\n",
    "\n",
    "            local_hist.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "        end_t = time.time()\n",
    "\n",
    "        loss_mean = np.array(local_hist).mean()\n",
    "        loss_history.append(loss_mean)\n",
    "            \n",
    "        print(\n",
    "            f\"(Epoch {i}), time: {end_t - start_t:.1f}s, loss: {loss_mean:.3f}\"\n",
    "        )\n",
    "        if isVerbose:\n",
    "            train_accuracy, train_precision, train_recall, train_f1 = get_scores(y_trues.to('cpu'), y_preds, model.num_classes) # This is an aggregated result due to GPU size limit\n",
    "            print(f\"    Training Set - accuracy: {train_accuracy:.2f}, precision: {train_precision:.2f}, recall: {train_recall:.2f}, f1-score: {train_f1:.2f},\")\n",
    "            if val_ids is not None:\n",
    "                val_accuracy, val_precision, val_recall, val_f1 = eval_text_audio(model, dataset, val_ids, num_classes, device, is_verbose = (loss_mean < 0.5))\n",
    "                print(f\"    Validation Set - accuracy: {val_accuracy:.2f}, precision: {val_precision:.2f}, recall: {val_recall:.2f}, f1-score: {val_f1:.2f},\")\n",
    "        if i%200 == 0 and isCheckpoint:\n",
    "          dir = \"checkpoints\"\n",
    "          if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "          file = f\"epoch{i}.pt\"\n",
    "          path = dir+'/'+file\n",
    "          torch.save({\n",
    "                      'epoch': i,\n",
    "                      'model_state_dict': model.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict(),\n",
    "                      'loss': loss_mean,\n",
    "                      }, path)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        if loss_mean < 0.4:\n",
    "          break\n",
    "    \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "\n",
    "def train_model_cv5(model, dataset):\n",
    "    loss_hist = []\n",
    "    kf = KFold(n_splits=5)\n",
    "    cnt = 1\n",
    "    for train_index, val_index in kf.split(dataset):\n",
    "        model.reset()\n",
    "        model.to('cuda:3')\n",
    "        model.base_wav2vec = torch.nn.DataParallel(model.base_wav2vec)\n",
    "        model.base_wav2vec.to('cuda')\n",
    "        model.base_bert.requires_grad = False\n",
    "        model.base_wav2vec.requires_grad = False\n",
    "        print(\"Fold \"+str(cnt)+\" (val\", val_index[0],\"-\",str(val_index[-1])+\")\")\n",
    "        loss_hist_fold = train_model(model, device = device, dataset=dataset, train_val_split=(train_index, val_index),learning_rate=3e-6, lr_decay=0.99, weight_decay=1e-4, batch_size=5, num_epochs=500, isCheckpoint = False, isVerbose = True)\n",
    "        loss_hist.append(loss_hist_fold)\n",
    "        cnt += 1\n",
    "    return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (val 0 - 42)\n",
      "(Epoch 0), time: 22.4s, loss: 1.409\n",
      "    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n",
      "    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n",
      "(Epoch 1), time: 13.9s, loss: 1.402\n",
      "    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n",
      "    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n",
      "(Epoch 2), time: 13.9s, loss: 1.392\n",
      "    Training Set - accuracy: 0.10, precision: 0.12, recall: 0.28, f1-score: 0.07,\n",
      "    Validation Set - accuracy: 0.12, precision: 0.30, recall: 0.41, f1-score: 0.10,\n",
      "(Epoch 3), time: 13.8s, loss: 1.382\n",
      "    Training Set - accuracy: 0.32, precision: 0.19, recall: 0.25, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.15, precision: 0.28, recall: 0.26, f1-score: 0.07,\n",
      "(Epoch 4), time: 14.0s, loss: 1.363\n",
      "    Training Set - accuracy: 0.45, precision: 0.23, recall: 0.28, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.25, recall: 0.26, f1-score: 0.15,\n",
      "(Epoch 5), time: 14.0s, loss: 1.343\n",
      "    Training Set - accuracy: 0.46, precision: 0.22, recall: 0.26, f1-score: 0.23,\n",
      "    Validation Set - accuracy: 0.65, precision: 0.26, recall: 0.28, f1-score: 0.26,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m lost_hist_folds \u001b[39m=\u001b[39m train_model_cv5(model, dataset)\n",
      "\u001b[1;32m/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_model_cv5\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mbase_wav2vec\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFold \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(cnt)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (val\u001b[39m\u001b[39m\"\u001b[39m, val_index[\u001b[39m0\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mstr\u001b[39m(val_index[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m loss_hist_fold \u001b[39m=\u001b[39m train_model(model, device \u001b[39m=\u001b[39;49m device, dataset\u001b[39m=\u001b[39;49mdataset, train_val_split\u001b[39m=\u001b[39;49m(train_index, val_index),learning_rate\u001b[39m=\u001b[39;49m\u001b[39m3e-6\u001b[39;49m, lr_decay\u001b[39m=\u001b[39;49m\u001b[39m0.99\u001b[39;49m, weight_decay\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, isCheckpoint \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, isVerbose \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m loss_hist\u001b[39m.\u001b[39mappend(loss_hist_fold)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m cnt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, learning_rate, lr_decay, weight_decay, batch_size, num_epochs, device, isCheckpoint, train_val_split, isVerbose)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda:3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m digits \u001b[39m=\u001b[39m model(tokens, waveforms)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m y_preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack([y_preds,digits\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blit1000.eecs.umich.edu/home/henrw/Misinfo-Engagement/bert_wav2vec_concat.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m y_trues \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack([y_trues,y_true])\n",
      "File \u001b[0;32m~/anaconda3/envs/misinfo-engage/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Misinfo-Engagement/models/multi_modality_classifiers.py:37\u001b[0m, in \u001b[0;36mRobertaWav2VecClassifier.forward\u001b[0;34m(self, token, audio)\u001b[0m\n\u001b[1;32m     35\u001b[0m output_bert \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_bert(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtoken)\n\u001b[1;32m     36\u001b[0m \u001b[39m# print(\"2\",waveform.shape)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m output_wav2vec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_wav2vec(audio)\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda:3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[39m# print(output_bert['pooler_output'].shape)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m# print(output_wav2vec.shape)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# if output_wav2vec.shape[0] != 5:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m#     return None\u001b[39;00m\n\u001b[1;32m     42\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([output_bert[\u001b[39m'\u001b[39m\u001b[39mpooler_output\u001b[39m\u001b[39m'\u001b[39m], output_wav2vec],dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/misinfo-engage/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/misinfo-engage/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/misinfo-engage/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/anaconda3/envs/misinfo-engage/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:78\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m         thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     77\u001b[0m     \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[0;32m---> 78\u001b[0m         thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     _worker(\u001b[39m0\u001b[39m, modules[\u001b[39m0\u001b[39m], inputs[\u001b[39m0\u001b[39m], kwargs_tup[\u001b[39m0\u001b[39m], devices[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/misinfo-engage/lib/python3.10/threading.py:1089\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1088\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1090\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1091\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/misinfo-engage/lib/python3.10/threading.py:1109\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1110\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1111\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lost_hist_folds = train_model_cv5(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - T001: 0.00019621849060058594 seconds.\n",
      "1 - T003: 0.0009250640869140625 seconds.\n",
      "2 - T004: 0.00012254714965820312 seconds.\n",
      "3 - T006: 9.393692016601562e-05 seconds.\n",
      "4 - T007: 9.489059448242188e-05 seconds.\n",
      "5 - T009: 9.036064147949219e-05 seconds.\n",
      "6 - T011: 8.821487426757812e-05 seconds.\n",
      "7 - T013: 8.153915405273438e-05 seconds.\n",
      "8 - T015: 9.34600830078125e-05 seconds.\n",
      "9 - T016: 8.535385131835938e-05 seconds.\n",
      "10 - T017: 0.00010347366333007812 seconds.\n",
      "11 - T018: 9.918212890625e-05 seconds.\n",
      "12 - T020: 8.678436279296875e-05 seconds.\n",
      "13 - T021: 8.559226989746094e-05 seconds.\n",
      "14 - T022: 9.322166442871094e-05 seconds.\n",
      "15 - T023: 0.00010395050048828125 seconds.\n",
      "16 - T024: 9.560585021972656e-05 seconds.\n",
      "17 - T027: 9.608268737792969e-05 seconds.\n",
      "18 - T028: 8.416175842285156e-05 seconds.\n",
      "19 - T031: 8.630752563476562e-05 seconds.\n",
      "20 - T033: 8.559226989746094e-05 seconds.\n",
      "21 - T034: 0.00010538101196289062 seconds.\n",
      "22 - T035: 8.749961853027344e-05 seconds.\n",
      "23 - T036: 0.00010228157043457031 seconds.\n",
      "24 - T037: 8.821487426757812e-05 seconds.\n",
      "25 - T038: 8.130073547363281e-05 seconds.\n",
      "26 - T039: 8.487701416015625e-05 seconds.\n",
      "27 - T040: 8.344650268554688e-05 seconds.\n",
      "28 - T041: 8.368492126464844e-05 seconds.\n",
      "29 - T042: 8.177757263183594e-05 seconds.\n",
      "30 - T043: 8.511543273925781e-05 seconds.\n",
      "31 - T044: 8.749961853027344e-05 seconds.\n",
      "32 - T045: 8.749961853027344e-05 seconds.\n",
      "33 - T046: 8.273124694824219e-05 seconds.\n",
      "34 - T047: 8.320808410644531e-05 seconds.\n",
      "35 - T049: 8.320808410644531e-05 seconds.\n",
      "36 - T050: 8.296966552734375e-05 seconds.\n",
      "37 - T051: 8.678436279296875e-05 seconds.\n",
      "38 - T052: 8.511543273925781e-05 seconds.\n",
      "39 - T053: 8.654594421386719e-05 seconds.\n",
      "40 - T055: 8.916854858398438e-05 seconds.\n",
      "41 - T056: 8.130073547363281e-05 seconds.\n",
      "42 - T060: 8.821487426757812e-05 seconds.\n",
      "43 - T061: 8.296966552734375e-05 seconds.\n",
      "44 - T062: 8.654594421386719e-05 seconds.\n",
      "45 - T063: 8.96453857421875e-05 seconds.\n",
      "46 - T064: 9.393692016601562e-05 seconds.\n",
      "47 - T065: 9.72747802734375e-05 seconds.\n",
      "48 - T067: 8.511543273925781e-05 seconds.\n",
      "49 - T069: 9.274482727050781e-05 seconds.\n",
      "50 - T070: 8.988380432128906e-05 seconds.\n",
      "51 - T072: 8.344650268554688e-05 seconds.\n",
      "52 - T073: 8.487701416015625e-05 seconds.\n",
      "53 - T074: 8.368492126464844e-05 seconds.\n",
      "54 - T075: 8.320808410644531e-05 seconds.\n",
      "55 - T077: 0.00010156631469726562 seconds.\n",
      "56 - S001: 8.749961853027344e-05 seconds.\n",
      "57 - S002: 9.799003601074219e-05 seconds.\n",
      "58 - S003: 8.273124694824219e-05 seconds.\n",
      "59 - S004: 0.00011205673217773438 seconds.\n",
      "60 - S005: 6.794929504394531e-05 seconds.\n",
      "61 - S006: 6.866455078125e-05 seconds.\n",
      "62 - S007: 6.771087646484375e-05 seconds.\n",
      "63 - S009: 7.295608520507812e-05 seconds.\n",
      "64 - S010: 7.104873657226562e-05 seconds.\n",
      "65 - S013: 7.009506225585938e-05 seconds.\n",
      "66 - S014: 7.343292236328125e-05 seconds.\n",
      "67 - S016: 6.556510925292969e-05 seconds.\n",
      "68 - S017: 9.34600830078125e-05 seconds.\n",
      "69 - S018: 8.368492126464844e-05 seconds.\n",
      "70 - S019: 8.630752563476562e-05 seconds.\n",
      "71 - S020: 0.00011014938354492188 seconds.\n",
      "72 - S021: 9.441375732421875e-05 seconds.\n",
      "73 - S022: 8.273124694824219e-05 seconds.\n",
      "74 - S023: 8.368492126464844e-05 seconds.\n",
      "75 - S024: 8.392333984375e-05 seconds.\n",
      "76 - S025: 8.702278137207031e-05 seconds.\n",
      "77 - S026: 8.273124694824219e-05 seconds.\n",
      "78 - S027: 8.177757263183594e-05 seconds.\n",
      "79 - S028: 8.344650268554688e-05 seconds.\n",
      "80 - S029: 9.489059448242188e-05 seconds.\n",
      "81 - S030: 8.153915405273438e-05 seconds.\n",
      "82 - S034: 8.249282836914062e-05 seconds.\n",
      "83 - S035: 7.510185241699219e-05 seconds.\n",
      "84 - S036: 6.651878356933594e-05 seconds.\n",
      "85 - S038: 7.2479248046875e-05 seconds.\n",
      "86 - S039: 6.723403930664062e-05 seconds.\n",
      "87 - S043: 7.796287536621094e-05 seconds.\n",
      "88 - S044: 7.05718994140625e-05 seconds.\n",
      "89 - S047: 6.747245788574219e-05 seconds.\n",
      "90 - S048: 6.29425048828125e-05 seconds.\n",
      "91 - S049: 7.653236389160156e-05 seconds.\n",
      "92 - S050: 6.628036499023438e-05 seconds.\n",
      "93 - S051: 7.390975952148438e-05 seconds.\n",
      "94 - S052: 6.747245788574219e-05 seconds.\n",
      "95 - S055: 7.224082946777344e-05 seconds.\n",
      "96 - S057: 9.250640869140625e-05 seconds.\n",
      "97 - S058: 9.608268737792969e-05 seconds.\n",
      "98 - S059: 9.202957153320312e-05 seconds.\n",
      "99 - S061: 9.894371032714844e-05 seconds.\n",
      "100 - S064: 8.630752563476562e-05 seconds.\n",
      "101 - S065: 9.894371032714844e-05 seconds.\n",
      "102 - S067: 7.62939453125e-05 seconds.\n",
      "103 - S069: 7.486343383789062e-05 seconds.\n",
      "104 - S071: 7.271766662597656e-05 seconds.\n",
      "105 - S072: 6.4849853515625e-05 seconds.\n",
      "106 - S073: 0.0001087188720703125 seconds.\n",
      "107 - S074: 8.153915405273438e-05 seconds.\n",
      "108 - S076: 0.00010752677917480469 seconds.\n",
      "109 - MI0002: 9.703636169433594e-05 seconds.\n",
      "110 - MI0003: 8.96453857421875e-05 seconds.\n",
      "111 - MI0004: 8.416175842285156e-05 seconds.\n",
      "112 - MI0021: 9.465217590332031e-05 seconds.\n",
      "113 - MI0022: 6.914138793945312e-05 seconds.\n",
      "114 - MI0023: 7.367134094238281e-05 seconds.\n",
      "115 - MI0024: 6.556510925292969e-05 seconds.\n",
      "116 - MI0025: 7.319450378417969e-05 seconds.\n",
      "117 - MI0026: 6.413459777832031e-05 seconds.\n",
      "118 - MI0027: 6.723403930664062e-05 seconds.\n",
      "119 - MI0028: 0.00010251998901367188 seconds.\n",
      "120 - MI0029: 0.0004420280456542969 seconds.\n",
      "121 - MI0030: 0.0002970695495605469 seconds.\n",
      "122 - MI0031: 0.00025177001953125 seconds.\n",
      "123 - MI0034: 0.00021529197692871094 seconds.\n",
      "124 - MI0035: 0.0002219676971435547 seconds.\n",
      "125 - MI0036: 0.00019741058349609375 seconds.\n",
      "126 - MI0037: 0.00018286705017089844 seconds.\n",
      "127 - MI0038: 0.00019860267639160156 seconds.\n",
      "128 - MI0039: 0.00020003318786621094 seconds.\n",
      "129 - MI0040: 0.0001926422119140625 seconds.\n",
      "130 - MI0041: 0.0002129077911376953 seconds.\n",
      "131 - MI0042: 0.00019049644470214844 seconds.\n",
      "132 - MI0043: 0.00018024444580078125 seconds.\n",
      "133 - MI0046: 0.0003829002380371094 seconds.\n",
      "134 - MI0047: 0.00022554397583007812 seconds.\n",
      "135 - MI0048: 0.00025963783264160156 seconds.\n",
      "136 - MI0049: 0.00021886825561523438 seconds.\n",
      "137 - MI0050: 0.00019550323486328125 seconds.\n",
      "138 - MI0051: 0.0001442432403564453 seconds.\n",
      "139 - MI0052: 0.00015544891357421875 seconds.\n",
      "140 - MI0053: 0.0001533031463623047 seconds.\n",
      "141 - MI0054: 0.00016355514526367188 seconds.\n",
      "142 - MI0057: 0.00015807151794433594 seconds.\n",
      "143 - MI0058: 0.0001556873321533203 seconds.\n",
      "144 - MI0059: 0.00015544891357421875 seconds.\n",
      "145 - MI0060: 0.0001785755157470703 seconds.\n",
      "146 - MI0061: 0.00015163421630859375 seconds.\n",
      "147 - MI0062: 0.00015974044799804688 seconds.\n",
      "148 - MI0064: 0.0001895427703857422 seconds.\n",
      "149 - MI0066: 0.00015544891357421875 seconds.\n",
      "150 - MI0067: 0.00015616416931152344 seconds.\n",
      "151 - MI0068: 0.000171661376953125 seconds.\n",
      "152 - MI0069: 0.0001506805419921875 seconds.\n",
      "153 - MI0070: 0.00015091896057128906 seconds.\n",
      "154 - MI0071: 0.00015211105346679688 seconds.\n",
      "155 - MI0072: 0.00015616416931152344 seconds.\n",
      "156 - MI0073: 0.0001747608184814453 seconds.\n",
      "157 - MI0074: 0.00017762184143066406 seconds.\n",
      "158 - MI0075: 0.0001513957977294922 seconds.\n",
      "159 - MI0077: 0.00015211105346679688 seconds.\n",
      "160 - MI0078: 0.00017070770263671875 seconds.\n",
      "161 - MI0079: 0.0001742839813232422 seconds.\n",
      "162 - MI0080: 0.00015544891357421875 seconds.\n",
      "163 - MI0081: 0.0001480579376220703 seconds.\n",
      "164 - MI0082: 0.0001506805419921875 seconds.\n",
      "165 - MI0083: 0.0001723766326904297 seconds.\n",
      "166 - MI0084: 0.00015592575073242188 seconds.\n",
      "167 - MI0085: 0.00014472007751464844 seconds.\n",
      "168 - MI0086: 0.0001518726348876953 seconds.\n",
      "169 - MI0087: 0.0001068115234375 seconds.\n",
      "170 - MI0088: 0.00011086463928222656 seconds.\n",
      "171 - MI0089: 0.0001277923583984375 seconds.\n",
      "172 - MI0090: 0.00012302398681640625 seconds.\n",
      "173 - MI0092: 0.00010442733764648438 seconds.\n",
      "174 - MI0093: 0.00011444091796875 seconds.\n",
      "175 - MI0095: 0.00010323524475097656 seconds.\n",
      "176 - MI0096: 0.00012087821960449219 seconds.\n",
      "177 - MI0097: 0.00012040138244628906 seconds.\n",
      "178 - MI0098: 0.00012755393981933594 seconds.\n",
      "179 - MI0099: 0.00012040138244628906 seconds.\n",
      "180 - MI0101: 0.00012135505676269531 seconds.\n",
      "181 - MI0102: 0.00011444091796875 seconds.\n",
      "182 - MI0104: 0.00011587142944335938 seconds.\n",
      "183 - MI0105: 0.00011491775512695312 seconds.\n",
      "184 - MI0106: 0.00010609626770019531 seconds.\n",
      "185 - MI0107: 0.00010967254638671875 seconds.\n",
      "186 - MI0109: 0.00010561943054199219 seconds.\n",
      "187 - MI0110: 0.00012040138244628906 seconds.\n",
      "188 - MI0111: 0.00012564659118652344 seconds.\n",
      "189 - MI0112: 0.00011730194091796875 seconds.\n",
      "190 - MI0113: 0.00010371208190917969 seconds.\n",
      "191 - MI0114: 0.00011491775512695312 seconds.\n",
      "192 - MI0117: 0.00010704994201660156 seconds.\n",
      "193 - MI0118: 0.00010442733764648438 seconds.\n",
      "194 - MI0119: 9.989738464355469e-05 seconds.\n",
      "195 - MI0120: 0.00012421607971191406 seconds.\n",
      "196 - MI0121: 0.00010180473327636719 seconds.\n",
      "197 - MI0122: 0.0001201629638671875 seconds.\n",
      "198 - MI0123: 0.00010323524475097656 seconds.\n",
      "199 - MI0124: 0.00010633468627929688 seconds.\n",
      "200 - MI0125: 0.00011897087097167969 seconds.\n",
      "201 - MI0127: 0.00010538101196289062 seconds.\n",
      "202 - MI0128: 0.00011801719665527344 seconds.\n",
      "203 - MI0129: 0.00012087821960449219 seconds.\n",
      "204 - MI0130: 0.00010704994201660156 seconds.\n",
      "205 - MI0132: 0.00011658668518066406 seconds.\n",
      "206 - MI0133: 0.00010251998901367188 seconds.\n",
      "207 - MI0134: 0.00010395050048828125 seconds.\n",
      "208 - MI0135: 0.0001010894775390625 seconds.\n",
      "209 - MI0136: 0.00010323524475097656 seconds.\n",
      "210 - MI0138: 7.104873657226562e-05 seconds.\n",
      "Fold 1 (val 0 - 42)\n",
      "(Epoch 0), time: 8.8s, loss: 1.130\n",
      "    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n",
      "(Epoch 1), time: 8.8s, loss: 1.127\n",
      "    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n",
      "(Epoch 2), time: 8.8s, loss: 1.127\n",
      "    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n",
      "(Epoch 3), time: 8.9s, loss: 1.125\n",
      "    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n",
      "(Epoch 4), time: 9.0s, loss: 1.121\n",
      "    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n",
      "(Epoch 5), time: 9.0s, loss: 1.115\n",
      "    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n",
      "(Epoch 6), time: 9.0s, loss: 1.108\n",
      "    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n",
      "(Epoch 7), time: 9.0s, loss: 1.102\n",
      "    Training Set - accuracy: 0.19, precision: 0.39, recall: 0.34, f1-score: 0.12,\n",
      "    Validation Set - accuracy: 0.10, precision: 0.44, recall: 0.41, f1-score: 0.13,\n",
      "(Epoch 8), time: 9.0s, loss: 1.089\n",
      "    Training Set - accuracy: 0.27, precision: 0.58, recall: 0.38, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.07, precision: 0.08, recall: 0.40, f1-score: 0.10,\n",
      "(Epoch 9), time: 9.0s, loss: 1.091\n",
      "    Training Set - accuracy: 0.28, precision: 0.40, recall: 0.39, f1-score: 0.26,\n",
      "    Validation Set - accuracy: 0.17, precision: 0.36, recall: 0.44, f1-score: 0.18,\n",
      "(Epoch 10), time: 9.0s, loss: 1.091\n",
      "    Training Set - accuracy: 0.27, precision: 0.42, recall: 0.38, f1-score: 0.26,\n",
      "    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.04,\n",
      "(Epoch 11), time: 9.0s, loss: 1.077\n",
      "    Training Set - accuracy: 0.29, precision: 0.29, recall: 0.42, f1-score: 0.26,\n",
      "    Validation Set - accuracy: 0.07, precision: 0.05, recall: 0.40, f1-score: 0.08,\n",
      "(Epoch 12), time: 9.0s, loss: 1.071\n",
      "    Training Set - accuracy: 0.30, precision: 0.23, recall: 0.41, f1-score: 0.27,\n",
      "    Validation Set - accuracy: 0.10, precision: 0.39, recall: 0.41, f1-score: 0.10,\n",
      "(Epoch 13), time: 9.0s, loss: 1.065\n",
      "    Training Set - accuracy: 0.30, precision: 0.48, recall: 0.42, f1-score: 0.28,\n",
      "    Validation Set - accuracy: 0.12, precision: 0.28, recall: 0.42, f1-score: 0.13,\n",
      "(Epoch 14), time: 9.0s, loss: 1.055\n",
      "    Training Set - accuracy: 0.34, precision: 0.49, recall: 0.45, f1-score: 0.33,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.33, recall: 0.52, f1-score: 0.22,\n",
      "(Epoch 15), time: 9.0s, loss: 1.035\n",
      "    Training Set - accuracy: 0.38, precision: 0.51, recall: 0.49, f1-score: 0.36,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.45, recall: 0.65, f1-score: 0.28,\n",
      "(Epoch 16), time: 9.0s, loss: 1.023\n",
      "    Training Set - accuracy: 0.43, precision: 0.57, recall: 0.53, f1-score: 0.42,\n",
      "    Validation Set - accuracy: 0.25, precision: 0.38, recall: 0.58, f1-score: 0.25,\n",
      "(Epoch 17), time: 9.0s, loss: 0.998\n",
      "    Training Set - accuracy: 0.52, precision: 0.61, recall: 0.59, f1-score: 0.52,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.36, recall: 0.47, f1-score: 0.22,\n",
      "(Epoch 18), time: 9.0s, loss: 0.983\n",
      "    Training Set - accuracy: 0.60, precision: 0.65, recall: 0.66, f1-score: 0.60,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.33, recall: 0.50, f1-score: 0.27,\n",
      "(Epoch 19), time: 9.0s, loss: 1.001\n",
      "    Training Set - accuracy: 0.55, precision: 0.59, recall: 0.61, f1-score: 0.54,\n",
      "    Validation Set - accuracy: 0.25, precision: 0.33, recall: 0.43, f1-score: 0.23,\n",
      "(Epoch 20), time: 9.0s, loss: 1.014\n",
      "    Training Set - accuracy: 0.59, precision: 0.62, recall: 0.62, f1-score: 0.58,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.37, recall: 0.47, f1-score: 0.30,\n",
      "(Epoch 21), time: 9.0s, loss: 0.981\n",
      "    Training Set - accuracy: 0.64, precision: 0.65, recall: 0.66, f1-score: 0.62,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.27, recall: 0.27, f1-score: 0.20,\n",
      "(Epoch 22), time: 9.0s, loss: 0.955\n",
      "    Training Set - accuracy: 0.64, precision: 0.68, recall: 0.67, f1-score: 0.63,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.30, recall: 0.34, f1-score: 0.25,\n",
      "(Epoch 23), time: 9.0s, loss: 0.931\n",
      "    Training Set - accuracy: 0.68, precision: 0.68, recall: 0.70, f1-score: 0.67,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.31, recall: 0.32, f1-score: 0.23,\n",
      "(Epoch 24), time: 9.0s, loss: 0.916\n",
      "    Training Set - accuracy: 0.69, precision: 0.70, recall: 0.72, f1-score: 0.68,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.30, recall: 0.32, f1-score: 0.22,\n",
      "(Epoch 25), time: 9.0s, loss: 0.881\n",
      "    Training Set - accuracy: 0.72, precision: 0.74, recall: 0.76, f1-score: 0.72,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.35, recall: 0.42, f1-score: 0.29,\n",
      "(Epoch 26), time: 9.0s, loss: 0.855\n",
      "    Training Set - accuracy: 0.74, precision: 0.76, recall: 0.77, f1-score: 0.74,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.27, recall: 0.27, f1-score: 0.21,\n",
      "(Epoch 27), time: 9.1s, loss: 0.835\n",
      "    Training Set - accuracy: 0.74, precision: 0.75, recall: 0.77, f1-score: 0.73,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.30, recall: 0.30, f1-score: 0.25,\n",
      "(Epoch 28), time: 9.0s, loss: 0.832\n",
      "    Training Set - accuracy: 0.77, precision: 0.76, recall: 0.78, f1-score: 0.76,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.34, recall: 0.39, f1-score: 0.29,\n",
      "(Epoch 29), time: 9.0s, loss: 0.804\n",
      "    Training Set - accuracy: 0.78, precision: 0.76, recall: 0.79, f1-score: 0.77,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.30, recall: 0.36, f1-score: 0.27,\n",
      "(Epoch 30), time: 9.0s, loss: 0.773\n",
      "    Training Set - accuracy: 0.79, precision: 0.78, recall: 0.82, f1-score: 0.78,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.38, recall: 0.44, f1-score: 0.35,\n",
      "(Epoch 31), time: 9.0s, loss: 0.748\n",
      "    Training Set - accuracy: 0.81, precision: 0.80, recall: 0.83, f1-score: 0.81,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.32, recall: 0.37, f1-score: 0.29,\n",
      "(Epoch 32), time: 9.0s, loss: 0.690\n",
      "    Training Set - accuracy: 0.82, precision: 0.81, recall: 0.85, f1-score: 0.81,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.29, recall: 0.33, f1-score: 0.22,\n",
      "(Epoch 33), time: 9.0s, loss: 0.694\n",
      "    Training Set - accuracy: 0.82, precision: 0.81, recall: 0.84, f1-score: 0.82,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.31, recall: 0.40, f1-score: 0.26,\n",
      "(Epoch 34), time: 9.0s, loss: 0.709\n",
      "    Training Set - accuracy: 0.79, precision: 0.78, recall: 0.81, f1-score: 0.79,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.32, recall: 0.34, f1-score: 0.30,\n",
      "(Epoch 35), time: 9.0s, loss: 0.654\n",
      "    Training Set - accuracy: 0.81, precision: 0.79, recall: 0.83, f1-score: 0.80,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.30, recall: 0.34, f1-score: 0.29,\n",
      "(Epoch 36), time: 9.0s, loss: 0.590\n",
      "    Training Set - accuracy: 0.86, precision: 0.84, recall: 0.87, f1-score: 0.85,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.38, recall: 0.36, f1-score: 0.33,\n",
      "(Epoch 37), time: 9.0s, loss: 0.578\n",
      "    Training Set - accuracy: 0.87, precision: 0.87, recall: 0.88, f1-score: 0.87,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.31, recall: 0.33, f1-score: 0.28,\n",
      "(Epoch 38), time: 9.0s, loss: 0.542\n",
      "    Training Set - accuracy: 0.90, precision: 0.90, recall: 0.90, f1-score: 0.90,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.36, f1-score: 0.33,\n",
      "(Epoch 39), time: 9.0s, loss: 0.506\n",
      "    Training Set - accuracy: 0.91, precision: 0.90, recall: 0.90, f1-score: 0.90,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.28, recall: 0.30, f1-score: 0.23,\n",
      "(Epoch 40), time: 9.0s, loss: 0.496\n",
      "    Training Set - accuracy: 0.92, precision: 0.91, recall: 0.92, f1-score: 0.91,\n",
      "Confusion Matrix:\n",
      "[[15 14  4]\n",
      " [ 4  1  0]\n",
      " [ 1  0  1]]\n",
      "    Validation Set - accuracy: 0.42, precision: 0.34, recall: 0.38, f1-score: 0.32,\n",
      "Fold 2 (val 43 - 84)\n",
      "(Epoch 0), time: 9.0s, loss: 1.126\n",
      "    Training Set - accuracy: 0.31, precision: 0.10, recall: 0.33, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.07, recall: 0.33, f1-score: 0.12,\n",
      "(Epoch 1), time: 9.0s, loss: 1.117\n",
      "    Training Set - accuracy: 0.31, precision: 0.10, recall: 0.33, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.07, recall: 0.33, f1-score: 0.12,\n",
      "(Epoch 2), time: 9.0s, loss: 1.110\n",
      "    Training Set - accuracy: 0.31, precision: 0.10, recall: 0.33, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.07, recall: 0.33, f1-score: 0.12,\n",
      "(Epoch 3), time: 9.0s, loss: 1.102\n",
      "    Training Set - accuracy: 0.31, precision: 0.10, recall: 0.33, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.07, recall: 0.33, f1-score: 0.12,\n",
      "(Epoch 4), time: 9.0s, loss: 1.090\n",
      "    Training Set - accuracy: 0.31, precision: 0.10, recall: 0.33, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.07, recall: 0.33, f1-score: 0.12,\n",
      "(Epoch 5), time: 9.0s, loss: 1.083\n",
      "    Training Set - accuracy: 0.31, precision: 0.10, recall: 0.33, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.07, recall: 0.33, f1-score: 0.12,\n",
      "(Epoch 6), time: 9.0s, loss: 1.061\n",
      "    Training Set - accuracy: 0.31, precision: 0.10, recall: 0.33, f1-score: 0.16,\n",
      "    Validation Set - accuracy: 0.17, precision: 0.14, recall: 0.23, f1-score: 0.11,\n",
      "(Epoch 7), time: 9.0s, loss: 1.039\n",
      "    Training Set - accuracy: 0.39, precision: 0.69, recall: 0.43, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.29, recall: 0.29, f1-score: 0.21,\n",
      "(Epoch 8), time: 9.0s, loss: 1.031\n",
      "    Training Set - accuracy: 0.42, precision: 0.55, recall: 0.46, f1-score: 0.38,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.31, recall: 0.29, f1-score: 0.23,\n",
      "(Epoch 9), time: 9.0s, loss: 1.002\n",
      "    Training Set - accuracy: 0.52, precision: 0.58, recall: 0.57, f1-score: 0.52,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.26, recall: 0.23, f1-score: 0.19,\n",
      "(Epoch 10), time: 9.1s, loss: 0.976\n",
      "    Training Set - accuracy: 0.56, precision: 0.60, recall: 0.62, f1-score: 0.57,\n",
      "    Validation Set - accuracy: 0.25, precision: 0.21, recall: 0.14, f1-score: 0.16,\n",
      "(Epoch 11), time: 9.1s, loss: 0.948\n",
      "    Training Set - accuracy: 0.57, precision: 0.57, recall: 0.61, f1-score: 0.56,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.23, recall: 0.23, f1-score: 0.18,\n",
      "(Epoch 12), time: 9.1s, loss: 0.929\n",
      "    Training Set - accuracy: 0.56, precision: 0.58, recall: 0.62, f1-score: 0.55,\n",
      "    Validation Set - accuracy: 0.23, precision: 0.27, recall: 0.13, f1-score: 0.17,\n",
      "(Epoch 13), time: 9.0s, loss: 0.898\n",
      "    Training Set - accuracy: 0.57, precision: 0.60, recall: 0.64, f1-score: 0.56,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.36, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 14), time: 9.0s, loss: 0.871\n",
      "    Training Set - accuracy: 0.64, precision: 0.65, recall: 0.69, f1-score: 0.63,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.25, recall: 0.25, f1-score: 0.21,\n",
      "(Epoch 15), time: 9.0s, loss: 0.838\n",
      "    Training Set - accuracy: 0.64, precision: 0.64, recall: 0.69, f1-score: 0.63,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.30, f1-score: 0.27,\n",
      "(Epoch 16), time: 9.0s, loss: 0.811\n",
      "    Training Set - accuracy: 0.64, precision: 0.64, recall: 0.69, f1-score: 0.63,\n",
      "    Validation Set - accuracy: 0.20, precision: 0.20, recall: 0.12, f1-score: 0.15,\n",
      "(Epoch 17), time: 9.0s, loss: 0.802\n",
      "    Training Set - accuracy: 0.68, precision: 0.67, recall: 0.72, f1-score: 0.67,\n",
      "    Validation Set - accuracy: 0.20, precision: 0.21, recall: 0.17, f1-score: 0.15,\n",
      "(Epoch 18), time: 9.1s, loss: 0.764\n",
      "    Training Set - accuracy: 0.71, precision: 0.69, recall: 0.75, f1-score: 0.70,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.30, recall: 0.24, f1-score: 0.26,\n",
      "(Epoch 19), time: 9.1s, loss: 0.710\n",
      "    Training Set - accuracy: 0.79, precision: 0.78, recall: 0.83, f1-score: 0.79,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.24, recall: 0.22, f1-score: 0.22,\n",
      "(Epoch 20), time: 9.1s, loss: 0.650\n",
      "    Training Set - accuracy: 0.84, precision: 0.82, recall: 0.86, f1-score: 0.84,\n",
      "    Validation Set - accuracy: 0.25, precision: 0.20, recall: 0.17, f1-score: 0.18,\n",
      "(Epoch 21), time: 9.1s, loss: 0.611\n",
      "    Training Set - accuracy: 0.81, precision: 0.79, recall: 0.82, f1-score: 0.80,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.26, recall: 0.24, f1-score: 0.25,\n",
      "(Epoch 22), time: 9.0s, loss: 0.560\n",
      "    Training Set - accuracy: 0.86, precision: 0.85, recall: 0.88, f1-score: 0.86,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.24, recall: 0.23, f1-score: 0.23,\n",
      "(Epoch 23), time: 9.0s, loss: 0.519\n",
      "    Training Set - accuracy: 0.88, precision: 0.86, recall: 0.88, f1-score: 0.87,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.23, recall: 0.19, f1-score: 0.20,\n",
      "(Epoch 24), time: 9.0s, loss: 0.501\n",
      "    Training Set - accuracy: 0.89, precision: 0.88, recall: 0.90, f1-score: 0.89,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.18, recall: 0.17, f1-score: 0.17,\n",
      "(Epoch 25), time: 9.0s, loss: 0.468\n",
      "    Training Set - accuracy: 0.91, precision: 0.89, recall: 0.92, f1-score: 0.91,\n",
      "Confusion Matrix:\n",
      "[[14 10  4]\n",
      " [ 6  3  0]\n",
      " [ 1  2  0]]\n",
      "    Validation Set - accuracy: 0.42, precision: 0.29, recall: 0.28, f1-score: 0.27,\n",
      "Fold 3 (val 85 - 126)\n",
      "(Epoch 0), time: 9.0s, loss: 1.100\n",
      "    Training Set - accuracy: 0.51, precision: 0.19, recall: 0.29, f1-score: 0.23,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 1), time: 9.0s, loss: 1.093\n",
      "    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 2), time: 9.0s, loss: 1.080\n",
      "    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 3), time: 9.1s, loss: 1.062\n",
      "    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 4), time: 9.1s, loss: 1.047\n",
      "    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 5), time: 9.1s, loss: 1.032\n",
      "    Training Set - accuracy: 0.60, precision: 0.53, recall: 0.35, f1-score: 0.28,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 6), time: 9.1s, loss: 1.021\n",
      "    Training Set - accuracy: 0.60, precision: 0.53, recall: 0.35, f1-score: 0.28,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 7), time: 9.1s, loss: 1.006\n",
      "    Training Set - accuracy: 0.61, precision: 0.53, recall: 0.37, f1-score: 0.31,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 8), time: 9.1s, loss: 0.991\n",
      "    Training Set - accuracy: 0.61, precision: 0.54, recall: 0.38, f1-score: 0.33,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n",
      "(Epoch 9), time: 9.1s, loss: 0.973\n",
      "    Training Set - accuracy: 0.64, precision: 0.54, recall: 0.44, f1-score: 0.42,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.46, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 10), time: 9.1s, loss: 0.963\n",
      "    Training Set - accuracy: 0.64, precision: 0.54, recall: 0.44, f1-score: 0.42,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.30, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 11), time: 9.1s, loss: 0.953\n",
      "    Training Set - accuracy: 0.67, precision: 0.55, recall: 0.52, f1-score: 0.50,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.21, recall: 0.35, f1-score: 0.23,\n",
      "(Epoch 12), time: 9.1s, loss: 0.945\n",
      "    Training Set - accuracy: 0.66, precision: 0.52, recall: 0.50, f1-score: 0.48,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.24, recall: 0.35, f1-score: 0.24,\n",
      "(Epoch 13), time: 9.1s, loss: 0.934\n",
      "    Training Set - accuracy: 0.67, precision: 0.55, recall: 0.52, f1-score: 0.50,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 14), time: 9.1s, loss: 0.916\n",
      "    Training Set - accuracy: 0.68, precision: 0.53, recall: 0.56, f1-score: 0.52,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 15), time: 9.1s, loss: 0.898\n",
      "    Training Set - accuracy: 0.69, precision: 0.55, recall: 0.59, f1-score: 0.55,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.21, recall: 0.35, f1-score: 0.23,\n",
      "(Epoch 16), time: 9.1s, loss: 0.879\n",
      "    Training Set - accuracy: 0.70, precision: 0.52, recall: 0.62, f1-score: 0.56,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.24, recall: 0.35, f1-score: 0.24,\n",
      "(Epoch 17), time: 9.1s, loss: 0.858\n",
      "    Training Set - accuracy: 0.71, precision: 0.54, recall: 0.65, f1-score: 0.59,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.13, recall: 0.33, f1-score: 0.19,\n",
      "(Epoch 18), time: 9.1s, loss: 0.833\n",
      "    Training Set - accuracy: 0.71, precision: 0.56, recall: 0.62, f1-score: 0.57,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.13, recall: 0.33, f1-score: 0.19,\n",
      "(Epoch 19), time: 9.1s, loss: 0.809\n",
      "    Training Set - accuracy: 0.71, precision: 0.54, recall: 0.62, f1-score: 0.57,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 20), time: 9.1s, loss: 0.773\n",
      "    Training Set - accuracy: 0.72, precision: 0.55, recall: 0.65, f1-score: 0.59,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.30, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 21), time: 9.1s, loss: 0.743\n",
      "    Training Set - accuracy: 0.72, precision: 0.56, recall: 0.65, f1-score: 0.59,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.22, recall: 0.37, f1-score: 0.25,\n",
      "(Epoch 22), time: 9.1s, loss: 0.707\n",
      "    Training Set - accuracy: 0.72, precision: 0.56, recall: 0.65, f1-score: 0.59,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.24, recall: 0.35, f1-score: 0.24,\n",
      "(Epoch 23), time: 9.1s, loss: 0.686\n",
      "    Training Set - accuracy: 0.72, precision: 0.86, recall: 0.66, f1-score: 0.61,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.17, recall: 0.30, f1-score: 0.21,\n",
      "(Epoch 24), time: 9.1s, loss: 0.673\n",
      "    Training Set - accuracy: 0.74, precision: 0.79, recall: 0.70, f1-score: 0.65,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.19, recall: 0.33, f1-score: 0.22,\n",
      "(Epoch 25), time: 9.1s, loss: 0.757\n",
      "    Training Set - accuracy: 0.69, precision: 0.74, recall: 0.66, f1-score: 0.56,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.22, recall: 0.37, f1-score: 0.28,\n",
      "(Epoch 26), time: 9.1s, loss: 0.673\n",
      "    Training Set - accuracy: 0.75, precision: 0.78, recall: 0.73, f1-score: 0.70,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.27, recall: 0.30, f1-score: 0.24,\n",
      "(Epoch 27), time: 9.1s, loss: 0.666\n",
      "    Training Set - accuracy: 0.74, precision: 0.76, recall: 0.69, f1-score: 0.68,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.28, recall: 0.40, f1-score: 0.31,\n",
      "(Epoch 28), time: 9.1s, loss: 0.618\n",
      "    Training Set - accuracy: 0.78, precision: 0.88, recall: 0.73, f1-score: 0.74,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.19, recall: 0.33, f1-score: 0.22,\n",
      "(Epoch 29), time: 9.1s, loss: 0.582\n",
      "    Training Set - accuracy: 0.82, precision: 0.88, recall: 0.78, f1-score: 0.81,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.18, recall: 0.30, f1-score: 0.22,\n",
      "(Epoch 30), time: 9.1s, loss: 0.557\n",
      "    Training Set - accuracy: 0.84, precision: 0.88, recall: 0.83, f1-score: 0.85,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.24, recall: 0.30, f1-score: 0.25,\n",
      "(Epoch 31), time: 9.1s, loss: 0.535\n",
      "    Training Set - accuracy: 0.82, precision: 0.86, recall: 0.80, f1-score: 0.82,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.26, recall: 0.32, f1-score: 0.27,\n",
      "(Epoch 32), time: 9.1s, loss: 0.519\n",
      "    Training Set - accuracy: 0.85, precision: 0.88, recall: 0.83, f1-score: 0.85,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.26, recall: 0.30, f1-score: 0.27,\n",
      "(Epoch 33), time: 9.1s, loss: 0.506\n",
      "    Training Set - accuracy: 0.89, precision: 0.90, recall: 0.88, f1-score: 0.89,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.35, recall: 0.37, f1-score: 0.32,\n",
      "(Epoch 34), time: 9.1s, loss: 0.524\n",
      "    Training Set - accuracy: 0.91, precision: 0.92, recall: 0.90, f1-score: 0.91,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.44, recall: 0.45, f1-score: 0.43,\n",
      "(Epoch 35), time: 9.1s, loss: 0.502\n",
      "    Training Set - accuracy: 0.89, precision: 0.91, recall: 0.88, f1-score: 0.89,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.32, recall: 0.34, f1-score: 0.32,\n",
      "(Epoch 36), time: 9.1s, loss: 0.478\n",
      "    Training Set - accuracy: 0.91, precision: 0.92, recall: 0.90, f1-score: 0.91,\n",
      "Confusion Matrix:\n",
      "[[12  2  1]\n",
      " [ 9  5  2]\n",
      " [ 5  3  1]]\n",
      "    Validation Set - accuracy: 0.45, precision: 0.40, recall: 0.41, f1-score: 0.37,\n",
      "Fold 4 (val 127 - 168)\n",
      "(Epoch 0), time: 9.0s, loss: 1.109\n",
      "    Training Set - accuracy: 0.30, precision: 0.10, recall: 0.33, f1-score: 0.15,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.10, recall: 0.33, f1-score: 0.15,\n",
      "(Epoch 1), time: 9.0s, loss: 1.100\n",
      "    Training Set - accuracy: 0.30, precision: 0.10, recall: 0.33, f1-score: 0.15,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.10, recall: 0.33, f1-score: 0.15,\n",
      "(Epoch 2), time: 9.0s, loss: 1.097\n",
      "    Training Set - accuracy: 0.30, precision: 0.10, recall: 0.33, f1-score: 0.15,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.10, recall: 0.33, f1-score: 0.15,\n",
      "(Epoch 3), time: 9.0s, loss: 1.093\n",
      "    Training Set - accuracy: 0.34, precision: 0.28, recall: 0.32, f1-score: 0.24,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.27, recall: 0.34, f1-score: 0.29,\n",
      "(Epoch 4), time: 9.0s, loss: 1.083\n",
      "    Training Set - accuracy: 0.49, precision: 0.32, recall: 0.37, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.30, recall: 0.40, f1-score: 0.33,\n",
      "(Epoch 5), time: 9.0s, loss: 1.072\n",
      "    Training Set - accuracy: 0.53, precision: 0.31, recall: 0.35, f1-score: 0.33,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.28, recall: 0.36, f1-score: 0.30,\n",
      "(Epoch 6), time: 9.0s, loss: 1.066\n",
      "    Training Set - accuracy: 0.56, precision: 0.34, recall: 0.36, f1-score: 0.33,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n",
      "(Epoch 7), time: 9.0s, loss: 1.049\n",
      "    Training Set - accuracy: 0.60, precision: 0.39, recall: 0.39, f1-score: 0.36,\n",
      "    Validation Set - accuracy: 0.47, precision: 0.49, recall: 0.36, f1-score: 0.26,\n",
      "(Epoch 8), time: 9.0s, loss: 1.041\n",
      "    Training Set - accuracy: 0.59, precision: 0.37, recall: 0.38, f1-score: 0.35,\n",
      "    Validation Set - accuracy: 0.47, precision: 0.49, recall: 0.36, f1-score: 0.26,\n",
      "(Epoch 9), time: 9.0s, loss: 1.020\n",
      "    Training Set - accuracy: 0.60, precision: 0.39, recall: 0.40, f1-score: 0.38,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.31, recall: 0.35, f1-score: 0.28,\n",
      "(Epoch 10), time: 9.0s, loss: 1.009\n",
      "    Training Set - accuracy: 0.60, precision: 0.39, recall: 0.40, f1-score: 0.38,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.33, f1-score: 0.27,\n",
      "(Epoch 11), time: 9.0s, loss: 0.986\n",
      "    Training Set - accuracy: 0.61, precision: 0.40, recall: 0.40, f1-score: 0.38,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.31, recall: 0.35, f1-score: 0.28,\n",
      "(Epoch 12), time: 9.0s, loss: 0.960\n",
      "    Training Set - accuracy: 0.62, precision: 0.41, recall: 0.43, f1-score: 0.41,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.33, f1-score: 0.27,\n",
      "(Epoch 13), time: 9.0s, loss: 0.945\n",
      "    Training Set - accuracy: 0.62, precision: 0.40, recall: 0.43, f1-score: 0.41,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.32, f1-score: 0.27,\n",
      "(Epoch 14), time: 9.0s, loss: 0.946\n",
      "    Training Set - accuracy: 0.62, precision: 0.73, recall: 0.46, f1-score: 0.45,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.26, recall: 0.33, f1-score: 0.27,\n",
      "(Epoch 15), time: 9.0s, loss: 0.921\n",
      "    Training Set - accuracy: 0.61, precision: 0.72, recall: 0.45, f1-score: 0.46,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.27, recall: 0.31, f1-score: 0.26,\n",
      "(Epoch 16), time: 9.0s, loss: 0.920\n",
      "    Training Set - accuracy: 0.66, precision: 0.69, recall: 0.56, f1-score: 0.59,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.28, recall: 0.31, f1-score: 0.27,\n",
      "(Epoch 17), time: 9.0s, loss: 0.885\n",
      "    Training Set - accuracy: 0.66, precision: 0.69, recall: 0.57, f1-score: 0.61,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.48, recall: 0.32, f1-score: 0.25,\n",
      "(Epoch 18), time: 9.0s, loss: 0.893\n",
      "    Training Set - accuracy: 0.70, precision: 0.70, recall: 0.65, f1-score: 0.66,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.31, recall: 0.31, f1-score: 0.27,\n",
      "(Epoch 19), time: 9.0s, loss: 0.852\n",
      "    Training Set - accuracy: 0.69, precision: 0.69, recall: 0.66, f1-score: 0.67,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.37, recall: 0.32, f1-score: 0.28,\n",
      "(Epoch 20), time: 9.0s, loss: 0.825\n",
      "    Training Set - accuracy: 0.74, precision: 0.70, recall: 0.71, f1-score: 0.70,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.35, recall: 0.34, f1-score: 0.33,\n",
      "(Epoch 21), time: 9.0s, loss: 0.806\n",
      "    Training Set - accuracy: 0.73, precision: 0.69, recall: 0.73, f1-score: 0.70,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.39, recall: 0.38, f1-score: 0.36,\n",
      "(Epoch 22), time: 9.0s, loss: 0.768\n",
      "    Training Set - accuracy: 0.78, precision: 0.74, recall: 0.75, f1-score: 0.73,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.35, recall: 0.30, f1-score: 0.27,\n",
      "(Epoch 23), time: 9.0s, loss: 0.751\n",
      "    Training Set - accuracy: 0.81, precision: 0.78, recall: 0.80, f1-score: 0.78,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.31, recall: 0.32, f1-score: 0.28,\n",
      "(Epoch 24), time: 9.0s, loss: 0.706\n",
      "    Training Set - accuracy: 0.83, precision: 0.79, recall: 0.84, f1-score: 0.81,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.43, recall: 0.39, f1-score: 0.38,\n",
      "(Epoch 25), time: 9.0s, loss: 0.676\n",
      "    Training Set - accuracy: 0.84, precision: 0.80, recall: 0.85, f1-score: 0.82,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.33, recall: 0.34, f1-score: 0.33,\n",
      "(Epoch 26), time: 9.0s, loss: 0.638\n",
      "    Training Set - accuracy: 0.88, precision: 0.84, recall: 0.89, f1-score: 0.86,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.39, recall: 0.39, f1-score: 0.38,\n",
      "(Epoch 27), time: 9.0s, loss: 0.592\n",
      "    Training Set - accuracy: 0.90, precision: 0.86, recall: 0.91, f1-score: 0.88,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.39, recall: 0.37, f1-score: 0.37,\n",
      "(Epoch 28), time: 9.1s, loss: 0.572\n",
      "    Training Set - accuracy: 0.89, precision: 0.86, recall: 0.91, f1-score: 0.88,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.39, recall: 0.39, f1-score: 0.38,\n",
      "(Epoch 29), time: 9.1s, loss: 0.537\n",
      "    Training Set - accuracy: 0.91, precision: 0.88, recall: 0.92, f1-score: 0.90,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.39, recall: 0.39, f1-score: 0.38,\n",
      "(Epoch 30), time: 9.1s, loss: 0.507\n",
      "    Training Set - accuracy: 0.91, precision: 0.88, recall: 0.93, f1-score: 0.90,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.35, recall: 0.34, f1-score: 0.33,\n",
      "(Epoch 31), time: 9.1s, loss: 0.498\n",
      "    Training Set - accuracy: 0.91, precision: 0.88, recall: 0.92, f1-score: 0.90,\n",
      "Confusion Matrix:\n",
      "[[12  3  3]\n",
      " [ 7  2  3]\n",
      " [ 7  2  1]]\n",
      "    Validation Set - accuracy: 0.38, precision: 0.30, recall: 0.31, f1-score: 0.29,\n",
      "Fold 5 (val 169 - 210)\n",
      "(Epoch 0), time: 9.1s, loss: 1.093\n",
      "    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n",
      "(Epoch 1), time: 9.1s, loss: 1.088\n",
      "    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n",
      "(Epoch 2), time: 9.1s, loss: 1.085\n",
      "    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n",
      "(Epoch 3), time: 9.1s, loss: 1.082\n",
      "    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n",
      "(Epoch 4), time: 9.1s, loss: 1.077\n",
      "    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n",
      "(Epoch 5), time: 9.1s, loss: 1.075\n",
      "    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n",
      "(Epoch 6), time: 9.1s, loss: 1.065\n",
      "    Training Set - accuracy: 0.62, precision: 0.54, recall: 0.36, f1-score: 0.30,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.45, recall: 0.35, f1-score: 0.21,\n",
      "(Epoch 7), time: 9.1s, loss: 1.059\n",
      "    Training Set - accuracy: 0.62, precision: 0.44, recall: 0.37, f1-score: 0.32,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.34, recall: 0.34, f1-score: 0.23,\n",
      "(Epoch 8), time: 9.1s, loss: 1.058\n",
      "    Training Set - accuracy: 0.60, precision: 0.37, recall: 0.35, f1-score: 0.29,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.46, recall: 0.37, f1-score: 0.24,\n",
      "(Epoch 9), time: 9.1s, loss: 1.037\n",
      "    Training Set - accuracy: 0.62, precision: 0.40, recall: 0.38, f1-score: 0.35,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.34, recall: 0.34, f1-score: 0.23,\n",
      "(Epoch 10), time: 9.1s, loss: 1.026\n",
      "    Training Set - accuracy: 0.63, precision: 0.45, recall: 0.39, f1-score: 0.36,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n",
      "(Epoch 11), time: 9.1s, loss: 1.016\n",
      "    Training Set - accuracy: 0.63, precision: 0.42, recall: 0.38, f1-score: 0.35,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.38, recall: 0.39, f1-score: 0.32,\n",
      "(Epoch 12), time: 9.1s, loss: 1.009\n",
      "    Training Set - accuracy: 0.62, precision: 0.44, recall: 0.38, f1-score: 0.35,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.32, recall: 0.37, f1-score: 0.30,\n",
      "(Epoch 13), time: 9.1s, loss: 0.987\n",
      "    Training Set - accuracy: 0.63, precision: 0.41, recall: 0.41, f1-score: 0.38,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.11, recall: 0.31, f1-score: 0.16,\n",
      "(Epoch 14), time: 9.1s, loss: 0.961\n",
      "    Training Set - accuracy: 0.66, precision: 0.47, recall: 0.43, f1-score: 0.40,\n",
      "    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.41, f1-score: 0.34,\n",
      "(Epoch 15), time: 9.1s, loss: 0.945\n",
      "    Training Set - accuracy: 0.65, precision: 0.43, recall: 0.44, f1-score: 0.42,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.36, recall: 0.37, f1-score: 0.30,\n",
      "(Epoch 16), time: 9.1s, loss: 0.905\n",
      "    Training Set - accuracy: 0.69, precision: 0.46, recall: 0.49, f1-score: 0.47,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.34, recall: 0.37, f1-score: 0.31,\n",
      "(Epoch 17), time: 9.1s, loss: 0.887\n",
      "    Training Set - accuracy: 0.76, precision: 0.83, recall: 0.62, f1-score: 0.63,\n",
      "    Validation Set - accuracy: 0.47, precision: 0.54, recall: 0.45, f1-score: 0.46,\n",
      "(Epoch 18), time: 9.1s, loss: 0.925\n",
      "    Training Set - accuracy: 0.78, precision: 0.78, recall: 0.69, f1-score: 0.71,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.50, recall: 0.41, f1-score: 0.36,\n",
      "(Epoch 19), time: 9.1s, loss: 0.910\n",
      "    Training Set - accuracy: 0.78, precision: 0.73, recall: 0.69, f1-score: 0.70,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.35, recall: 0.38, f1-score: 0.34,\n",
      "(Epoch 20), time: 9.1s, loss: 0.902\n",
      "    Training Set - accuracy: 0.76, precision: 0.71, recall: 0.67, f1-score: 0.69,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.27, recall: 0.35, f1-score: 0.28,\n",
      "(Epoch 21), time: 9.1s, loss: 0.814\n",
      "    Training Set - accuracy: 0.82, precision: 0.83, recall: 0.78, f1-score: 0.79,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.42, recall: 0.43, f1-score: 0.38,\n",
      "(Epoch 22), time: 9.1s, loss: 0.788\n",
      "    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.79, f1-score: 0.79,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.49, recall: 0.52, f1-score: 0.44,\n",
      "(Epoch 23), time: 9.1s, loss: 0.709\n",
      "    Training Set - accuracy: 0.87, precision: 0.86, recall: 0.86, f1-score: 0.86,\n",
      "    Validation Set - accuracy: 0.47, precision: 0.50, recall: 0.54, f1-score: 0.48,\n",
      "(Epoch 24), time: 9.1s, loss: 0.682\n",
      "    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.81, f1-score: 0.80,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.60, recall: 0.63, f1-score: 0.57,\n",
      "(Epoch 25), time: 9.1s, loss: 0.641\n",
      "    Training Set - accuracy: 0.88, precision: 0.86, recall: 0.87, f1-score: 0.86,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.38, recall: 0.39, f1-score: 0.38,\n",
      "(Epoch 26), time: 9.2s, loss: 0.607\n",
      "    Training Set - accuracy: 0.86, precision: 0.85, recall: 0.85, f1-score: 0.84,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.40, recall: 0.41, f1-score: 0.40,\n",
      "(Epoch 27), time: 9.1s, loss: 0.571\n",
      "    Training Set - accuracy: 0.89, precision: 0.88, recall: 0.87, f1-score: 0.87,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.48, recall: 0.48, f1-score: 0.47,\n",
      "(Epoch 28), time: 9.1s, loss: 0.546\n",
      "    Training Set - accuracy: 0.91, precision: 0.90, recall: 0.89, f1-score: 0.89,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.39, recall: 0.38, f1-score: 0.35,\n",
      "(Epoch 29), time: 9.1s, loss: 0.526\n",
      "    Training Set - accuracy: 0.92, precision: 0.92, recall: 0.89, f1-score: 0.90,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.46, recall: 0.49, f1-score: 0.45,\n",
      "(Epoch 30), time: 9.1s, loss: 0.504\n",
      "    Training Set - accuracy: 0.91, precision: 0.92, recall: 0.89, f1-score: 0.90,\n",
      "    Validation Set - accuracy: 0.55, precision: 0.53, recall: 0.56, f1-score: 0.53,\n",
      "(Epoch 31), time: 9.1s, loss: 0.489\n",
      "    Training Set - accuracy: 0.91, precision: 0.91, recall: 0.89, f1-score: 0.90,\n",
      "Confusion Matrix:\n",
      "[[7 3 4]\n",
      " [7 6 6]\n",
      " [2 2 3]]\n",
      "    Validation Set - accuracy: 0.40, precision: 0.40, recall: 0.41, f1-score: 0.39,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.1295877173542976,\n",
       "  1.1273719817399979,\n",
       "  1.1268511712551117,\n",
       "  1.124887079000473,\n",
       "  1.120848223567009,\n",
       "  1.1153303906321526,\n",
       "  1.1076990067958832,\n",
       "  1.1024466305971146,\n",
       "  1.089106909930706,\n",
       "  1.0906677693128586,\n",
       "  1.0913375169038773,\n",
       "  1.0770012326538563,\n",
       "  1.0709569789469242,\n",
       "  1.0649440288543701,\n",
       "  1.0545285604894161,\n",
       "  1.034836869686842,\n",
       "  1.022515494376421,\n",
       "  0.9983116127550602,\n",
       "  0.9832006767392159,\n",
       "  1.0010471381247044,\n",
       "  1.0138780772686005,\n",
       "  0.9809206649661064,\n",
       "  0.9553652666509151,\n",
       "  0.9312872663140297,\n",
       "  0.9159387163817883,\n",
       "  0.8806792236864567,\n",
       "  0.8545030504465103,\n",
       "  0.8353528715670109,\n",
       "  0.8315897472202778,\n",
       "  0.8039390929043293,\n",
       "  0.7733923085033894,\n",
       "  0.7478423789143562,\n",
       "  0.689947135746479,\n",
       "  0.6941433772444725,\n",
       "  0.7089653164148331,\n",
       "  0.653754087164998,\n",
       "  0.589550107717514,\n",
       "  0.5779519621282816,\n",
       "  0.5418468713760376,\n",
       "  0.5064200181514025,\n",
       "  0.49614852480590343],\n",
       " [1.1255304217338562,\n",
       "  1.1167023032903671,\n",
       "  1.10970588773489,\n",
       "  1.1021500378847122,\n",
       "  1.0901186093688011,\n",
       "  1.082912564277649,\n",
       "  1.0610359832644463,\n",
       "  1.039264339953661,\n",
       "  1.030928947031498,\n",
       "  1.0020114667713642,\n",
       "  0.9763657823204994,\n",
       "  0.948297955095768,\n",
       "  0.9286039099097252,\n",
       "  0.8983095586299896,\n",
       "  0.8714240603148937,\n",
       "  0.8383592367172241,\n",
       "  0.8111905232071877,\n",
       "  0.8015674278140068,\n",
       "  0.76417351141572,\n",
       "  0.7098459415137768,\n",
       "  0.650355314835906,\n",
       "  0.6107173915952444,\n",
       "  0.5601443033665419,\n",
       "  0.5191024299710989,\n",
       "  0.5008558761328459,\n",
       "  0.46817851811647415],\n",
       " [1.0999666899442673,\n",
       "  1.0931278243660927,\n",
       "  1.0801623277366161,\n",
       "  1.0618313327431679,\n",
       "  1.0471185073256493,\n",
       "  1.0321552492678165,\n",
       "  1.021254274994135,\n",
       "  1.0056300908327103,\n",
       "  0.9906017854809761,\n",
       "  0.9727866500616074,\n",
       "  0.9633142873644829,\n",
       "  0.9529412649571896,\n",
       "  0.9447227194905281,\n",
       "  0.9341713562607765,\n",
       "  0.9161859527230263,\n",
       "  0.8977288082242012,\n",
       "  0.8790025860071182,\n",
       "  0.8579804934561253,\n",
       "  0.8331949524581432,\n",
       "  0.8091721907258034,\n",
       "  0.7729845903813839,\n",
       "  0.7430573292076588,\n",
       "  0.7073334977030754,\n",
       "  0.6856196913868189,\n",
       "  0.6733102574944496,\n",
       "  0.7568710148334503,\n",
       "  0.6732655242085457,\n",
       "  0.666211923584342,\n",
       "  0.6177287716418505,\n",
       "  0.5818351488560438,\n",
       "  0.5569766331464052,\n",
       "  0.53533317707479,\n",
       "  0.519244521856308,\n",
       "  0.5060293544083834,\n",
       "  0.5236253701150417,\n",
       "  0.5021528955549002,\n",
       "  0.47846914641559124],\n",
       " [1.108768455684185,\n",
       "  1.1002722270786762,\n",
       "  1.0966245047748089,\n",
       "  1.0925384908914566,\n",
       "  1.0829748958349228,\n",
       "  1.0720667466521263,\n",
       "  1.0662939809262753,\n",
       "  1.0494373068213463,\n",
       "  1.0405406951904297,\n",
       "  1.0203767344355583,\n",
       "  1.0087951123714447,\n",
       "  0.9863297268748283,\n",
       "  0.9601857587695122,\n",
       "  0.9452037289738655,\n",
       "  0.9456206820905209,\n",
       "  0.9210170693695545,\n",
       "  0.9204907603561878,\n",
       "  0.884746178984642,\n",
       "  0.8930058106780052,\n",
       "  0.8524160757660866,\n",
       "  0.8246185444295406,\n",
       "  0.8060095310211182,\n",
       "  0.7675262875854969,\n",
       "  0.7509374432265759,\n",
       "  0.7055321410298347,\n",
       "  0.6755052283406258,\n",
       "  0.6376624628901482,\n",
       "  0.5924200434237719,\n",
       "  0.5716117229312658,\n",
       "  0.5366114489734173,\n",
       "  0.5066093076020479,\n",
       "  0.4984979871660471],\n",
       " [1.092797115445137,\n",
       "  1.0879093445837498,\n",
       "  1.0847054533660412,\n",
       "  1.0818292833864689,\n",
       "  1.0773782096803188,\n",
       "  1.0748420618474483,\n",
       "  1.065478466451168,\n",
       "  1.0585888847708702,\n",
       "  1.0579520910978317,\n",
       "  1.0367474034428596,\n",
       "  1.0261922106146812,\n",
       "  1.016372136771679,\n",
       "  1.0094193927943707,\n",
       "  0.9873018115758896,\n",
       "  0.9605824612081051,\n",
       "  0.9448641389608383,\n",
       "  0.904879730194807,\n",
       "  0.8869948871433735,\n",
       "  0.9245993867516518,\n",
       "  0.9103205017745495,\n",
       "  0.9017536528408527,\n",
       "  0.8137729428708553,\n",
       "  0.7876322977244854,\n",
       "  0.7092504389584064,\n",
       "  0.6817021295428276,\n",
       "  0.641000296920538,\n",
       "  0.607367143034935,\n",
       "  0.5714009162038565,\n",
       "  0.5456921607255936,\n",
       "  0.5260806791484356,\n",
       "  0.5036541372537613,\n",
       "  0.48855045810341835]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = [10,20]\n",
    "num_classes = len(splits)+1\n",
    "\n",
    "dataset = YouTubeDataset(splits)\n",
    "model = RobertaWav2VecClassifier(num_classes)\n",
    "train_model_cv5(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - T001: 0.00040268898010253906 seconds.\n",
      "1 - T003: 0.0006885528564453125 seconds.\n",
      "2 - T004: 0.0002930164337158203 seconds.\n",
      "3 - T006: 0.00023746490478515625 seconds.\n",
      "4 - T007: 0.0002677440643310547 seconds.\n",
      "5 - T009: 0.00022935867309570312 seconds.\n",
      "6 - T011: 0.0002467632293701172 seconds.\n",
      "7 - T013: 0.0002090930938720703 seconds.\n",
      "8 - T015: 0.0002536773681640625 seconds.\n",
      "9 - T016: 0.00021839141845703125 seconds.\n",
      "10 - T017: 0.0002696514129638672 seconds.\n",
      "11 - T018: 0.0002193450927734375 seconds.\n",
      "12 - T020: 0.0002453327178955078 seconds.\n",
      "13 - T021: 0.00021576881408691406 seconds.\n",
      "14 - T022: 0.00025010108947753906 seconds.\n",
      "15 - T023: 0.00022482872009277344 seconds.\n",
      "16 - T024: 0.0002605915069580078 seconds.\n",
      "17 - T027: 0.00022673606872558594 seconds.\n",
      "18 - T028: 0.00015997886657714844 seconds.\n",
      "19 - T031: 0.00017881393432617188 seconds.\n",
      "20 - T033: 0.0001633167266845703 seconds.\n",
      "21 - T034: 0.0001575946807861328 seconds.\n",
      "22 - T035: 0.0001678466796875 seconds.\n",
      "23 - T036: 0.00014328956604003906 seconds.\n",
      "24 - T037: 0.0001647472381591797 seconds.\n",
      "25 - T038: 0.00014352798461914062 seconds.\n",
      "26 - T039: 0.0001609325408935547 seconds.\n",
      "27 - T040: 0.0001614093780517578 seconds.\n",
      "28 - T041: 0.00016379356384277344 seconds.\n",
      "29 - T042: 0.0001418590545654297 seconds.\n",
      "30 - T043: 0.00016045570373535156 seconds.\n",
      "31 - T044: 0.0001475811004638672 seconds.\n",
      "32 - T045: 0.00017905235290527344 seconds.\n",
      "33 - T046: 0.00014591217041015625 seconds.\n",
      "34 - T047: 0.00015974044799804688 seconds.\n",
      "35 - T049: 0.00014472007751464844 seconds.\n",
      "36 - T050: 0.0001590251922607422 seconds.\n",
      "37 - T051: 0.0001461505889892578 seconds.\n",
      "38 - T052: 0.0001595020294189453 seconds.\n",
      "39 - T053: 0.00014781951904296875 seconds.\n",
      "40 - T055: 0.0001628398895263672 seconds.\n",
      "41 - T056: 0.00014591217041015625 seconds.\n",
      "42 - T060: 0.0001628398895263672 seconds.\n",
      "43 - T061: 0.00014281272888183594 seconds.\n",
      "44 - T062: 0.00016236305236816406 seconds.\n",
      "45 - T063: 0.0001678466796875 seconds.\n",
      "46 - T064: 0.00017023086547851562 seconds.\n",
      "47 - T065: 0.0001480579376220703 seconds.\n",
      "48 - T067: 0.00016307830810546875 seconds.\n",
      "49 - T069: 9.655952453613281e-05 seconds.\n",
      "50 - T070: 0.00011324882507324219 seconds.\n",
      "51 - T072: 0.00010251998901367188 seconds.\n",
      "52 - T073: 0.00011205673217773438 seconds.\n",
      "53 - T074: 0.00010061264038085938 seconds.\n",
      "54 - T075: 0.00011014938354492188 seconds.\n",
      "55 - T077: 0.00010466575622558594 seconds.\n",
      "56 - S001: 0.00011301040649414062 seconds.\n",
      "57 - S002: 0.00010156631469726562 seconds.\n",
      "58 - S003: 0.00010991096496582031 seconds.\n",
      "59 - S004: 0.00011920928955078125 seconds.\n",
      "60 - S005: 0.00011038780212402344 seconds.\n",
      "61 - S006: 0.00010085105895996094 seconds.\n",
      "62 - S007: 0.00012183189392089844 seconds.\n",
      "63 - S009: 0.00011444091796875 seconds.\n",
      "64 - S010: 0.00011396408081054688 seconds.\n",
      "65 - S013: 0.00010395050048828125 seconds.\n",
      "66 - S014: 0.00010585784912109375 seconds.\n",
      "67 - S016: 9.560585021972656e-05 seconds.\n",
      "68 - S017: 0.00010800361633300781 seconds.\n",
      "69 - S018: 0.00010061264038085938 seconds.\n",
      "70 - S019: 0.00011348724365234375 seconds.\n",
      "71 - S020: 0.00010704994201660156 seconds.\n",
      "72 - S021: 0.00011658668518066406 seconds.\n",
      "73 - S022: 9.894371032714844e-05 seconds.\n",
      "74 - S023: 0.00010991096496582031 seconds.\n",
      "75 - S024: 9.989738464355469e-05 seconds.\n",
      "76 - S025: 0.00011515617370605469 seconds.\n",
      "77 - S026: 0.00010085105895996094 seconds.\n",
      "78 - S027: 0.00010728836059570312 seconds.\n",
      "79 - S028: 0.00010132789611816406 seconds.\n",
      "80 - S029: 0.00010919570922851562 seconds.\n",
      "81 - S030: 0.000110626220703125 seconds.\n",
      "82 - S034: 0.00012087821960449219 seconds.\n",
      "83 - S035: 0.0001010894775390625 seconds.\n",
      "84 - S036: 0.000110626220703125 seconds.\n",
      "85 - S038: 0.00010800361633300781 seconds.\n",
      "86 - S039: 0.0001125335693359375 seconds.\n",
      "87 - S043: 0.00010037422180175781 seconds.\n",
      "88 - S044: 0.00011610984802246094 seconds.\n",
      "89 - S047: 0.00010013580322265625 seconds.\n",
      "90 - S048: 0.0001068115234375 seconds.\n",
      "91 - S049: 9.846687316894531e-05 seconds.\n",
      "92 - S050: 0.00010776519775390625 seconds.\n",
      "93 - S051: 9.918212890625e-05 seconds.\n",
      "94 - S052: 0.00010895729064941406 seconds.\n",
      "95 - S055: 0.00010704994201660156 seconds.\n",
      "96 - S057: 8.440017700195312e-05 seconds.\n",
      "97 - S058: 7.081031799316406e-05 seconds.\n",
      "98 - S059: 7.462501525878906e-05 seconds.\n",
      "99 - S061: 7.534027099609375e-05 seconds.\n",
      "100 - S064: 7.963180541992188e-05 seconds.\n",
      "101 - S065: 7.05718994140625e-05 seconds.\n",
      "102 - S067: 7.796287536621094e-05 seconds.\n",
      "103 - S069: 6.866455078125e-05 seconds.\n",
      "104 - S071: 8.440017700195312e-05 seconds.\n",
      "105 - S072: 6.890296936035156e-05 seconds.\n",
      "106 - S073: 7.128715515136719e-05 seconds.\n",
      "107 - S074: 7.319450378417969e-05 seconds.\n",
      "108 - S076: 8.511543273925781e-05 seconds.\n",
      "109 - MI0002: 7.295608520507812e-05 seconds.\n",
      "110 - MI0003: 8.177757263183594e-05 seconds.\n",
      "111 - MI0004: 7.271766662597656e-05 seconds.\n",
      "112 - MI0021: 7.700920104980469e-05 seconds.\n",
      "113 - MI0022: 7.2479248046875e-05 seconds.\n",
      "114 - MI0023: 7.62939453125e-05 seconds.\n",
      "115 - MI0024: 6.890296936035156e-05 seconds.\n",
      "116 - MI0025: 7.43865966796875e-05 seconds.\n",
      "117 - MI0026: 7.939338684082031e-05 seconds.\n",
      "118 - MI0027: 7.772445678710938e-05 seconds.\n",
      "119 - MI0028: 6.890296936035156e-05 seconds.\n",
      "120 - MI0029: 7.343292236328125e-05 seconds.\n",
      "121 - MI0030: 6.67572021484375e-05 seconds.\n",
      "122 - MI0031: 7.390975952148438e-05 seconds.\n",
      "123 - MI0034: 7.295608520507812e-05 seconds.\n",
      "124 - MI0035: 7.510185241699219e-05 seconds.\n",
      "125 - MI0036: 8.7738037109375e-05 seconds.\n",
      "126 - MI0037: 9.322166442871094e-05 seconds.\n",
      "127 - MI0038: 8.821487426757812e-05 seconds.\n",
      "128 - MI0039: 0.00010061264038085938 seconds.\n",
      "129 - MI0040: 8.702278137207031e-05 seconds.\n",
      "130 - MI0041: 9.179115295410156e-05 seconds.\n",
      "131 - MI0042: 6.842613220214844e-05 seconds.\n",
      "132 - MI0043: 7.367134094238281e-05 seconds.\n",
      "133 - MI0046: 7.05718994140625e-05 seconds.\n",
      "134 - MI0047: 7.605552673339844e-05 seconds.\n",
      "135 - MI0048: 6.699562072753906e-05 seconds.\n",
      "136 - MI0049: 7.486343383789062e-05 seconds.\n",
      "137 - MI0050: 7.104873657226562e-05 seconds.\n",
      "138 - MI0051: 7.319450378417969e-05 seconds.\n",
      "139 - MI0052: 6.985664367675781e-05 seconds.\n",
      "140 - MI0053: 7.772445678710938e-05 seconds.\n",
      "141 - MI0054: 7.486343383789062e-05 seconds.\n",
      "142 - MI0057: 8.416175842285156e-05 seconds.\n",
      "143 - MI0058: 6.961822509765625e-05 seconds.\n",
      "144 - MI0059: 7.748603820800781e-05 seconds.\n",
      "145 - MI0060: 6.747245788574219e-05 seconds.\n",
      "146 - MI0061: 7.295608520507812e-05 seconds.\n",
      "147 - MI0062: 7.200241088867188e-05 seconds.\n",
      "148 - MI0064: 8.511543273925781e-05 seconds.\n",
      "149 - MI0066: 7.009506225585938e-05 seconds.\n",
      "150 - MI0067: 8.368492126464844e-05 seconds.\n",
      "151 - MI0068: 0.0001010894775390625 seconds.\n",
      "152 - MI0069: 9.608268737792969e-05 seconds.\n",
      "153 - MI0070: 8.559226989746094e-05 seconds.\n",
      "154 - MI0071: 9.560585021972656e-05 seconds.\n",
      "155 - MI0072: 8.797645568847656e-05 seconds.\n",
      "156 - MI0073: 0.00010776519775390625 seconds.\n",
      "157 - MI0074: 7.009506225585938e-05 seconds.\n",
      "158 - MI0075: 7.796287536621094e-05 seconds.\n",
      "159 - MI0077: 6.985664367675781e-05 seconds.\n",
      "160 - MI0078: 7.557868957519531e-05 seconds.\n",
      "161 - MI0079: 7.295608520507812e-05 seconds.\n",
      "162 - MI0080: 7.724761962890625e-05 seconds.\n",
      "163 - MI0081: 6.771087646484375e-05 seconds.\n",
      "164 - MI0082: 7.605552673339844e-05 seconds.\n",
      "165 - MI0083: 6.818771362304688e-05 seconds.\n",
      "166 - MI0084: 7.82012939453125e-05 seconds.\n",
      "167 - MI0085: 6.747245788574219e-05 seconds.\n",
      "168 - MI0086: 7.462501525878906e-05 seconds.\n",
      "169 - MI0087: 7.200241088867188e-05 seconds.\n",
      "170 - MI0088: 8.130073547363281e-05 seconds.\n",
      "171 - MI0089: 6.699562072753906e-05 seconds.\n",
      "172 - MI0090: 7.843971252441406e-05 seconds.\n",
      "173 - MI0092: 7.009506225585938e-05 seconds.\n",
      "174 - MI0093: 7.534027099609375e-05 seconds.\n",
      "175 - MI0095: 7.176399230957031e-05 seconds.\n",
      "176 - MI0096: 0.00012731552124023438 seconds.\n",
      "177 - MI0097: 8.845329284667969e-05 seconds.\n",
      "178 - MI0098: 9.584426879882812e-05 seconds.\n",
      "179 - MI0099: 8.487701416015625e-05 seconds.\n",
      "180 - MI0101: 9.918212890625e-05 seconds.\n",
      "181 - MI0102: 9.894371032714844e-05 seconds.\n",
      "182 - MI0104: 7.724761962890625e-05 seconds.\n",
      "183 - MI0105: 6.866455078125e-05 seconds.\n",
      "184 - MI0106: 8.177757263183594e-05 seconds.\n",
      "185 - MI0107: 7.343292236328125e-05 seconds.\n",
      "186 - MI0109: 8.106231689453125e-05 seconds.\n",
      "187 - MI0110: 7.081031799316406e-05 seconds.\n",
      "188 - MI0111: 7.677078247070312e-05 seconds.\n",
      "189 - MI0112: 6.818771362304688e-05 seconds.\n",
      "190 - MI0113: 7.700920104980469e-05 seconds.\n",
      "191 - MI0114: 6.651878356933594e-05 seconds.\n",
      "192 - MI0117: 7.963180541992188e-05 seconds.\n",
      "193 - MI0118: 6.890296936035156e-05 seconds.\n",
      "194 - MI0119: 7.867813110351562e-05 seconds.\n",
      "195 - MI0120: 7.104873657226562e-05 seconds.\n",
      "196 - MI0121: 7.510185241699219e-05 seconds.\n",
      "197 - MI0122: 6.961822509765625e-05 seconds.\n",
      "198 - MI0123: 7.653236389160156e-05 seconds.\n",
      "199 - MI0124: 6.985664367675781e-05 seconds.\n",
      "200 - MI0125: 7.653236389160156e-05 seconds.\n",
      "201 - MI0127: 9.322166442871094e-05 seconds.\n",
      "202 - MI0128: 9.679794311523438e-05 seconds.\n",
      "203 - MI0129: 8.821487426757812e-05 seconds.\n",
      "204 - MI0130: 9.846687316894531e-05 seconds.\n",
      "205 - MI0132: 8.702278137207031e-05 seconds.\n",
      "206 - MI0133: 0.00010585784912109375 seconds.\n",
      "207 - MI0134: 7.033348083496094e-05 seconds.\n",
      "208 - MI0135: 7.700920104980469e-05 seconds.\n",
      "209 - MI0136: 7.033348083496094e-05 seconds.\n",
      "210 - MI0138: 7.915496826171875e-05 seconds.\n",
      "Fold 1 (val 0 - 42)\n",
      "(Epoch 0), time: 8.9s, loss: 0.746\n",
      "    Training Set - accuracy: 0.47, precision: 0.23, recall: 0.50, f1-score: 0.32,\n",
      "    Validation Set - accuracy: 0.82, precision: 0.41, recall: 0.50, f1-score: 0.45,\n",
      "(Epoch 1), time: 8.9s, loss: 0.728\n",
      "    Training Set - accuracy: 0.47, precision: 0.23, recall: 0.50, f1-score: 0.32,\n",
      "    Validation Set - accuracy: 0.82, precision: 0.41, recall: 0.50, f1-score: 0.45,\n",
      "(Epoch 2), time: 9.0s, loss: 0.721\n",
      "    Training Set - accuracy: 0.47, precision: 0.23, recall: 0.50, f1-score: 0.32,\n",
      "    Validation Set - accuracy: 0.82, precision: 0.41, recall: 0.50, f1-score: 0.45,\n",
      "(Epoch 3), time: 9.0s, loss: 0.713\n",
      "    Training Set - accuracy: 0.47, precision: 0.23, recall: 0.50, f1-score: 0.32,\n",
      "    Validation Set - accuracy: 0.82, precision: 0.41, recall: 0.50, f1-score: 0.45,\n",
      "(Epoch 4), time: 9.0s, loss: 0.700\n",
      "    Training Set - accuracy: 0.47, precision: 0.23, recall: 0.50, f1-score: 0.32,\n",
      "    Validation Set - accuracy: 0.82, precision: 0.41, recall: 0.50, f1-score: 0.45,\n",
      "(Epoch 5), time: 9.0s, loss: 0.691\n",
      "    Training Set - accuracy: 0.49, precision: 0.74, recall: 0.52, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.68, precision: 0.47, recall: 0.47, f1-score: 0.47,\n",
      "(Epoch 6), time: 9.0s, loss: 0.683\n",
      "    Training Set - accuracy: 0.54, precision: 0.69, recall: 0.57, f1-score: 0.47,\n",
      "    Validation Set - accuracy: 0.65, precision: 0.46, recall: 0.45, f1-score: 0.45,\n",
      "(Epoch 7), time: 9.1s, loss: 0.673\n",
      "    Training Set - accuracy: 0.56, precision: 0.62, recall: 0.58, f1-score: 0.53,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.38, recall: 0.35, f1-score: 0.37,\n",
      "(Epoch 8), time: 9.1s, loss: 0.658\n",
      "    Training Set - accuracy: 0.58, precision: 0.62, recall: 0.59, f1-score: 0.57,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.39, recall: 0.38, f1-score: 0.38,\n",
      "(Epoch 9), time: 9.1s, loss: 0.636\n",
      "    Training Set - accuracy: 0.62, precision: 0.66, recall: 0.63, f1-score: 0.61,\n",
      "    Validation Set - accuracy: 0.55, precision: 0.43, recall: 0.39, f1-score: 0.40,\n",
      "(Epoch 10), time: 9.1s, loss: 0.640\n",
      "    Training Set - accuracy: 0.59, precision: 0.63, recall: 0.60, f1-score: 0.57,\n",
      "    Validation Set - accuracy: 0.47, precision: 0.37, recall: 0.29, f1-score: 0.32,\n",
      "(Epoch 11), time: 9.1s, loss: 0.687\n",
      "    Training Set - accuracy: 0.55, precision: 0.58, recall: 0.56, f1-score: 0.53,\n",
      "    Validation Set - accuracy: 0.68, precision: 0.40, recall: 0.41, f1-score: 0.40,\n",
      "(Epoch 12), time: 9.1s, loss: 0.668\n",
      "    Training Set - accuracy: 0.57, precision: 0.61, recall: 0.59, f1-score: 0.56,\n",
      "    Validation Set - accuracy: 0.55, precision: 0.57, recall: 0.61, f1-score: 0.51,\n",
      "(Epoch 13), time: 9.1s, loss: 0.697\n",
      "    Training Set - accuracy: 0.51, precision: 0.52, recall: 0.52, f1-score: 0.51,\n",
      "    Validation Set - accuracy: 0.65, precision: 0.54, recall: 0.56, f1-score: 0.53,\n",
      "(Epoch 14), time: 9.1s, loss: 0.671\n",
      "    Training Set - accuracy: 0.61, precision: 0.64, recall: 0.62, f1-score: 0.60,\n",
      "    Validation Set - accuracy: 0.53, precision: 0.46, recall: 0.43, f1-score: 0.42,\n",
      "(Epoch 15), time: 9.1s, loss: 0.639\n",
      "    Training Set - accuracy: 0.68, precision: 0.68, recall: 0.68, f1-score: 0.67,\n",
      "    Validation Set - accuracy: 0.53, precision: 0.53, recall: 0.54, f1-score: 0.47,\n",
      "(Epoch 16), time: 9.1s, loss: 0.611\n",
      "    Training Set - accuracy: 0.76, precision: 0.76, recall: 0.75, f1-score: 0.75,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.39, recall: 0.31, f1-score: 0.29,\n",
      "(Epoch 17), time: 9.1s, loss: 0.565\n",
      "    Training Set - accuracy: 0.76, precision: 0.79, recall: 0.75, f1-score: 0.75,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.36, recall: 0.25, f1-score: 0.27,\n",
      "(Epoch 18), time: 9.1s, loss: 0.560\n",
      "    Training Set - accuracy: 0.75, precision: 0.79, recall: 0.74, f1-score: 0.74,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.39, recall: 0.34, f1-score: 0.26,\n",
      "(Epoch 19), time: 9.1s, loss: 0.563\n",
      "    Training Set - accuracy: 0.74, precision: 0.76, recall: 0.73, f1-score: 0.73,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.36, recall: 0.28, f1-score: 0.25,\n",
      "(Epoch 20), time: 9.1s, loss: 0.590\n",
      "    Training Set - accuracy: 0.72, precision: 0.74, recall: 0.71, f1-score: 0.71,\n",
      "    Validation Set - accuracy: 0.33, precision: 0.39, recall: 0.31, f1-score: 0.29,\n",
      "(Epoch 21), time: 9.1s, loss: 0.571\n",
      "    Training Set - accuracy: 0.71, precision: 0.78, recall: 0.70, f1-score: 0.68,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.40, recall: 0.35, f1-score: 0.28,\n",
      "(Epoch 22), time: 9.1s, loss: 0.561\n",
      "    Training Set - accuracy: 0.76, precision: 0.78, recall: 0.75, f1-score: 0.75,\n",
      "    Validation Set - accuracy: 0.28, precision: 0.33, recall: 0.22, f1-score: 0.24,\n",
      "(Epoch 23), time: 9.1s, loss: 0.531\n",
      "    Training Set - accuracy: 0.73, precision: 0.79, recall: 0.72, f1-score: 0.71,\n",
      "    Validation Set - accuracy: 0.30, precision: 0.47, recall: 0.46, f1-score: 0.30,\n",
      "(Epoch 24), time: 9.1s, loss: 0.504\n",
      "    Training Set - accuracy: 0.78, precision: 0.84, recall: 0.77, f1-score: 0.77,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.50, recall: 0.49, f1-score: 0.34,\n",
      "(Epoch 25), time: 9.1s, loss: 0.486\n",
      "    Training Set - accuracy: 0.79, precision: 0.84, recall: 0.77, f1-score: 0.77,\n",
      "Confusion Matrix:\n",
      "[[12 21]\n",
      " [ 2  5]]\n",
      "    Validation Set - accuracy: 0.42, precision: 0.52, recall: 0.54, f1-score: 0.41,\n",
      "Fold 2 (val 43 - 84)\n",
      "(Epoch 0), time: 9.1s, loss: 0.698\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 1), time: 9.1s, loss: 0.692\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 2), time: 9.1s, loss: 0.690\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 3), time: 9.1s, loss: 0.685\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 4), time: 9.1s, loss: 0.680\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 5), time: 9.1s, loss: 0.670\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 6), time: 9.1s, loss: 0.667\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 7), time: 9.1s, loss: 0.636\n",
      "    Training Set - accuracy: 0.51, precision: 0.26, recall: 0.50, f1-score: 0.34,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.35, recall: 0.50, f1-score: 0.41,\n",
      "(Epoch 8), time: 9.1s, loss: 0.622\n",
      "    Training Set - accuracy: 0.51, precision: 0.51, recall: 0.50, f1-score: 0.35,\n",
      "    Validation Set - accuracy: 0.65, precision: 0.34, recall: 0.46, f1-score: 0.39,\n",
      "(Epoch 9), time: 9.1s, loss: 0.603\n",
      "    Training Set - accuracy: 0.53, precision: 0.76, recall: 0.51, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.68, precision: 0.35, recall: 0.48, f1-score: 0.40,\n",
      "(Epoch 10), time: 9.1s, loss: 0.575\n",
      "    Training Set - accuracy: 0.60, precision: 0.67, recall: 0.59, f1-score: 0.54,\n",
      "    Validation Set - accuracy: 0.68, precision: 0.52, recall: 0.51, f1-score: 0.47,\n",
      "(Epoch 11), time: 9.1s, loss: 0.560\n",
      "    Training Set - accuracy: 0.68, precision: 0.70, recall: 0.67, f1-score: 0.66,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.45, recall: 0.46, f1-score: 0.45,\n",
      "(Epoch 12), time: 9.1s, loss: 0.573\n",
      "    Training Set - accuracy: 0.72, precision: 0.76, recall: 0.71, f1-score: 0.70,\n",
      "    Validation Set - accuracy: 0.60, precision: 0.42, recall: 0.45, f1-score: 0.43,\n",
      "(Epoch 13), time: 9.1s, loss: 0.532\n",
      "    Training Set - accuracy: 0.74, precision: 0.78, recall: 0.74, f1-score: 0.73,\n",
      "    Validation Set - accuracy: 0.55, precision: 0.43, recall: 0.44, f1-score: 0.44,\n",
      "(Epoch 14), time: 9.1s, loss: 0.579\n",
      "    Training Set - accuracy: 0.74, precision: 0.77, recall: 0.73, f1-score: 0.73,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.41, recall: 0.40, f1-score: 0.39,\n",
      "(Epoch 15), time: 9.1s, loss: 0.591\n",
      "    Training Set - accuracy: 0.71, precision: 0.71, recall: 0.71, f1-score: 0.71,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.31, recall: 0.36, f1-score: 0.33,\n",
      "(Epoch 16), time: 9.1s, loss: 0.528\n",
      "    Training Set - accuracy: 0.79, precision: 0.80, recall: 0.78, f1-score: 0.78,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.45, recall: 0.46, f1-score: 0.45,\n",
      "(Epoch 17), time: 9.1s, loss: 0.515\n",
      "    Training Set - accuracy: 0.83, precision: 0.84, recall: 0.83, f1-score: 0.83,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.54, recall: 0.54, f1-score: 0.54,\n",
      "(Epoch 18), time: 9.1s, loss: 0.506\n",
      "    Training Set - accuracy: 0.83, precision: 0.84, recall: 0.83, f1-score: 0.83,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.40, f1-score: 0.40,\n",
      "(Epoch 19), time: 9.1s, loss: 0.501\n",
      "    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.82, f1-score: 0.82,\n",
      "    Validation Set - accuracy: 0.55, precision: 0.43, recall: 0.44, f1-score: 0.44,\n",
      "(Epoch 20), time: 9.1s, loss: 0.482\n",
      "    Training Set - accuracy: 0.86, precision: 0.86, recall: 0.86, f1-score: 0.86,\n",
      "Confusion Matrix:\n",
      "[[18 10]\n",
      " [ 9  3]]\n",
      "    Validation Set - accuracy: 0.53, precision: 0.45, recall: 0.45, f1-score: 0.45,\n",
      "Fold 3 (val 85 - 126)\n",
      "(Epoch 0), time: 9.1s, loss: 0.735\n",
      "    Training Set - accuracy: 0.41, precision: 0.20, recall: 0.50, f1-score: 0.29,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.31, recall: 0.50, f1-score: 0.38,\n",
      "(Epoch 1), time: 9.1s, loss: 0.727\n",
      "    Training Set - accuracy: 0.41, precision: 0.20, recall: 0.50, f1-score: 0.29,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.31, recall: 0.50, f1-score: 0.38,\n",
      "(Epoch 2), time: 9.1s, loss: 0.718\n",
      "    Training Set - accuracy: 0.41, precision: 0.20, recall: 0.50, f1-score: 0.29,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.31, recall: 0.50, f1-score: 0.38,\n",
      "(Epoch 3), time: 9.1s, loss: 0.705\n",
      "    Training Set - accuracy: 0.41, precision: 0.45, recall: 0.50, f1-score: 0.31,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.31, recall: 0.50, f1-score: 0.38,\n",
      "(Epoch 4), time: 9.1s, loss: 0.696\n",
      "    Training Set - accuracy: 0.45, precision: 0.62, recall: 0.53, f1-score: 0.38,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.74, recall: 0.61, f1-score: 0.60,\n",
      "(Epoch 5), time: 9.1s, loss: 0.696\n",
      "    Training Set - accuracy: 0.48, precision: 0.53, recall: 0.52, f1-score: 0.47,\n",
      "    Validation Set - accuracy: 0.70, precision: 0.69, recall: 0.71, f1-score: 0.69,\n",
      "(Epoch 6), time: 9.1s, loss: 0.666\n",
      "    Training Set - accuracy: 0.59, precision: 0.63, recall: 0.62, f1-score: 0.59,\n",
      "    Validation Set - accuracy: 0.72, precision: 0.71, recall: 0.69, f1-score: 0.69,\n",
      "(Epoch 7), time: 9.1s, loss: 0.683\n",
      "    Training Set - accuracy: 0.60, precision: 0.63, recall: 0.62, f1-score: 0.60,\n",
      "    Validation Set - accuracy: 0.68, precision: 0.66, recall: 0.67, f1-score: 0.66,\n",
      "(Epoch 8), time: 9.1s, loss: 0.641\n",
      "    Training Set - accuracy: 0.73, precision: 0.74, recall: 0.74, f1-score: 0.73,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.57, recall: 0.58, f1-score: 0.57,\n",
      "(Epoch 9), time: 9.1s, loss: 0.635\n",
      "    Training Set - accuracy: 0.72, precision: 0.71, recall: 0.71, f1-score: 0.71,\n",
      "    Validation Set - accuracy: 0.65, precision: 0.63, recall: 0.64, f1-score: 0.64,\n",
      "(Epoch 10), time: 9.1s, loss: 0.636\n",
      "    Training Set - accuracy: 0.72, precision: 0.71, recall: 0.72, f1-score: 0.71,\n",
      "    Validation Set - accuracy: 0.55, precision: 0.59, recall: 0.59, f1-score: 0.55,\n",
      "(Epoch 11), time: 9.1s, loss: 0.596\n",
      "    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.80, f1-score: 0.81,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.59, recall: 0.59, f1-score: 0.57,\n",
      "(Epoch 12), time: 9.1s, loss: 0.623\n",
      "    Training Set - accuracy: 0.79, precision: 0.80, recall: 0.76, f1-score: 0.77,\n",
      "    Validation Set - accuracy: 0.65, precision: 0.76, recall: 0.72, f1-score: 0.65,\n",
      "(Epoch 13), time: 9.1s, loss: 0.577\n",
      "    Training Set - accuracy: 0.84, precision: 0.84, recall: 0.82, f1-score: 0.83,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.56, recall: 0.57, f1-score: 0.56,\n",
      "(Epoch 14), time: 9.1s, loss: 0.518\n",
      "    Training Set - accuracy: 0.91, precision: 0.91, recall: 0.90, f1-score: 0.90,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.59, recall: 0.59, f1-score: 0.57,\n",
      "(Epoch 15), time: 9.1s, loss: 0.491\n",
      "    Training Set - accuracy: 0.91, precision: 0.91, recall: 0.90, f1-score: 0.91,\n",
      "Confusion Matrix:\n",
      "[[ 9  6]\n",
      " [10 15]]\n",
      "    Validation Set - accuracy: 0.60, precision: 0.59, recall: 0.60, f1-score: 0.59,\n",
      "Fold 4 (val 127 - 168)\n",
      "(Epoch 0), time: 9.1s, loss: 0.698\n",
      "    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n",
      "(Epoch 1), time: 9.1s, loss: 0.692\n",
      "    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n",
      "(Epoch 2), time: 9.1s, loss: 0.692\n",
      "    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n",
      "(Epoch 3), time: 9.1s, loss: 0.690\n",
      "    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n",
      "(Epoch 4), time: 9.1s, loss: 0.686\n",
      "    Training Set - accuracy: 0.60, precision: 0.79, recall: 0.53, f1-score: 0.43,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.74, recall: 0.55, f1-score: 0.40,\n",
      "(Epoch 5), time: 9.1s, loss: 0.684\n",
      "    Training Set - accuracy: 0.58, precision: 0.56, recall: 0.52, f1-score: 0.47,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.61, recall: 0.54, f1-score: 0.43,\n",
      "(Epoch 6), time: 9.1s, loss: 0.680\n",
      "    Training Set - accuracy: 0.57, precision: 0.52, recall: 0.51, f1-score: 0.44,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.57, recall: 0.54, f1-score: 0.45,\n",
      "(Epoch 7), time: 9.1s, loss: 0.686\n",
      "    Training Set - accuracy: 0.50, precision: 0.37, recall: 0.44, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n",
      "(Epoch 8), time: 9.1s, loss: 0.674\n",
      "    Training Set - accuracy: 0.58, precision: 0.56, recall: 0.52, f1-score: 0.44,\n",
      "    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n",
      "(Epoch 9), time: 9.1s, loss: 0.657\n",
      "    Training Set - accuracy: 0.62, precision: 0.64, recall: 0.57, f1-score: 0.54,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.53, recall: 0.53, f1-score: 0.48,\n",
      "(Epoch 10), time: 9.1s, loss: 0.656\n",
      "    Training Set - accuracy: 0.62, precision: 0.62, recall: 0.58, f1-score: 0.57,\n",
      "    Validation Set - accuracy: 0.55, precision: 0.67, recall: 0.59, f1-score: 0.51,\n",
      "(Epoch 11), time: 9.1s, loss: 0.656\n",
      "    Training Set - accuracy: 0.66, precision: 0.68, recall: 0.61, f1-score: 0.60,\n",
      "    Validation Set - accuracy: 0.60, precision: 0.70, recall: 0.63, f1-score: 0.57,\n",
      "(Epoch 12), time: 9.1s, loss: 0.623\n",
      "    Training Set - accuracy: 0.76, precision: 0.75, recall: 0.75, f1-score: 0.75,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.72, recall: 0.65, f1-score: 0.61,\n",
      "(Epoch 13), time: 9.1s, loss: 0.610\n",
      "    Training Set - accuracy: 0.76, precision: 0.76, recall: 0.76, f1-score: 0.76,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.62, recall: 0.61, f1-score: 0.61,\n",
      "(Epoch 14), time: 9.1s, loss: 0.602\n",
      "    Training Set - accuracy: 0.74, precision: 0.77, recall: 0.77, f1-score: 0.74,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.57, recall: 0.55, f1-score: 0.54,\n",
      "(Epoch 15), time: 9.1s, loss: 0.564\n",
      "    Training Set - accuracy: 0.74, precision: 0.79, recall: 0.77, f1-score: 0.74,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.70, recall: 0.59, f1-score: 0.54,\n",
      "(Epoch 16), time: 9.1s, loss: 0.525\n",
      "    Training Set - accuracy: 0.78, precision: 0.81, recall: 0.80, f1-score: 0.78,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.64, recall: 0.60, f1-score: 0.58,\n",
      "(Epoch 17), time: 9.0s, loss: 0.499\n",
      "    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.82, f1-score: 0.81,\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [14  8]]\n",
      "    Validation Set - accuracy: 0.57, precision: 0.62, recall: 0.60, f1-score: 0.56,\n",
      "Fold 5 (val 169 - 210)\n",
      "(Epoch 0), time: 9.0s, loss: 0.694\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 1), time: 9.0s, loss: 0.693\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 2), time: 9.0s, loss: 0.693\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 3), time: 9.0s, loss: 0.692\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 4), time: 9.1s, loss: 0.692\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 5), time: 9.1s, loss: 0.691\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 6), time: 9.1s, loss: 0.691\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 7), time: 9.0s, loss: 0.688\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 8), time: 9.1s, loss: 0.688\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 9), time: 9.1s, loss: 0.688\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 10), time: 9.0s, loss: 0.688\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 11), time: 9.0s, loss: 0.689\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 12), time: 9.0s, loss: 0.690\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 13), time: 9.0s, loss: 0.686\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 14), time: 9.0s, loss: 0.677\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 15), time: 9.0s, loss: 0.654\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 16), time: 9.0s, loss: 0.659\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 17), time: 9.0s, loss: 0.642\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 18), time: 9.0s, loss: 0.638\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 19), time: 9.0s, loss: 0.665\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 20), time: 9.0s, loss: 0.657\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 21), time: 9.0s, loss: 0.663\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 22), time: 9.0s, loss: 0.644\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 23), time: 9.1s, loss: 0.635\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 24), time: 9.0s, loss: 0.627\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 25), time: 9.0s, loss: 0.620\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 26), time: 9.1s, loss: 0.616\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 27), time: 9.0s, loss: 0.608\n",
      "    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 28), time: 9.0s, loss: 0.603\n",
      "    Training Set - accuracy: 0.62, precision: 0.81, recall: 0.52, f1-score: 0.42,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n",
      "(Epoch 29), time: 9.1s, loss: 0.598\n",
      "    Training Set - accuracy: 0.71, precision: 0.84, recall: 0.63, f1-score: 0.61,\n",
      "    Validation Set - accuracy: 0.38, precision: 0.47, recall: 0.49, f1-score: 0.34,\n",
      "(Epoch 30), time: 9.0s, loss: 0.594\n",
      "    Training Set - accuracy: 0.76, precision: 0.86, recall: 0.70, f1-score: 0.70,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.48, recall: 0.49, f1-score: 0.39,\n",
      "(Epoch 31), time: 9.0s, loss: 0.589\n",
      "    Training Set - accuracy: 0.78, precision: 0.87, recall: 0.73, f1-score: 0.73,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.51, recall: 0.51, f1-score: 0.42,\n",
      "(Epoch 32), time: 9.0s, loss: 0.585\n",
      "    Training Set - accuracy: 0.76, precision: 0.82, recall: 0.71, f1-score: 0.72,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.51, recall: 0.51, f1-score: 0.42,\n",
      "(Epoch 33), time: 9.1s, loss: 0.578\n",
      "    Training Set - accuracy: 0.78, precision: 0.82, recall: 0.73, f1-score: 0.74,\n",
      "    Validation Set - accuracy: 0.42, precision: 0.47, recall: 0.48, f1-score: 0.42,\n",
      "(Epoch 34), time: 9.1s, loss: 0.557\n",
      "    Training Set - accuracy: 0.82, precision: 0.85, recall: 0.78, f1-score: 0.80,\n",
      "    Validation Set - accuracy: 0.35, precision: 0.38, recall: 0.38, f1-score: 0.35,\n",
      "(Epoch 35), time: 9.0s, loss: 0.490\n",
      "    Training Set - accuracy: 0.84, precision: 0.83, recall: 0.84, f1-score: 0.83,\n",
      "Confusion Matrix:\n",
      "[[ 4 10]\n",
      " [ 8 18]]\n",
      "    Validation Set - accuracy: 0.55, precision: 0.49, recall: 0.49, f1-score: 0.49,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.7464047539979219,\n",
       "  0.7282361555844545,\n",
       "  0.7211398221552372,\n",
       "  0.7127474062144756,\n",
       "  0.6998687721788883,\n",
       "  0.6914235651493073,\n",
       "  0.6826597899198532,\n",
       "  0.6733386367559433,\n",
       "  0.6579379066824913,\n",
       "  0.6358466930687428,\n",
       "  0.6398527063429356,\n",
       "  0.6865830272436142,\n",
       "  0.6680218912661076,\n",
       "  0.6974000334739685,\n",
       "  0.6706861667335033,\n",
       "  0.6388220228254795,\n",
       "  0.6111139599233866,\n",
       "  0.5651876330375671,\n",
       "  0.5597941409796476,\n",
       "  0.5628745798021555,\n",
       "  0.5896639954298735,\n",
       "  0.5712015479803085,\n",
       "  0.5613272916525602,\n",
       "  0.5308751985430717,\n",
       "  0.5039190147072077,\n",
       "  0.48604968190193176],\n",
       " [0.698051143437624,\n",
       "  0.6921644918620586,\n",
       "  0.6900754831731319,\n",
       "  0.6851878836750984,\n",
       "  0.6797115318477154,\n",
       "  0.6697666682302952,\n",
       "  0.6665422096848488,\n",
       "  0.6361907552927732,\n",
       "  0.6220542211085558,\n",
       "  0.6034978069365025,\n",
       "  0.5748561136424541,\n",
       "  0.5601145159453154,\n",
       "  0.573477054014802,\n",
       "  0.5323265343904495,\n",
       "  0.5793350785970688,\n",
       "  0.5909880064427853,\n",
       "  0.5283417478203773,\n",
       "  0.5145398955792189,\n",
       "  0.5055317282676697,\n",
       "  0.5005722418427467,\n",
       "  0.4824784081429243],\n",
       " [0.7345037758350372,\n",
       "  0.7274535037577152,\n",
       "  0.7175552509725094,\n",
       "  0.7045535556972027,\n",
       "  0.6963031142950058,\n",
       "  0.6956558488309383,\n",
       "  0.6657366193830967,\n",
       "  0.6828793697059155,\n",
       "  0.6413946151733398,\n",
       "  0.6353548243641853,\n",
       "  0.6363191902637482,\n",
       "  0.5958796553313732,\n",
       "  0.6234215274453163,\n",
       "  0.5771639384329319,\n",
       "  0.5180174745619297,\n",
       "  0.4912040699273348],\n",
       " [0.6983263455331326,\n",
       "  0.691716056317091,\n",
       "  0.6919385381042957,\n",
       "  0.6902674920856953,\n",
       "  0.6864608861505985,\n",
       "  0.6844574734568596,\n",
       "  0.6801517307758331,\n",
       "  0.686328012496233,\n",
       "  0.6737486943602562,\n",
       "  0.6567740254104137,\n",
       "  0.6560819521546364,\n",
       "  0.6563254483044147,\n",
       "  0.6231426447629929,\n",
       "  0.6099903881549835,\n",
       "  0.6023285910487175,\n",
       "  0.5637151151895523,\n",
       "  0.5251467432826757,\n",
       "  0.49938999861478806],\n",
       " [0.6943616308271885,\n",
       "  0.693103801459074,\n",
       "  0.6925348713994026,\n",
       "  0.692028634250164,\n",
       "  0.6917465291917324,\n",
       "  0.6910705864429474,\n",
       "  0.6907148994505405,\n",
       "  0.6881951242685318,\n",
       "  0.6876760087907314,\n",
       "  0.688029196113348,\n",
       "  0.6877423077821732,\n",
       "  0.6894313879311085,\n",
       "  0.6896402761340141,\n",
       "  0.6862590089440346,\n",
       "  0.6774394921958447,\n",
       "  0.653775081038475,\n",
       "  0.6592578552663326,\n",
       "  0.6422967445105314,\n",
       "  0.6384684219956398,\n",
       "  0.6645044237375259,\n",
       "  0.6571259293705225,\n",
       "  0.6633554175496101,\n",
       "  0.6440852545201778,\n",
       "  0.6353730410337448,\n",
       "  0.626826798543334,\n",
       "  0.6200364790856838,\n",
       "  0.6158115137368441,\n",
       "  0.6079283133149147,\n",
       "  0.6030769664794207,\n",
       "  0.5984517596662045,\n",
       "  0.5942803807556629,\n",
       "  0.5892973486334085,\n",
       "  0.5849741064012051,\n",
       "  0.577639676630497,\n",
       "  0.5574714336544275,\n",
       "  0.49023161455988884]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = [10]\n",
    "num_classes = len(splits)+1\n",
    "\n",
    "dataset = YouTubeDataset(splits)\n",
    "model = RobertaWav2VecClassifier(num_classes)\n",
    "train_model_cv5(model, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('misinfoengage')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d3b53da97a4d5230a2d6a56d4dc057ea257b55156c1302576dbafca9234f1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
