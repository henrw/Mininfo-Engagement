{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [10,20,30]\n",
    "num_classes = len(splits)+1\n",
    "from dataset import YouTubeDataset\n",
    "dataset = YouTubeDataset(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "from inference import eval, get_scores\n",
    "from torch.nn.functional import cross_entropy\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "def train_model(dataset, train_val_split = None):\n",
    "    if not train_val_split:\n",
    "      train_ids = [i for i in range(len(dataset))]\n",
    "      val_ids = None\n",
    "    else:\n",
    "      train_ids, val_ids = train_val_split\n",
    "    \n",
    "    X_train, y_train = [dataset.text[i] for i in train_ids], dataset.label[train_ids].numpy()\n",
    "    X_val, y_val = [dataset.text[i] for i in val_ids], dataset.label[val_ids].numpy()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2)\n",
    "    X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "    X_val = vectorizer.transform(X_val)\n",
    "    \n",
    "    # Fit the model\n",
    "    base_clf=LinearSVC(penalty='l2', loss = 'squared_hinge', dual=False)\n",
    "    model = OneVsRestClassifier(base_clf)\n",
    "    model.fit(X_train, y_train)\n",
    "    # Compute the R^2 score on the training and testing set\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    train_accuracy, train_precision, train_recall, train_f1 = get_scores(y_train, y_pred, num_classes) # This is an aggregated result due to GPU size limit\n",
    "    print(f\"    Training Set - accuracy: {train_accuracy:.2f}, precision: {train_precision:.2f}, recall: {train_recall:.2f}, f1-score: {train_f1:.2f},\")\n",
    "    val_accuracy, val_precision, val_recall, val_f1 = get_scores(y_val, y_pred_val, num_classes)\n",
    "    print(f\"    Validation Set - accuracy: {val_accuracy:.2f}, precision: {val_precision:.2f}, recall: {val_recall:.2f}, f1-score: {val_f1:.2f},\")\n",
    "    return val_accuracy, val_precision, val_recall, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def train_model_cv5(dataset):\n",
    "    kf = KFold(n_splits=5)\n",
    "    cnt = 1\n",
    "    val_accuracy_ls, val_precision_ls, val_recall_ls, val_f1_ls = [], [], [], []\n",
    "    for train_index, val_index in kf.split(dataset):\n",
    "        print(\"Fold \"+str(cnt)+\" (val\", val_index[0],\"-\",str(val_index[-1])+\")\")\n",
    "        val_accuracy, val_precision, val_recall, val_f1 = train_model(dataset=dataset, train_val_split=(train_index, val_index))\n",
    "        val_accuracy_ls.append(val_accuracy)\n",
    "        val_precision_ls.append(val_precision)\n",
    "        val_recall_ls.append(val_recall)\n",
    "        val_f1_ls.append(val_f1)\n",
    "        cnt += 1\n",
    "\n",
    "    print(f\"{np.array(val_accuracy_ls).mean(): .3f} {np.array(val_precision_ls).mean(): .3f} {np.array(val_recall_ls).mean(): .3f} {np.array(val_f1_ls).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (val 0 - 42)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.79, precision: 0.32, recall: 0.32, f1-score: 0.32,\n",
      "Fold 2 (val 43 - 84)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.67, precision: 0.29, recall: 0.31, f1-score: 0.30,\n",
      "Fold 3 (val 85 - 126)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.40, precision: 0.21, recall: 0.27, f1-score: 0.20,\n",
      "Fold 4 (val 127 - 168)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.25, recall: 0.31, f1-score: 0.26,\n",
      "Fold 5 (val 169 - 210)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.48, precision: 0.26, recall: 0.30, f1-score: 0.25,\n",
      " 0.568  0.266  0.299 0.267\n"
     ]
    }
   ],
   "source": [
    "train_model_cv5(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (val 0 - 42)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.81, precision: 0.60, recall: 0.60, f1-score: 0.60,\n",
      "Fold 2 (val 43 - 84)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.67, precision: 0.39, recall: 0.41, f1-score: 0.40,\n",
      "Fold 3 (val 85 - 126)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.43, precision: 0.63, recall: 0.39, f1-score: 0.33,\n",
      "Fold 4 (val 127 - 168)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.50, precision: 0.33, recall: 0.41, f1-score: 0.35,\n",
      "Fold 5 (val 169 - 210)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.48, precision: 0.38, recall: 0.39, f1-score: 0.35,\n",
      " 0.577  0.466  0.439 0.405\n"
     ]
    }
   ],
   "source": [
    "splits = [10,20]\n",
    "num_classes = len(splits)+1\n",
    "from dataset import YouTubeDataset\n",
    "dataset = YouTubeDataset(splits)\n",
    "train_model_cv5(dataset)\n",
    "# 0.577  0.466  0.439 0.405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (val 0 - 42)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.72, precision: 0.60, recall: 0.66, f1-score: 0.61,\n",
      "Fold 2 (val 43 - 84)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.64, precision: 0.57, recall: 0.57, f1-score: 0.57,\n",
      "Fold 3 (val 85 - 126)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.43, precision: 0.44, recall: 0.44, f1-score: 0.43,\n",
      "Fold 4 (val 127 - 168)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.57, precision: 0.62, recall: 0.59, f1-score: 0.56,\n",
      "Fold 5 (val 169 - 210)\n",
      "    Training Set - accuracy: 1.00, precision: 1.00, recall: 1.00, f1-score: 1.00,\n",
      "    Validation Set - accuracy: 0.62, precision: 0.61, recall: 0.62, f1-score: 0.61,\n",
      " 0.597  0.572  0.578 0.555\n"
     ]
    }
   ],
   "source": [
    "splits = [10]\n",
    "num_classes = len(splits)+1\n",
    "from dataset import YouTubeDataset\n",
    "dataset = YouTubeDataset(splits)\n",
    "train_model_cv5(dataset)\n",
    "# 0.577  0.466  0.439 0.405"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
