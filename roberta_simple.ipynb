{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19785,"status":"ok","timestamp":1661367265489,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"qXW99pdz2Q5u","outputId":"660b6b3c-5c5b-467f-fc58-8e0c76fadfb9"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/Users/henrywu/Documents/UM/3_2022_Summer/Misinfo Engagement/FusionModel/roberta_simple.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/henrywu/Documents/UM/3_2022_Summer/Misinfo%20Engagement/FusionModel/roberta_simple.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/henrywu/Documents/UM/3_2022_Summer/Misinfo%20Engagement/FusionModel/roberta_simple.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m\"\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/henrywu/Documents/UM/3_2022_Summer/Misinfo%20Engagement/FusionModel/roberta_simple.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mcd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdrive/MyDrive/FusionModel\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd drive/MyDrive/FusionModel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125717,"status":"ok","timestamp":1661367400391,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"6ecJw0ec2uRE","outputId":"6bc9c559-72f6-4dce-c127-1146ed10530d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 1.1 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 62.4 MB/s \n","\u001b[?25hCollecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 64.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (4.1.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n","Installing collected packages: torch, torchvision, torchtext, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","Successfully installed torch-1.9.0 torchaudio-0.9.0 torchtext-0.10.0 torchvision-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.8.0\n","  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 14.2 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 62.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (1.21.6)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2022.6.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 65.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.0) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=53eb607a6f37a3199ee79cb0ef6708fbc5ba66fdc4a5073ce3eaa0f5004a4be9\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.8.0\n"]}],"source":["!pip install torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 torchtext==0.10.0\n","!pip install transformers==4.8.0"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["device = 'cpu'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["b5e5d60429374b84b6ba3f5feca9c349","63811ff2b84f4fd8b2dbe65a43908231","fbeaf94af2694ce1ba95b4e6ce2af82d","e648d9b7adbb4111b4e103672d324a8b","5d2a6f4a866f48acaf8adcf9fc8874ce","e9909dd8b95a423cb0f0c283ffb08cce","3433096f2bd24645a7ab2c380ec2f367","2cce8b4228224c5e983a9c9e96e549e1","397be3e582ba4c3a9f77129a40e25594","5a0cce9096ef4d35867d3a06df436bfa","7936416e704343aa8b94e7f6f7985bbf","396d7c58e4e64320b335f7bf0a7c6013","e4feaeed11564983bb2579ade267b7ef","13ede9e8a2b547b3a1983309294071fe","3569571613594c8990135993d20d2cda","2f3b0d19361d4fa08c72cafdff7b0536","ae231613e2e34bd7bcaacdc530d3fa9a","b1a410a1bad64d20a25fc0586ff80861","3dea95408a084988ac9f070af86d18c4","e35eb37541f241848d29f5da7f6bb8c3","10e69a8b31d5498fa6b0a4054421e15a","5ecdb2e6621e4853bbfd563585e37c65","b08a0a63c71149c1b111b97b0ef364c3","c57ffbdb9c0a4d039583b81ce5c2afd8","975c6d4639c9460284165dfa2c77bb18","910e90f190584d58b5005ea4e25e3281","c47de754a9a0477dbdfb7c008c2127a5","803f54f4bb6c474a80dabdb79d2ba93c","d6acf6d28f0d4a528eaaf5efe20fadcf","7e5ace079b8647188e2f79d554f4ab26","7ebff393e19a4bd89c699e9add1c6413","4ebc623079e945c2855425e00dcff89c","b98ca0171e394889ae447699f04cd288"]},"executionInfo":{"elapsed":110315,"status":"ok","timestamp":1661367510693,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"qJhlLvN_2Q5w","outputId":"2eafbc0f-5e94-48d3-a58f-1ef33f9b65b1"},"outputs":[],"source":["from dataset import YouTubeDataset\n","dataset = YouTubeDataset()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["2e488f88cc3544ae96801fbe44f7980e","f234245a76e74911a2a2b1042ad5418c","42cbf08bafe74f67829f6c7d9c3268bd","027004400f834cc684be4d2d3d96e98d","69dd00814443469a84946f7f78a6a353","32a56ce59456423c9c01ae00c63385ba","3bb5ec8b303e4b5582f2330311a3ed76","c1a2ae63450a4839abe714d4b23b10f1","1c7f833b66754199bc33293c936e9faa","ced32e6d5d61434c953df26272395a7e","90ff98d4bd5340e39b704441d7aa6e08","4bc95ac17f0d4689899a45123d6562cf","b5ae3b9233c04828ae141480d03ac039","c7034eb174024547a4b659da5ea3bedb","55e349ee0d9b42dca2052264a2836743","124d533bfc5f4f0d8d550a7980e81d2b","c2b4f12ed35a45ec9527d485b52f95ed","500abca2f821455ba58779544055cb02","794f5db50e6b442885d91e6aeb007d37","84db0e522404415e9fc7fd995d581238","6047bd0aa0ba4ca0be4ae504718de138","d35aba4e5e6f45ea9018b5688050f685"]},"executionInfo":{"elapsed":19103,"status":"ok","timestamp":1661367529794,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"8p-lRwh82Q5w","outputId":"9c36cec6-c5c1-4fcb-97e7-3e589832ad02"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Initialization success if you see a tensor: tensor([[ 0.1730,  0.2517,  0.0699, -0.0068]], grad_fn=<AddmmBackward0>).\n"]}],"source":["from model import SimpleBert\n","model = SimpleBert()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22947,"status":"ok","timestamp":1661367681202,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"uUElxqlG3odH","outputId":"dfa74a1c-55a0-4807-a1c7-92c3eaa92d8e"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","checkpoint = torch.load(\"checkpoints/epoch200.pt\",map_location=torch.device('cpu'))\n","model.load_state_dict(checkpoint['model_state_dict'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1661367529794,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"hFBPwWgpLOjG"},"outputs":[],"source":["# model.base.requires_grad = False"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1661367529795,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"Xcddavmj7N7S"},"outputs":[],"source":["loss_history = []"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":255282,"status":"aborted","timestamp":1661367529795,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"3FtOdoeaL1wS"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.45474138 0.85080645 2.39772727 4.79545455]\n"]}],"source":["from sklearn.utils.class_weight import compute_class_weight\n","import torch\n","class_weights = compute_class_weight(class_weight='balanced', classes=torch.unique(dataset.label).numpy(), y=dataset.label.numpy())\n","print(class_weights)\n","class_weights = torch.tensor(class_weights, dtype=torch.float, device=device)\n","loss_fn = torch.nn.NLLLoss(weight = class_weights)\n","# from torch.nn.functional import cross_entropy\n","# loss_fn = cross_entropy"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":255280,"status":"aborted","timestamp":1661367529796,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"ZvBMRR972Q5x"},"outputs":[],"source":["import torch\n","import math\n","import os\n","import time\n","import numpy as np\n","\n","def train_model(model, train_data, loss_fn, learning_rate, lr_decay, batch_size, num_epochs, test_data=None, loss_history=None, device='cpu', isCheckpoint=False, isVerbose=True):\n","    model = model.to(device)\n","    model.train()\n","\n","    optimizer = torch.optim.AdamW(\n","        filter(lambda p: p.requires_grad, model.parameters()), learning_rate\n","    )\n","    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n","        optimizer, lambda epoch: lr_decay ** epoch\n","    )\n","\n","    # sample minibatch data\n","    iter_per_epoch = math.ceil(len(dataset) // batch_size)\n","    \n","    for i in range(num_epochs):\n","        start_t = time.time()\n","        local_hist = []\n","        correct_cnt = 0\n","        for j in range(iter_per_epoch):\n","            tokens, labels = dataset[j * batch_size: (j + 1) * batch_size]\n","            N = labels.shape[0]\n","            tokens = tokens.to(device)\n","            labels = labels.to(device)\n","            # groundTruth = torch.zeros((N,4),dtype=torch.long,device=device)\n","            # groundTruth[torch.arange(N),labels] = 1\n","            optimizer.zero_grad()\n","\n","            digits = model(tokens)\n","            # print(groundTruth,digits)\n","            probs = torch.nn.LogSoftmax(dim=1)(digits)\n","            loss = loss_fn(probs,labels)\n","            loss.backward()\n","\n","            local_hist.append(loss.item())\n","            optimizer.step()\n","\n","        end_t = time.time()\n","\n","        if loss_history:\n","            loss_mean = np.array(local_hist).mean()\n","            loss_history.append(loss_mean)\n","            \n","        if isVerbose:\n","            print(\n","                f\"(Epoch {i} / {num_epochs}), time: {end_t - start_t:.1f}s\"\n","            )\n","            print(f\"/tTrain - loss: {loss_mean:.3f}, accuracy: {correct_cnt/len(train_data):.2f}, precision: {}\")\n","        if i%100 == 0 and isCheckpoint:\n","          dir = \"checkpoints\"\n","          if not os.path.exists(dir):\n","            os.mkdir(dir)\n","          file = f\"epoch{i}.pt\"\n","          path = dir+'/'+file\n","          torch.save({\n","                      'epoch': i,\n","                      'model_state_dict': model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss_mean,\n","                      }, path)\n","\n","        lr_scheduler.step()\n","        \n","train_model(model, dataset, loss_fn, learning_rate=1e-6, lr_decay=0.99, batch_size=10, num_epochs=500, loss_history = loss_history, isCheckpoint = True, isVerbose = True)"]},{"cell_type":"markdown","metadata":{},"source":["## 5-fold CV"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["TRAIN: [ 43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n","  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n","  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n","  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n"," 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n"," 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n"," 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\n"," 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n"," 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n"," 205 206 207 208 209 210] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n","{'input_ids': tensor([[    0,  2387,   766,  ...,     1,     1,     1],\n","        [    0,  2847, 12402,  ...,     5,  2476,     2],\n","        [    0,  2847,    11,  ...,     6,    65,     2],\n","        ...,\n","        [    0, 30086,     6,  ...,   614,     6,     2],\n","        [    0,   894,  8473,  ...,   127,   809,     2],\n","        [    0, 13755,    47,  ...,  8859,    11,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]])} tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1,\n","        2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 3, 3,\n","        1, 2, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 3, 1, 0, 1, 1, 0, 3, 1, 0, 1,\n","        2, 1, 0, 0, 1, 2, 2, 1, 0, 1, 0, 3, 0, 2, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2,\n","        0, 3, 0, 0, 0, 0, 0, 2, 2, 1, 3, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 1, 1, 0,\n","        2, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0, 0, 2,\n","        1, 1, 1, 0, 1, 0, 0, 3, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 2, 0, 0])\n","TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  85  86  87  88  89  90  91  92  93  94  95\n","  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n"," 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n"," 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n"," 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n"," 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n"," 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n"," 204 205 206 207 208 209 210] TEST: [43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66\n"," 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84]\n","{'input_ids': tensor([[    0,  1185,   114,  ...,    53,    24,     2],\n","        [    0,  1779,    10,  ...,  3373,    19,     2],\n","        [    0, 44966,    26,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 30086,     6,  ...,   614,     6,     2],\n","        [    0,   894,  8473,  ...,   127,   809,     2],\n","        [    0, 13755,    47,  ...,  8859,    11,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]])} tensor([0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3,\n","        3, 1, 2, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 3, 1, 0, 1, 1, 0, 3, 1, 0,\n","        1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 1, 0, 3, 0, 2, 0, 1, 0, 2, 1, 1, 1, 1, 0,\n","        2, 0, 3, 0, 0, 0, 0, 0, 2, 2, 1, 3, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 1, 1,\n","        0, 2, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0, 0,\n","        2, 1, 1, 1, 0, 1, 0, 0, 3, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 2, 0,\n","        0])\n","TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n","  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n","  72  73  74  75  76  77  78  79  80  81  82  83  84 127 128 129 130 131\n"," 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n"," 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n"," 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n"," 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n"," 204 205 206 207 208 209 210] TEST: [ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n"," 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n"," 121 122 123 124 125 126]\n","{'input_ids': tensor([[    0,  1185,   114,  ...,    53,    24,     2],\n","        [    0,  1779,    10,  ...,  3373,    19,     2],\n","        [    0, 44966,    26,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 30086,     6,  ...,   614,     6,     2],\n","        [    0,   894,  8473,  ...,   127,   809,     2],\n","        [    0, 13755,    47,  ...,  8859,    11,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]])} tensor([0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 2, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 2, 0, 1, 0, 2, 1, 1, 1, 1, 0,\n","        2, 0, 3, 0, 0, 0, 0, 0, 2, 2, 1, 3, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 1, 1,\n","        0, 2, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0, 0,\n","        2, 1, 1, 1, 0, 1, 0, 0, 3, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 2, 0,\n","        0])\n","TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n","  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n","  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n","  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n"," 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n"," 126 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n"," 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n"," 204 205 206 207 208 209 210] TEST: [127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n"," 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n"," 163 164 165 166 167 168]\n","{'input_ids': tensor([[    0,  1185,   114,  ...,    53,    24,     2],\n","        [    0,  1779,    10,  ...,  3373,    19,     2],\n","        [    0, 44966,    26,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 30086,     6,  ...,   614,     6,     2],\n","        [    0,   894,  8473,  ...,   127,   809,     2],\n","        [    0, 13755,    47,  ...,  8859,    11,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]])} tensor([0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 2, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 3, 3, 1, 2, 0, 0, 0,\n","        0, 1, 2, 1, 0, 1, 1, 1, 0, 3, 1, 0, 1, 1, 0, 3, 1, 0, 1, 2, 1, 0, 0, 1,\n","        2, 2, 1, 0, 1, 0, 3, 0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0, 0,\n","        2, 1, 1, 1, 0, 1, 0, 0, 3, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 2, 0,\n","        0])\n","TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n","  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n","  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n","  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n"," 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n"," 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n"," 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n"," 162 163 164 165 166 167 168] TEST: [169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n"," 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n"," 205 206 207 208 209 210]\n","{'input_ids': tensor([[    0,  1185,   114,  ...,    53,    24,     2],\n","        [    0,  1779,    10,  ...,  3373,    19,     2],\n","        [    0, 44966,    26,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 30086,     6,  ...,     6,     8,     2],\n","        [    0,  7939,   108,  ...,     9,     5,     2],\n","        [    0, 30086,  1669,  ...,   114,    47,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]])} tensor([0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 2, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 3, 3, 1, 2, 0, 0, 0,\n","        0, 1, 2, 1, 0, 1, 1, 1, 0, 3, 1, 0, 1, 1, 0, 3, 1, 0, 1, 2, 1, 0, 0, 1,\n","        2, 2, 1, 0, 1, 0, 3, 0, 2, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2, 0, 3, 0, 0, 0,\n","        0, 0, 2, 2, 1, 3, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 1, 1, 0, 2, 0, 1, 0, 2,\n","        0])\n"]}],"source":["from sklearn.model_selection import KFold\n","import torch\n","\n","def train_model_cv5(model, dataset):\n","    epochs = 500\n","    kf = KFold(n_splits=5)\n","    for train_index, test_index in kf.split(dataset):\n","        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","        X_train, y_train = dataset[train_index]\n","        y_val, y_val = dataset[test_index]\n","        print(X_train, y_train)\n","        \n","train_model_cv5(model, dataset)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11028,"status":"ok","timestamp":1661368291671,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"BZazCaiIwQNM","outputId":"517e1a00-7e5c-4cb5-a609-c1da00200c52"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0])\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/henrywu/Documents/UM/3_2022_Summer/Misinfo Engagement/FusionModel/roberta_simple.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/henrywu/Documents/UM/3_2022_Summer/Misinfo%20Engagement/FusionModel/roberta_simple.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39meval\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/henrywu/Documents/UM/3_2022_Summer/Misinfo%20Engagement/FusionModel/roberta_simple.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39meval\u001b[39;49m(model,dataset)\n","File \u001b[0;32m~/Documents/UM/3_2022_Summer/Misinfo Engagement/FusionModel/train.py:21\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model, dataset, labels)\u001b[0m\n\u001b[1;32m     19\u001b[0m y_true\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m tokens\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m y_preds\u001b[39m.\u001b[39mappend(model(tokens)\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     22\u001b[0m y_trues\u001b[39m.\u001b[39mappend(y_true\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(y_true)\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/Documents/UM/3_2022_Summer/Misinfo Engagement/FusionModel/model.py:24\u001b[0m, in \u001b[0;36mSimpleBert.forward\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(token, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     23\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(token, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, max_length \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtoken)\n\u001b[1;32m     25\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(output[\u001b[39m'\u001b[39m\u001b[39mpooler_output\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     26\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(output)\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:848\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    841\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    842\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    843\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    846\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    847\u001b[0m )\n\u001b[0;32m--> 848\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    849\u001b[0m     embedding_output,\n\u001b[1;32m    850\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    851\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    852\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    853\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    854\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    855\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    856\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    857\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    858\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    859\u001b[0m )\n\u001b[1;32m    860\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    861\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    515\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    516\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    517\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    525\u001b[0m         hidden_states,\n\u001b[1;32m    526\u001b[0m         attention_mask,\n\u001b[1;32m    527\u001b[0m         layer_head_mask,\n\u001b[1;32m    528\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    529\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    530\u001b[0m         past_key_value,\n\u001b[1;32m    531\u001b[0m         output_attentions,\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:451\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    448\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    449\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 451\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    452\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    453\u001b[0m )\n\u001b[1;32m    454\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    456\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/transformers/pytorch_utils.py:243\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:463\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 463\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    464\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    465\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:361\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 361\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    362\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    363\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/opt/anaconda3/envs/misinfoengage/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from train import eval\n","\n","eval(model,dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1661367529982,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"sraz31H1wSih"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"roberta_simple.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"54d3b53da97a4d5230a2d6a56d4dc057ea257b55156c1302576dbafca9234f1a"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"027004400f834cc684be4d2d3d96e98d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ced32e6d5d61434c953df26272395a7e","placeholder":"​","style":"IPY_MODEL_90ff98d4bd5340e39b704441d7aa6e08","value":" 481/481 [00:00&lt;00:00, 6.18kB/s]"}},"10e69a8b31d5498fa6b0a4054421e15a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"124d533bfc5f4f0d8d550a7980e81d2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13ede9e8a2b547b3a1983309294071fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dea95408a084988ac9f070af86d18c4","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e35eb37541f241848d29f5da7f6bb8c3","value":456318}},"1c7f833b66754199bc33293c936e9faa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cce8b4228224c5e983a9c9e96e549e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e488f88cc3544ae96801fbe44f7980e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f234245a76e74911a2a2b1042ad5418c","IPY_MODEL_42cbf08bafe74f67829f6c7d9c3268bd","IPY_MODEL_027004400f834cc684be4d2d3d96e98d"],"layout":"IPY_MODEL_69dd00814443469a84946f7f78a6a353"}},"2f3b0d19361d4fa08c72cafdff7b0536":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32a56ce59456423c9c01ae00c63385ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3433096f2bd24645a7ab2c380ec2f367":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3569571613594c8990135993d20d2cda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10e69a8b31d5498fa6b0a4054421e15a","placeholder":"​","style":"IPY_MODEL_5ecdb2e6621e4853bbfd563585e37c65","value":" 456k/456k [00:00&lt;00:00, 568kB/s]"}},"396d7c58e4e64320b335f7bf0a7c6013":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4feaeed11564983bb2579ade267b7ef","IPY_MODEL_13ede9e8a2b547b3a1983309294071fe","IPY_MODEL_3569571613594c8990135993d20d2cda"],"layout":"IPY_MODEL_2f3b0d19361d4fa08c72cafdff7b0536"}},"397be3e582ba4c3a9f77129a40e25594":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3bb5ec8b303e4b5582f2330311a3ed76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3dea95408a084988ac9f070af86d18c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cbf08bafe74f67829f6c7d9c3268bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1a2ae63450a4839abe714d4b23b10f1","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c7f833b66754199bc33293c936e9faa","value":481}},"4bc95ac17f0d4689899a45123d6562cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5ae3b9233c04828ae141480d03ac039","IPY_MODEL_c7034eb174024547a4b659da5ea3bedb","IPY_MODEL_55e349ee0d9b42dca2052264a2836743"],"layout":"IPY_MODEL_124d533bfc5f4f0d8d550a7980e81d2b"}},"4ebc623079e945c2855425e00dcff89c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"500abca2f821455ba58779544055cb02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55e349ee0d9b42dca2052264a2836743":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6047bd0aa0ba4ca0be4ae504718de138","placeholder":"​","style":"IPY_MODEL_d35aba4e5e6f45ea9018b5688050f685","value":" 501M/501M [00:11&lt;00:00, 63.0MB/s]"}},"5a0cce9096ef4d35867d3a06df436bfa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d2a6f4a866f48acaf8adcf9fc8874ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ecdb2e6621e4853bbfd563585e37c65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6047bd0aa0ba4ca0be4ae504718de138":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63811ff2b84f4fd8b2dbe65a43908231":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9909dd8b95a423cb0f0c283ffb08cce","placeholder":"​","style":"IPY_MODEL_3433096f2bd24645a7ab2c380ec2f367","value":"Downloading: 100%"}},"69dd00814443469a84946f7f78a6a353":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7936416e704343aa8b94e7f6f7985bbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"794f5db50e6b442885d91e6aeb007d37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e5ace079b8647188e2f79d554f4ab26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ebff393e19a4bd89c699e9add1c6413":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"803f54f4bb6c474a80dabdb79d2ba93c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84db0e522404415e9fc7fd995d581238":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90ff98d4bd5340e39b704441d7aa6e08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"910e90f190584d58b5005ea4e25e3281":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ebc623079e945c2855425e00dcff89c","placeholder":"​","style":"IPY_MODEL_b98ca0171e394889ae447699f04cd288","value":" 1.36M/1.36M [00:00&lt;00:00, 2.12MB/s]"}},"975c6d4639c9460284165dfa2c77bb18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e5ace079b8647188e2f79d554f4ab26","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ebff393e19a4bd89c699e9add1c6413","value":1355863}},"ae231613e2e34bd7bcaacdc530d3fa9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b08a0a63c71149c1b111b97b0ef364c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c57ffbdb9c0a4d039583b81ce5c2afd8","IPY_MODEL_975c6d4639c9460284165dfa2c77bb18","IPY_MODEL_910e90f190584d58b5005ea4e25e3281"],"layout":"IPY_MODEL_c47de754a9a0477dbdfb7c008c2127a5"}},"b1a410a1bad64d20a25fc0586ff80861":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5ae3b9233c04828ae141480d03ac039":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2b4f12ed35a45ec9527d485b52f95ed","placeholder":"​","style":"IPY_MODEL_500abca2f821455ba58779544055cb02","value":"Downloading: 100%"}},"b5e5d60429374b84b6ba3f5feca9c349":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63811ff2b84f4fd8b2dbe65a43908231","IPY_MODEL_fbeaf94af2694ce1ba95b4e6ce2af82d","IPY_MODEL_e648d9b7adbb4111b4e103672d324a8b"],"layout":"IPY_MODEL_5d2a6f4a866f48acaf8adcf9fc8874ce"}},"b98ca0171e394889ae447699f04cd288":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1a2ae63450a4839abe714d4b23b10f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2b4f12ed35a45ec9527d485b52f95ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c47de754a9a0477dbdfb7c008c2127a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c57ffbdb9c0a4d039583b81ce5c2afd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_803f54f4bb6c474a80dabdb79d2ba93c","placeholder":"​","style":"IPY_MODEL_d6acf6d28f0d4a528eaaf5efe20fadcf","value":"Downloading: 100%"}},"c7034eb174024547a4b659da5ea3bedb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_794f5db50e6b442885d91e6aeb007d37","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84db0e522404415e9fc7fd995d581238","value":501200538}},"ced32e6d5d61434c953df26272395a7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d35aba4e5e6f45ea9018b5688050f685":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6acf6d28f0d4a528eaaf5efe20fadcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e35eb37541f241848d29f5da7f6bb8c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4feaeed11564983bb2579ade267b7ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae231613e2e34bd7bcaacdc530d3fa9a","placeholder":"​","style":"IPY_MODEL_b1a410a1bad64d20a25fc0586ff80861","value":"Downloading: 100%"}},"e648d9b7adbb4111b4e103672d324a8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a0cce9096ef4d35867d3a06df436bfa","placeholder":"​","style":"IPY_MODEL_7936416e704343aa8b94e7f6f7985bbf","value":" 899k/899k [00:00&lt;00:00, 2.11MB/s]"}},"e9909dd8b95a423cb0f0c283ffb08cce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f234245a76e74911a2a2b1042ad5418c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32a56ce59456423c9c01ae00c63385ba","placeholder":"​","style":"IPY_MODEL_3bb5ec8b303e4b5582f2330311a3ed76","value":"Downloading: 100%"}},"fbeaf94af2694ce1ba95b4e6ce2af82d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cce8b4228224c5e983a9c9e96e549e1","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_397be3e582ba4c3a9f77129a40e25594","value":898823}}}}},"nbformat":4,"nbformat_minor":0}
