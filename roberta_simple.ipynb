{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1661792745469,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"qXW99pdz2Q5u","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"041d8501-b316-4c0f-d0e4-6a855cbea01d"},"outputs":[{"output_type":"display_data","data":{"application/javascript":["IPython.notebook.set_autosave_interval(60000)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Autosaving every 60 seconds\n"]}],"source":["%load_ext autoreload\n","%autosave 60\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E4dTicgPTOiv","executionInfo":{"status":"ok","timestamp":1661792764003,"user_tz":240,"elapsed":18540,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"}},"outputId":"54727d33-4de9-461a-b1d0-8a1efd6f5239"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/FusionModel\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd drive/MyDrive/FusionModel"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9343,"status":"ok","timestamp":1661792773343,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"6ecJw0ec2uRE","outputId":"48a117f4-de6c-477e-cded-71b8cb904ed9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.8.0\n","  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 13.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 60.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.8.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (21.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2.23.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.0) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2022.6.15)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=c5f065314494e24eaceb15e3f51ac9bb2bedbcadc0d93902709741dbacc37e44\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.8.0\n"]}],"source":["# !pip install torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 torchtext==0.10.0\n","!pip install transformers==4.8.0"]},{"cell_type":"code","source":["splits = [10,20,30]\n","num_classes = len(splits)+1"],"metadata":{"id":"iZyn4_broM2O","executionInfo":{"status":"ok","timestamp":1661792773343,"user_tz":240,"elapsed":5,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":110504,"status":"ok","timestamp":1661792883844,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"qJhlLvN_2Q5w","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cd66edbd6d7c44969ebc631c2fe4075c","d29370d62ac44f78a6e2cc0c5307636a","d8bde791f64642d78f93ba76192cc640","4e377b69b4344192bdbe40a3813d9659","b180502ed69d4e31978149c2b2206680","a379cefbaa9e4582a5e21cdbca56e069","cadd20b50c264e9fb5f8f916aea88dc9","ede1f07546fb4ac9ac31db1404713a56","7cf8b510edc04528a9ac37b4d3f81a95","e920714c7b204178aeed15281b1180e4","b5a86cc7ac68460b908b82e1445a1365","dce48ab6b0a64446a16e4eff5fe8b5fd","17a82e25a1874537a0db547e27c02ac5","5d13558b56ff4f01b16bc047d978f499","2fc52cf92ebc4924b2904a5d227263cb","51b8300f519d425189c627f766943b78","2b9bbc1c1a8245c4b38a8fbb3d586d49","27b7a726ff094e84a6041b8edb2fcfb3","1e81e61c715946f6ac3e7596ba44e55a","3f649d86e6954b8abc7cd84417a8cfed","e9d34d9823f646fc9e4c853d13b6787e","fbc68c3c07e64c169094d6550045da5c","c166ba293937447ba93630d8e6ce4251","afbc33ba959343b195e0723e3c25d517","25c514de3b6b4d51ae400df8df391f06","50e8236d9524479e91d020302a2e157c","7f86de4c995e4674abdaf9804a86a125","a0ad6a4d9d0f4853887f92ed645350ad","1883ab1778ec46e9abdf8c016d88f9a1","476d46c1da2647c3873d89a19ca9a717","df0175e9af754a6780b2c7a68940c893","05eda02912f54e24b4a2eccb1f5d1985","f510a7cee8f44d67b51baf234d583186"]},"outputId":"9b3d34ec-97a4-4308-cf3b-6b1cc3b96b30"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd66edbd6d7c44969ebc631c2fe4075c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce48ab6b0a64446a16e4eff5fe8b5fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c166ba293937447ba93630d8e6ce4251"}},"metadata":{}}],"source":["from dataset import YouTubeDataset\n","dataset = YouTubeDataset(splits)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["ce4cc25400bd41358ad23d6f7b02ed0b","ff2b5b2e574e49d78d2ef90430128e88","13887f55b442474ea6971d5733ae99bc","da8b5156c6f247829d3d96923b852b4e","33b1d8be2ace4bc1a9415d67614c19e7","24614414bec54f4a9e16da0b4a76e332","e378819f52434b8caf3345a8101ba426","e1a99603efc14990b44f0cef9784ac97","7524bcc23b384abea0b4158780bba922","f8f55d57435049b9ac2b3016a5dde46b","355f43e3996849189748e707897ba985","2d27cdc2976746699dc635008321c9d0","7a0050ddc85c42f6b6f1e3cb545f97bf","3efb47bc5f874b6593343d0a656f7363","0336d3e29a50406483ffb92365b60fb2","0d0a5b569f5543a3aad0885b7ffc23b6","69cdef023ca54eba8ba67a31781f7a10","05a8ce378d33400396944a18ca453dfc","9ab7f2eb1b8847ca9c73bd212e448496","3375bb1641e540598ccafb19a0a6c6f5","5ac6a517f1f14abd8f526c1554d26175","d97a8b732489475fbb6efa5382fc4bf8"]},"executionInfo":{"elapsed":17873,"status":"ok","timestamp":1661792901707,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"8p-lRwh82Q5w","outputId":"eb578f74-214a-43bf-97e1-e376f97c01f9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4cc25400bd41358ad23d6f7b02ed0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d27cdc2976746699dc635008321c9d0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Initialization success if you see a tensor: tensor([[ 0.0480, -0.1949,  0.2635,  0.1745]], grad_fn=<AddmmBackward0>).\n"]}],"source":["from model import SimpleBert\n","model = SimpleBert(num_classes)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"uUElxqlG3odH","executionInfo":{"status":"ok","timestamp":1661792901708,"user_tz":240,"elapsed":11,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"}}},"outputs":[],"source":["# import torch\n","# checkpoint = torch.load(\"checkpoints/epoch200.pt\",map_location=torch.device('cpu'))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"hFBPwWgpLOjG","executionInfo":{"status":"ok","timestamp":1661792901974,"user_tz":240,"elapsed":277,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"}}},"outputs":[],"source":["# model.base.requires_grad = False"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1381,"status":"ok","timestamp":1661792903353,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"ZvBMRR972Q5x"},"outputs":[],"source":["import torch\n","import math\n","import os\n","import time\n","import numpy as np\n","from sklearn.utils.class_weight import compute_class_weight\n","from train import eval, get_scores\n","from torch.nn.functional import cross_entropy\n","\n","def train_model(model, dataset, learning_rate, lr_decay, batch_size, num_epochs, device='cuda', isCheckpoint=False, train_val_split = None, isVerbose=True):\n","    loss_history = []\n","\n","    model = model.to(device)\n","    model.train()\n","\n","    optimizer = torch.optim.AdamW(\n","        filter(lambda p: p.requires_grad, model.parameters()), learning_rate\n","    )\n","    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n","        optimizer, lambda epoch: lr_decay ** epoch\n","    )\n","\n","    # sample minibatch data\n","    if not train_val_split:\n","      train_ids = [i for i in range(len(dataset))]\n","      val_ids = None\n","    else:\n","      train_ids, val_ids = train_val_split\n","\n","    iter_per_epoch = math.ceil(len(train_ids) // batch_size)\n","    class_weights = torch.tensor(compute_class_weight(class_weight='balanced', classes=np.arange(model.num_classes), y=dataset.label[train_ids].numpy()), dtype=torch.float, device=device)\n","    loss_fn = torch.nn.NLLLoss(weight = class_weights)\n","    # loss_fn = cross_entropy\n","    \n","    for i in range(num_epochs):\n","        start_t = time.time()\n","        local_hist = []\n","        correct_cnt = 0\n","        y_preds = torch.empty((0,),device=device)\n","        y_trues = torch.empty((0,),device=device)\n","        for j in range(iter_per_epoch):\n","            tokens, y_true = dataset[train_ids[j * batch_size: (j + 1) * batch_size]]\n","\n","            tokens = tokens.to(device)\n","            y_true = y_true.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            digits = model(tokens)\n","            y_preds = torch.hstack([y_preds,digits.argmax(dim=1)])\n","            y_trues = torch.hstack([y_trues,y_true])\n","\n","            probs = torch.nn.LogSoftmax(dim=1)(digits)\n","            loss = loss_fn(probs,y_true)\n","            loss.backward()\n","\n","            local_hist.append(loss.item())\n","            optimizer.step()\n","\n","        end_t = time.time()\n","\n","        loss_mean = np.array(local_hist).mean()\n","        loss_history.append(loss_mean)\n","            \n","        print(\n","            f\"(Epoch {i}), time: {end_t - start_t:.1f}s, loss: {loss_mean:.3f}\"\n","        )\n","        if isVerbose:\n","            train_accuracy, train_precision, train_recall, train_f1 = get_scores(y_trues.to('cpu'), y_preds.to('cpu'), model.num_classes) # This is an aggregated result due to GPU size limit\n","            print(f\"    Training Set - accuracy: {train_accuracy:.2f}, precision: {train_precision:.2f}, recall: {train_recall:.2f}, f1-score: {train_f1:.2f},\")\n","            if val_ids is not None:\n","                val_accuracy, val_precision, val_recall, val_f1 = eval(model, dataset, val_ids, num_classes)\n","                print(f\"    Validation Set - accuracy: {val_accuracy:.2f}, precision: {val_precision:.2f}, recall: {val_recall:.2f}, f1-score: {val_f1:.2f},\")\n","        if i%200 == 0 and isCheckpoint:\n","          dir = \"checkpoints\"\n","          if not os.path.exists(dir):\n","            os.mkdir(dir)\n","          file = f\"epoch{i}.pt\"\n","          path = dir+'/'+file\n","          torch.save({\n","                      'epoch': i,\n","                      'model_state_dict': model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss_mean,\n","                      }, path)\n","\n","        lr_scheduler.step()\n","\n","        if loss_mean < 0.5:\n","          break\n","    \n","    return loss_history"]},{"cell_type":"code","source":["# loss_hist = train_model(model, dataset, learning_rate=5e-6, lr_decay=0.99, batch_size=10, num_epochs=200, isCheckpoint = True, isVerbose = True)"],"metadata":{"id":"EPcnBGvn8xBO","executionInfo":{"status":"ok","timestamp":1661792903353,"user_tz":240,"elapsed":3,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NVaX4nbOTOi0"},"source":["## 5-fold CV"]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import torch\n","\n","def train_model_cv5(model, dataset):\n","    loss_hist = []\n","    kf = KFold(n_splits=5)\n","    cnt = 1\n","    for train_index, val_index in kf.split(dataset):\n","        model.reset()\n","        print(\"Fold \"+str(cnt)+\" (val\", val_index[0],\"-\",str(val_index[-1])+\")\")\n","        loss_hist_fold = train_model(model, dataset=dataset, train_val_split=(train_index, val_index),learning_rate=3e-6, lr_decay=0.99, batch_size=10, num_epochs=300, isCheckpoint = False, isVerbose = True)\n","        loss_hist.append(loss_hist_fold)\n","        cnt += 1\n","    return loss_hist"],"metadata":{"id":"R8G3vHc48zoJ","executionInfo":{"status":"ok","timestamp":1661792903354,"user_tz":240,"elapsed":3,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XN5fu6oeTOi1","outputId":"131caa2f-8ad8-46fc-aab7-2c007f6bafc0","executionInfo":{"status":"ok","timestamp":1661798082967,"user_tz":240,"elapsed":21927,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 1 (val 0 - 42)\n","(Epoch 0), time: 11.3s, loss: 1.432\n","    Training Set - accuracy: 0.07, precision: 0.07, recall: 0.24, f1-score: 0.05,\n","    Validation Set - accuracy: 0.00, precision: 0.00, recall: 0.00, f1-score: 0.00,\n","(Epoch 1), time: 8.8s, loss: 1.425\n","    Training Set - accuracy: 0.21, precision: 0.11, recall: 0.34, f1-score: 0.14,\n","    Validation Set - accuracy: 0.15, precision: 0.07, recall: 0.50, f1-score: 0.11,\n","(Epoch 2), time: 8.8s, loss: 1.422\n","    Training Set - accuracy: 0.33, precision: 0.11, recall: 0.26, f1-score: 0.15,\n","    Validation Set - accuracy: 0.12, precision: 0.03, recall: 0.25, f1-score: 0.06,\n","(Epoch 3), time: 8.8s, loss: 1.415\n","    Training Set - accuracy: 0.35, precision: 0.09, recall: 0.25, f1-score: 0.13,\n","    Validation Set - accuracy: 0.12, precision: 0.03, recall: 0.25, f1-score: 0.06,\n","(Epoch 4), time: 8.9s, loss: 1.414\n","    Training Set - accuracy: 0.35, precision: 0.09, recall: 0.25, f1-score: 0.13,\n","    Validation Set - accuracy: 0.12, precision: 0.03, recall: 0.25, f1-score: 0.06,\n","(Epoch 5), time: 8.8s, loss: 1.407\n","    Training Set - accuracy: 0.35, precision: 0.09, recall: 0.25, f1-score: 0.13,\n","    Validation Set - accuracy: 0.12, precision: 0.03, recall: 0.25, f1-score: 0.06,\n","(Epoch 6), time: 8.8s, loss: 1.400\n","    Training Set - accuracy: 0.35, precision: 0.09, recall: 0.25, f1-score: 0.13,\n","    Validation Set - accuracy: 0.12, precision: 0.03, recall: 0.25, f1-score: 0.06,\n","(Epoch 7), time: 8.8s, loss: 1.383\n","    Training Set - accuracy: 0.36, precision: 0.25, recall: 0.25, f1-score: 0.15,\n","    Validation Set - accuracy: 0.23, precision: 0.28, recall: 0.28, f1-score: 0.12,\n","(Epoch 8), time: 8.8s, loss: 1.354\n","    Training Set - accuracy: 0.43, precision: 0.24, recall: 0.28, f1-score: 0.24,\n","    Validation Set - accuracy: 0.40, precision: 0.23, recall: 0.21, f1-score: 0.18,\n","(Epoch 9), time: 8.8s, loss: 1.334\n","    Training Set - accuracy: 0.48, precision: 0.24, recall: 0.29, f1-score: 0.26,\n","    Validation Set - accuracy: 0.55, precision: 0.24, recall: 0.25, f1-score: 0.22,\n","(Epoch 10), time: 8.8s, loss: 1.329\n","    Training Set - accuracy: 0.47, precision: 0.48, recall: 0.29, f1-score: 0.28,\n","    Validation Set - accuracy: 0.62, precision: 0.25, recall: 0.27, f1-score: 0.25,\n","(Epoch 11), time: 8.8s, loss: 1.309\n","    Training Set - accuracy: 0.51, precision: 0.39, recall: 0.36, f1-score: 0.36,\n","    Validation Set - accuracy: 0.60, precision: 0.23, recall: 0.22, f1-score: 0.22,\n","(Epoch 12), time: 8.8s, loss: 1.277\n","    Training Set - accuracy: 0.55, precision: 0.69, recall: 0.40, f1-score: 0.42,\n","    Validation Set - accuracy: 0.70, precision: 0.53, recall: 0.54, f1-score: 0.53,\n","(Epoch 13), time: 8.8s, loss: 1.252\n","    Training Set - accuracy: 0.50, precision: 0.54, recall: 0.40, f1-score: 0.42,\n","    Validation Set - accuracy: 0.75, precision: 0.39, recall: 0.51, f1-score: 0.43,\n","(Epoch 14), time: 8.7s, loss: 1.221\n","    Training Set - accuracy: 0.59, precision: 0.61, recall: 0.59, f1-score: 0.56,\n","    Validation Set - accuracy: 0.72, precision: 0.46, recall: 0.46, f1-score: 0.46,\n","(Epoch 15), time: 8.7s, loss: 1.186\n","    Training Set - accuracy: 0.61, precision: 0.67, recall: 0.60, f1-score: 0.59,\n","    Validation Set - accuracy: 0.75, precision: 0.34, recall: 0.47, f1-score: 0.38,\n","(Epoch 16), time: 8.8s, loss: 1.153\n","    Training Set - accuracy: 0.58, precision: 0.59, recall: 0.59, f1-score: 0.53,\n","    Validation Set - accuracy: 0.65, precision: 0.46, recall: 0.44, f1-score: 0.45,\n","(Epoch 17), time: 8.7s, loss: 1.115\n","    Training Set - accuracy: 0.60, precision: 0.59, recall: 0.61, f1-score: 0.54,\n","    Validation Set - accuracy: 0.68, precision: 0.21, recall: 0.20, f1-score: 0.21,\n","(Epoch 18), time: 8.8s, loss: 1.086\n","    Training Set - accuracy: 0.59, precision: 0.62, recall: 0.58, f1-score: 0.51,\n","    Validation Set - accuracy: 0.65, precision: 0.21, recall: 0.20, f1-score: 0.20,\n","(Epoch 19), time: 8.8s, loss: 1.042\n","    Training Set - accuracy: 0.62, precision: 0.71, recall: 0.65, f1-score: 0.58,\n","    Validation Set - accuracy: 0.72, precision: 0.20, recall: 0.22, f1-score: 0.21,\n","(Epoch 20), time: 8.8s, loss: 1.016\n","    Training Set - accuracy: 0.61, precision: 0.69, recall: 0.61, f1-score: 0.54,\n","    Validation Set - accuracy: 0.78, precision: 0.20, recall: 0.23, f1-score: 0.22,\n","(Epoch 21), time: 8.8s, loss: 0.992\n","    Training Set - accuracy: 0.60, precision: 0.63, recall: 0.60, f1-score: 0.51,\n","    Validation Set - accuracy: 0.75, precision: 0.20, recall: 0.23, f1-score: 0.21,\n","(Epoch 22), time: 8.7s, loss: 0.950\n","    Training Set - accuracy: 0.66, precision: 0.73, recall: 0.66, f1-score: 0.60,\n","    Validation Set - accuracy: 0.70, precision: 0.34, recall: 0.45, f1-score: 0.37,\n","(Epoch 23), time: 8.8s, loss: 0.886\n","    Training Set - accuracy: 0.72, precision: 0.80, recall: 0.73, f1-score: 0.72,\n","    Validation Set - accuracy: 0.60, precision: 0.29, recall: 0.42, f1-score: 0.31,\n","(Epoch 24), time: 8.7s, loss: 0.835\n","    Training Set - accuracy: 0.73, precision: 0.77, recall: 0.76, f1-score: 0.72,\n","    Validation Set - accuracy: 0.70, precision: 0.29, recall: 0.45, f1-score: 0.33,\n","(Epoch 25), time: 8.7s, loss: 0.779\n","    Training Set - accuracy: 0.75, precision: 0.79, recall: 0.79, f1-score: 0.75,\n","    Validation Set - accuracy: 0.75, precision: 0.51, recall: 0.51, f1-score: 0.51,\n","(Epoch 26), time: 8.7s, loss: 0.741\n","    Training Set - accuracy: 0.79, precision: 0.81, recall: 0.81, f1-score: 0.79,\n","    Validation Set - accuracy: 0.75, precision: 0.46, recall: 0.47, f1-score: 0.46,\n","(Epoch 27), time: 8.8s, loss: 0.696\n","    Training Set - accuracy: 0.80, precision: 0.83, recall: 0.83, f1-score: 0.80,\n","    Validation Set - accuracy: 0.68, precision: 0.38, recall: 0.49, f1-score: 0.41,\n","(Epoch 28), time: 8.7s, loss: 0.659\n","    Training Set - accuracy: 0.82, precision: 0.89, recall: 0.85, f1-score: 0.85,\n","    Validation Set - accuracy: 0.68, precision: 0.29, recall: 0.29, f1-score: 0.28,\n","(Epoch 29), time: 8.7s, loss: 0.646\n","    Training Set - accuracy: 0.81, precision: 0.87, recall: 0.83, f1-score: 0.83,\n","    Validation Set - accuracy: 0.65, precision: 0.37, recall: 0.48, f1-score: 0.40,\n","(Epoch 30), time: 8.7s, loss: 0.610\n","    Training Set - accuracy: 0.82, precision: 0.86, recall: 0.85, f1-score: 0.83,\n","    Validation Set - accuracy: 0.72, precision: 0.25, recall: 0.26, f1-score: 0.26,\n","(Epoch 31), time: 8.8s, loss: 0.574\n","    Training Set - accuracy: 0.88, precision: 0.87, recall: 0.88, f1-score: 0.87,\n","    Validation Set - accuracy: 0.70, precision: 0.25, recall: 0.25, f1-score: 0.25,\n","(Epoch 32), time: 8.7s, loss: 0.548\n","    Training Set - accuracy: 0.90, precision: 0.91, recall: 0.90, f1-score: 0.90,\n","    Validation Set - accuracy: 0.68, precision: 0.28, recall: 0.29, f1-score: 0.28,\n","(Epoch 33), time: 8.8s, loss: 0.519\n","    Training Set - accuracy: 0.88, precision: 0.93, recall: 0.91, f1-score: 0.91,\n","    Validation Set - accuracy: 0.62, precision: 0.26, recall: 0.27, f1-score: 0.25,\n","(Epoch 34), time: 8.8s, loss: 0.490\n","    Training Set - accuracy: 0.89, precision: 0.92, recall: 0.90, f1-score: 0.90,\n","    Validation Set - accuracy: 0.75, precision: 0.29, recall: 0.31, f1-score: 0.30,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 2 (val 43 - 84)\n","(Epoch 0), time: 8.8s, loss: 1.384\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 1), time: 8.7s, loss: 1.378\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 2), time: 8.8s, loss: 1.377\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 3), time: 8.8s, loss: 1.376\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 4), time: 8.8s, loss: 1.374\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 5), time: 8.8s, loss: 1.370\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 6), time: 8.8s, loss: 1.365\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 7), time: 8.8s, loss: 1.358\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 8), time: 8.8s, loss: 1.345\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 9), time: 8.8s, loss: 1.314\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 10), time: 8.8s, loss: 1.291\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 11), time: 8.8s, loss: 1.267\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 12), time: 8.8s, loss: 1.239\n","    Training Set - accuracy: 0.51, precision: 0.13, recall: 0.25, f1-score: 0.17,\n","    Validation Set - accuracy: 0.70, precision: 0.17, recall: 0.25, f1-score: 0.21,\n","(Epoch 13), time: 8.8s, loss: 1.212\n","    Training Set - accuracy: 0.52, precision: 0.25, recall: 0.26, f1-score: 0.20,\n","    Validation Set - accuracy: 0.68, precision: 0.17, recall: 0.24, f1-score: 0.20,\n","(Epoch 14), time: 8.7s, loss: 1.188\n","    Training Set - accuracy: 0.56, precision: 0.23, recall: 0.35, f1-score: 0.28,\n","    Validation Set - accuracy: 0.68, precision: 0.17, recall: 0.24, f1-score: 0.20,\n","(Epoch 15), time: 8.8s, loss: 1.156\n","    Training Set - accuracy: 0.53, precision: 0.22, recall: 0.35, f1-score: 0.27,\n","    Validation Set - accuracy: 0.55, precision: 0.20, recall: 0.31, f1-score: 0.22,\n","(Epoch 16), time: 8.8s, loss: 1.102\n","    Training Set - accuracy: 0.55, precision: 0.49, recall: 0.43, f1-score: 0.31,\n","    Validation Set - accuracy: 0.55, precision: 0.33, recall: 0.33, f1-score: 0.27,\n","(Epoch 17), time: 8.7s, loss: 1.058\n","    Training Set - accuracy: 0.58, precision: 0.51, recall: 0.48, f1-score: 0.35,\n","    Validation Set - accuracy: 0.50, precision: 0.29, recall: 0.31, f1-score: 0.25,\n","(Epoch 18), time: 8.8s, loss: 1.015\n","    Training Set - accuracy: 0.66, precision: 0.51, recall: 0.54, f1-score: 0.45,\n","    Validation Set - accuracy: 0.53, precision: 0.33, recall: 0.34, f1-score: 0.29,\n","(Epoch 19), time: 8.8s, loss: 0.993\n","    Training Set - accuracy: 0.67, precision: 0.51, recall: 0.55, f1-score: 0.46,\n","    Validation Set - accuracy: 0.50, precision: 0.26, recall: 0.31, f1-score: 0.25,\n","(Epoch 20), time: 8.8s, loss: 0.991\n","    Training Set - accuracy: 0.62, precision: 0.41, recall: 0.49, f1-score: 0.40,\n","    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.29, f1-score: 0.23,\n","(Epoch 21), time: 8.8s, loss: 1.019\n","    Training Set - accuracy: 0.67, precision: 0.47, recall: 0.52, f1-score: 0.45,\n","    Validation Set - accuracy: 0.30, precision: 0.25, recall: 0.24, f1-score: 0.18,\n","(Epoch 22), time: 8.8s, loss: 1.017\n","    Training Set - accuracy: 0.61, precision: 0.43, recall: 0.51, f1-score: 0.42,\n","    Validation Set - accuracy: 0.53, precision: 0.28, recall: 0.34, f1-score: 0.29,\n","(Epoch 23), time: 8.8s, loss: 0.910\n","    Training Set - accuracy: 0.72, precision: 0.53, recall: 0.60, f1-score: 0.52,\n","    Validation Set - accuracy: 0.53, precision: 0.25, recall: 0.24, f1-score: 0.24,\n","(Epoch 24), time: 8.8s, loss: 0.882\n","    Training Set - accuracy: 0.75, precision: 0.53, recall: 0.62, f1-score: 0.55,\n","    Validation Set - accuracy: 0.53, precision: 0.29, recall: 0.34, f1-score: 0.28,\n","(Epoch 25), time: 8.8s, loss: 0.870\n","    Training Set - accuracy: 0.75, precision: 0.53, recall: 0.62, f1-score: 0.54,\n","    Validation Set - accuracy: 0.50, precision: 0.25, recall: 0.31, f1-score: 0.26,\n","(Epoch 26), time: 8.8s, loss: 0.830\n","    Training Set - accuracy: 0.79, precision: 0.56, recall: 0.65, f1-score: 0.58,\n","    Validation Set - accuracy: 0.53, precision: 0.23, recall: 0.23, f1-score: 0.23,\n","(Epoch 27), time: 8.8s, loss: 0.808\n","    Training Set - accuracy: 0.81, precision: 0.57, recall: 0.66, f1-score: 0.59,\n","    Validation Set - accuracy: 0.50, precision: 0.23, recall: 0.22, f1-score: 0.22,\n","(Epoch 28), time: 8.8s, loss: 0.780\n","    Training Set - accuracy: 0.84, precision: 0.59, recall: 0.68, f1-score: 0.62,\n","    Validation Set - accuracy: 0.55, precision: 0.25, recall: 0.25, f1-score: 0.25,\n","(Epoch 29), time: 8.8s, loss: 0.762\n","    Training Set - accuracy: 0.81, precision: 0.57, recall: 0.66, f1-score: 0.60,\n","    Validation Set - accuracy: 0.55, precision: 0.28, recall: 0.27, f1-score: 0.27,\n","(Epoch 30), time: 8.8s, loss: 0.762\n","    Training Set - accuracy: 0.84, precision: 0.60, recall: 0.68, f1-score: 0.62,\n","    Validation Set - accuracy: 0.47, precision: 0.23, recall: 0.21, f1-score: 0.22,\n","(Epoch 31), time: 8.8s, loss: 0.739\n","    Training Set - accuracy: 0.86, precision: 0.60, recall: 0.69, f1-score: 0.63,\n","    Validation Set - accuracy: 0.55, precision: 0.25, recall: 0.25, f1-score: 0.25,\n","(Epoch 32), time: 8.8s, loss: 0.731\n","    Training Set - accuracy: 0.86, precision: 0.60, recall: 0.69, f1-score: 0.63,\n","    Validation Set - accuracy: 0.53, precision: 0.24, recall: 0.24, f1-score: 0.24,\n","(Epoch 33), time: 8.8s, loss: 0.717\n","    Training Set - accuracy: 0.84, precision: 0.59, recall: 0.68, f1-score: 0.62,\n","    Validation Set - accuracy: 0.70, precision: 0.30, recall: 0.33, f1-score: 0.31,\n","(Epoch 34), time: 8.8s, loss: 0.727\n","    Training Set - accuracy: 0.86, precision: 0.61, recall: 0.70, f1-score: 0.64,\n","    Validation Set - accuracy: 0.65, precision: 0.28, recall: 0.31, f1-score: 0.29,\n","(Epoch 35), time: 8.8s, loss: 0.713\n","    Training Set - accuracy: 0.86, precision: 0.61, recall: 0.70, f1-score: 0.64,\n","    Validation Set - accuracy: 0.50, precision: 0.25, recall: 0.24, f1-score: 0.24,\n","(Epoch 36), time: 8.8s, loss: 0.690\n","    Training Set - accuracy: 0.87, precision: 0.62, recall: 0.70, f1-score: 0.65,\n","    Validation Set - accuracy: 0.53, precision: 0.32, recall: 0.38, f1-score: 0.31,\n","(Epoch 37), time: 8.8s, loss: 0.668\n","    Training Set - accuracy: 0.89, precision: 0.63, recall: 0.72, f1-score: 0.67,\n","    Validation Set - accuracy: 0.55, precision: 0.32, recall: 0.39, f1-score: 0.32,\n","(Epoch 38), time: 8.8s, loss: 0.672\n","    Training Set - accuracy: 0.86, precision: 0.60, recall: 0.70, f1-score: 0.63,\n","    Validation Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.26,\n","(Epoch 39), time: 8.8s, loss: 0.649\n","    Training Set - accuracy: 0.90, precision: 0.63, recall: 0.73, f1-score: 0.67,\n","    Validation Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.26,\n","(Epoch 40), time: 8.8s, loss: 0.622\n","    Training Set - accuracy: 0.91, precision: 0.64, recall: 0.74, f1-score: 0.68,\n","    Validation Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.27,\n","(Epoch 41), time: 8.8s, loss: 0.607\n","    Training Set - accuracy: 0.93, precision: 0.65, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.55, precision: 0.27, recall: 0.27, f1-score: 0.26,\n","(Epoch 42), time: 8.8s, loss: 0.597\n","    Training Set - accuracy: 0.93, precision: 0.65, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.27,\n","(Epoch 43), time: 8.8s, loss: 0.593\n","    Training Set - accuracy: 0.93, precision: 0.66, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.27,\n","(Epoch 44), time: 8.8s, loss: 0.582\n","    Training Set - accuracy: 0.93, precision: 0.65, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.55, precision: 0.26, recall: 0.27, f1-score: 0.26,\n","(Epoch 45), time: 8.7s, loss: 0.578\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.60, precision: 0.27, recall: 0.29, f1-score: 0.28,\n","(Epoch 46), time: 8.8s, loss: 0.578\n","    Training Set - accuracy: 0.93, precision: 0.65, recall: 0.74, f1-score: 0.68,\n","    Validation Set - accuracy: 0.62, precision: 0.28, recall: 0.32, f1-score: 0.29,\n","(Epoch 47), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.62, precision: 0.28, recall: 0.32, f1-score: 0.29,\n","(Epoch 48), time: 8.8s, loss: 0.561\n","    Training Set - accuracy: 0.93, precision: 0.66, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.53, precision: 0.26, recall: 0.26, f1-score: 0.25,\n","(Epoch 49), time: 8.8s, loss: 0.546\n","    Training Set - accuracy: 0.93, precision: 0.66, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.60, precision: 0.27, recall: 0.29, f1-score: 0.28,\n","(Epoch 50), time: 8.8s, loss: 0.548\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.55, precision: 0.26, recall: 0.27, f1-score: 0.26,\n","(Epoch 51), time: 8.8s, loss: 0.534\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.60, precision: 0.27, recall: 0.29, f1-score: 0.28,\n","(Epoch 52), time: 8.8s, loss: 0.527\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.55, precision: 0.25, recall: 0.25, f1-score: 0.25,\n","(Epoch 53), time: 8.8s, loss: 0.521\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.60, precision: 0.28, recall: 0.31, f1-score: 0.28,\n","(Epoch 54), time: 8.8s, loss: 0.519\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.27,\n","(Epoch 55), time: 8.8s, loss: 0.514\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.27,\n","(Epoch 56), time: 8.8s, loss: 0.510\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.62, precision: 0.29, recall: 0.32, f1-score: 0.30,\n","(Epoch 57), time: 8.8s, loss: 0.526\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.60, precision: 0.28, recall: 0.31, f1-score: 0.29,\n","(Epoch 58), time: 8.8s, loss: 0.507\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.57, precision: 0.28, recall: 0.30, f1-score: 0.28,\n","(Epoch 59), time: 8.8s, loss: 0.497\n","    Training Set - accuracy: 0.94, precision: 0.66, recall: 0.75, f1-score: 0.70,\n","    Validation Set - accuracy: 0.60, precision: 0.26, recall: 0.29, f1-score: 0.27,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 3 (val 85 - 126)\n","(Epoch 0), time: 8.8s, loss: 1.385\n","    Training Set - accuracy: 0.14, precision: 0.12, recall: 0.25, f1-score: 0.08,\n","    Validation Set - accuracy: 0.17, precision: 0.18, recall: 0.25, f1-score: 0.12,\n","(Epoch 1), time: 8.8s, loss: 1.379\n","    Training Set - accuracy: 0.15, precision: 0.15, recall: 0.19, f1-score: 0.09,\n","    Validation Set - accuracy: 0.20, precision: 0.22, recall: 0.30, f1-score: 0.14,\n","(Epoch 2), time: 8.8s, loss: 1.377\n","    Training Set - accuracy: 0.38, precision: 0.14, recall: 0.19, f1-score: 0.16,\n","    Validation Set - accuracy: 0.35, precision: 0.09, recall: 0.23, f1-score: 0.13,\n","(Epoch 3), time: 8.7s, loss: 1.375\n","    Training Set - accuracy: 0.57, precision: 0.15, recall: 0.24, f1-score: 0.18,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 4), time: 8.8s, loss: 1.367\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 5), time: 8.8s, loss: 1.364\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 6), time: 8.8s, loss: 1.365\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 7), time: 8.8s, loss: 1.360\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 8), time: 8.8s, loss: 1.340\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 9), time: 8.8s, loss: 1.325\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 10), time: 8.8s, loss: 1.312\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 11), time: 8.8s, loss: 1.291\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 12), time: 8.8s, loss: 1.275\n","    Training Set - accuracy: 0.60, precision: 0.32, recall: 0.26, f1-score: 0.21,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 13), time: 8.8s, loss: 1.243\n","    Training Set - accuracy: 0.60, precision: 0.40, recall: 0.29, f1-score: 0.26,\n","    Validation Set - accuracy: 0.38, precision: 0.22, recall: 0.25, f1-score: 0.16,\n","(Epoch 14), time: 8.8s, loss: 1.218\n","    Training Set - accuracy: 0.62, precision: 0.57, recall: 0.43, f1-score: 0.38,\n","    Validation Set - accuracy: 0.40, precision: 0.22, recall: 0.27, f1-score: 0.17,\n","(Epoch 15), time: 8.8s, loss: 1.162\n","    Training Set - accuracy: 0.65, precision: 0.74, recall: 0.50, f1-score: 0.45,\n","    Validation Set - accuracy: 0.35, precision: 0.25, recall: 0.28, f1-score: 0.22,\n","(Epoch 16), time: 8.8s, loss: 1.126\n","    Training Set - accuracy: 0.66, precision: 0.78, recall: 0.52, f1-score: 0.49,\n","    Validation Set - accuracy: 0.40, precision: 0.31, recall: 0.36, f1-score: 0.28,\n","(Epoch 17), time: 8.8s, loss: 1.084\n","    Training Set - accuracy: 0.69, precision: 0.73, recall: 0.61, f1-score: 0.59,\n","    Validation Set - accuracy: 0.35, precision: 0.19, recall: 0.23, f1-score: 0.17,\n","(Epoch 18), time: 8.8s, loss: 1.043\n","    Training Set - accuracy: 0.72, precision: 0.74, recall: 0.68, f1-score: 0.64,\n","    Validation Set - accuracy: 0.42, precision: 0.35, recall: 0.37, f1-score: 0.32,\n","(Epoch 19), time: 8.8s, loss: 1.013\n","    Training Set - accuracy: 0.74, precision: 0.78, recall: 0.70, f1-score: 0.68,\n","    Validation Set - accuracy: 0.35, precision: 0.22, recall: 0.28, f1-score: 0.20,\n","(Epoch 20), time: 8.8s, loss: 0.971\n","    Training Set - accuracy: 0.74, precision: 0.79, recall: 0.70, f1-score: 0.69,\n","    Validation Set - accuracy: 0.40, precision: 0.33, recall: 0.31, f1-score: 0.27,\n","(Epoch 21), time: 8.8s, loss: 0.951\n","    Training Set - accuracy: 0.78, precision: 0.83, recall: 0.75, f1-score: 0.76,\n","    Validation Set - accuracy: 0.40, precision: 0.34, recall: 0.31, f1-score: 0.28,\n","(Epoch 22), time: 8.8s, loss: 0.908\n","    Training Set - accuracy: 0.80, precision: 0.89, recall: 0.76, f1-score: 0.80,\n","    Validation Set - accuracy: 0.42, precision: 0.33, recall: 0.33, f1-score: 0.29,\n","(Epoch 23), time: 8.8s, loss: 0.889\n","    Training Set - accuracy: 0.84, precision: 0.90, recall: 0.82, f1-score: 0.85,\n","    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.26, f1-score: 0.22,\n","(Epoch 24), time: 8.8s, loss: 0.859\n","    Training Set - accuracy: 0.82, precision: 0.81, recall: 0.80, f1-score: 0.79,\n","    Validation Set - accuracy: 0.45, precision: 0.33, recall: 0.34, f1-score: 0.32,\n","(Epoch 25), time: 8.8s, loss: 0.849\n","    Training Set - accuracy: 0.82, precision: 0.81, recall: 0.81, f1-score: 0.78,\n","    Validation Set - accuracy: 0.40, precision: 0.37, recall: 0.31, f1-score: 0.28,\n","(Epoch 26), time: 8.8s, loss: 0.799\n","    Training Set - accuracy: 0.85, precision: 0.87, recall: 0.83, f1-score: 0.84,\n","    Validation Set - accuracy: 0.42, precision: 0.25, recall: 0.28, f1-score: 0.24,\n","(Epoch 27), time: 8.8s, loss: 0.763\n","    Training Set - accuracy: 0.91, precision: 0.93, recall: 0.91, f1-score: 0.92,\n","    Validation Set - accuracy: 0.42, precision: 0.35, recall: 0.33, f1-score: 0.30,\n","(Epoch 28), time: 8.8s, loss: 0.724\n","    Training Set - accuracy: 0.91, precision: 0.93, recall: 0.89, f1-score: 0.91,\n","    Validation Set - accuracy: 0.38, precision: 0.26, recall: 0.29, f1-score: 0.27,\n","(Epoch 29), time: 8.8s, loss: 0.705\n","    Training Set - accuracy: 0.91, precision: 0.95, recall: 0.89, f1-score: 0.92,\n","    Validation Set - accuracy: 0.38, precision: 0.25, recall: 0.29, f1-score: 0.25,\n","(Epoch 30), time: 8.8s, loss: 0.675\n","    Training Set - accuracy: 0.91, precision: 0.87, recall: 0.89, f1-score: 0.87,\n","    Validation Set - accuracy: 0.38, precision: 0.21, recall: 0.25, f1-score: 0.21,\n","(Epoch 31), time: 8.8s, loss: 0.644\n","    Training Set - accuracy: 0.93, precision: 0.88, recall: 0.93, f1-score: 0.90,\n","    Validation Set - accuracy: 0.38, precision: 0.22, recall: 0.25, f1-score: 0.21,\n","(Epoch 32), time: 8.8s, loss: 0.631\n","    Training Set - accuracy: 0.95, precision: 0.95, recall: 0.95, f1-score: 0.95,\n","    Validation Set - accuracy: 0.33, precision: 0.17, recall: 0.21, f1-score: 0.17,\n","(Epoch 33), time: 8.8s, loss: 0.619\n","    Training Set - accuracy: 0.95, precision: 0.93, recall: 0.95, f1-score: 0.94,\n","    Validation Set - accuracy: 0.38, precision: 0.32, recall: 0.29, f1-score: 0.27,\n","(Epoch 34), time: 8.8s, loss: 0.583\n","    Training Set - accuracy: 0.96, precision: 0.93, recall: 0.97, f1-score: 0.95,\n","    Validation Set - accuracy: 0.38, precision: 0.20, recall: 0.25, f1-score: 0.20,\n","(Epoch 35), time: 8.8s, loss: 0.565\n","    Training Set - accuracy: 0.96, precision: 0.96, recall: 0.98, f1-score: 0.96,\n","    Validation Set - accuracy: 0.42, precision: 0.23, recall: 0.27, f1-score: 0.25,\n","(Epoch 36), time: 8.8s, loss: 0.541\n","    Training Set - accuracy: 0.96, precision: 0.96, recall: 0.98, f1-score: 0.97,\n","    Validation Set - accuracy: 0.50, precision: 0.33, recall: 0.37, f1-score: 0.35,\n","(Epoch 37), time: 8.8s, loss: 0.514\n","    Training Set - accuracy: 0.97, precision: 0.97, recall: 0.97, f1-score: 0.97,\n","    Validation Set - accuracy: 0.45, precision: 0.34, recall: 0.34, f1-score: 0.32,\n","(Epoch 38), time: 8.8s, loss: 0.495\n","    Training Set - accuracy: 0.96, precision: 0.96, recall: 0.96, f1-score: 0.95,\n","    Validation Set - accuracy: 0.40, precision: 0.24, recall: 0.26, f1-score: 0.21,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 4 (val 127 - 168)\n","(Epoch 0), time: 8.8s, loss: 1.415\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 1), time: 8.8s, loss: 1.410\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 2), time: 8.8s, loss: 1.402\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 3), time: 8.8s, loss: 1.399\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 4), time: 8.8s, loss: 1.398\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 5), time: 8.8s, loss: 1.396\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 6), time: 8.8s, loss: 1.396\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 7), time: 8.8s, loss: 1.397\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 8), time: 8.8s, loss: 1.395\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 9), time: 8.8s, loss: 1.395\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 10), time: 8.8s, loss: 1.391\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 11), time: 8.8s, loss: 1.392\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 12), time: 8.8s, loss: 1.389\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 13), time: 8.8s, loss: 1.384\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 14), time: 8.8s, loss: 1.378\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 15), time: 8.8s, loss: 1.360\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 16), time: 8.8s, loss: 1.328\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 17), time: 8.8s, loss: 1.311\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 18), time: 8.8s, loss: 1.272\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 19), time: 8.8s, loss: 1.230\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 20), time: 8.8s, loss: 1.183\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 21), time: 8.8s, loss: 1.156\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 22), time: 8.8s, loss: 1.125\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 23), time: 8.8s, loss: 1.108\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 24), time: 8.8s, loss: 1.086\n","    Training Set - accuracy: 0.06, precision: 0.01, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 25), time: 8.8s, loss: 1.054\n","    Training Set - accuracy: 0.06, precision: 0.26, recall: 0.27, f1-score: 0.07,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 26), time: 8.8s, loss: 1.041\n","    Training Set - accuracy: 0.10, precision: 0.26, recall: 0.41, f1-score: 0.22,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 27), time: 8.8s, loss: 1.031\n","    Training Set - accuracy: 0.11, precision: 0.26, recall: 0.43, f1-score: 0.24,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 28), time: 8.8s, loss: 1.022\n","    Training Set - accuracy: 0.11, precision: 0.26, recall: 0.45, f1-score: 0.25,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 29), time: 8.8s, loss: 1.009\n","    Training Set - accuracy: 0.10, precision: 0.26, recall: 0.41, f1-score: 0.22,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 30), time: 8.8s, loss: 0.999\n","    Training Set - accuracy: 0.11, precision: 0.26, recall: 0.45, f1-score: 0.25,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 31), time: 8.8s, loss: 0.985\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 32), time: 8.8s, loss: 0.979\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 33), time: 8.8s, loss: 0.973\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 34), time: 8.8s, loss: 0.969\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 35), time: 8.8s, loss: 0.964\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 36), time: 8.8s, loss: 0.962\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 37), time: 8.8s, loss: 0.956\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 38), time: 8.8s, loss: 0.951\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 39), time: 8.8s, loss: 0.948\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 40), time: 8.8s, loss: 0.948\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 41), time: 8.8s, loss: 0.941\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 42), time: 8.8s, loss: 0.939\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 43), time: 8.8s, loss: 0.937\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 44), time: 8.8s, loss: 0.932\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 45), time: 8.8s, loss: 0.930\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 46), time: 8.8s, loss: 0.931\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 47), time: 8.8s, loss: 0.925\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 48), time: 8.8s, loss: 0.923\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 49), time: 8.8s, loss: 0.919\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 50), time: 8.8s, loss: 0.918\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 51), time: 8.8s, loss: 0.915\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 52), time: 8.8s, loss: 0.913\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 53), time: 8.8s, loss: 0.909\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 54), time: 8.8s, loss: 0.910\n","    Training Set - accuracy: 0.12, precision: 0.27, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 55), time: 8.8s, loss: 0.902\n","    Training Set - accuracy: 0.12, precision: 0.52, recall: 0.48, f1-score: 0.28,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 56), time: 8.8s, loss: 0.895\n","    Training Set - accuracy: 0.12, precision: 0.52, recall: 0.48, f1-score: 0.28,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 57), time: 8.8s, loss: 0.893\n","    Training Set - accuracy: 0.14, precision: 0.52, recall: 0.50, f1-score: 0.31,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 58), time: 8.8s, loss: 0.883\n","    Training Set - accuracy: 0.20, precision: 0.52, recall: 0.54, f1-score: 0.38,\n","    Validation Set - accuracy: 0.07, precision: 0.06, recall: 0.17, f1-score: 0.06,\n","(Epoch 59), time: 8.8s, loss: 0.880\n","    Training Set - accuracy: 0.21, precision: 0.48, recall: 0.56, f1-score: 0.38,\n","    Validation Set - accuracy: 0.10, precision: 0.11, recall: 0.29, f1-score: 0.09,\n","(Epoch 60), time: 8.8s, loss: 0.867\n","    Training Set - accuracy: 0.31, precision: 0.49, recall: 0.64, f1-score: 0.46,\n","    Validation Set - accuracy: 0.07, precision: 0.06, recall: 0.17, f1-score: 0.06,\n","(Epoch 61), time: 8.8s, loss: 0.857\n","    Training Set - accuracy: 0.31, precision: 0.49, recall: 0.63, f1-score: 0.46,\n","    Validation Set - accuracy: 0.12, precision: 0.09, recall: 0.31, f1-score: 0.10,\n","(Epoch 62), time: 8.8s, loss: 0.851\n","    Training Set - accuracy: 0.35, precision: 0.50, recall: 0.67, f1-score: 0.48,\n","    Validation Set - accuracy: 0.10, precision: 0.08, recall: 0.08, f1-score: 0.08,\n","(Epoch 63), time: 8.8s, loss: 0.839\n","    Training Set - accuracy: 0.34, precision: 0.49, recall: 0.66, f1-score: 0.47,\n","    Validation Set - accuracy: 0.12, precision: 0.11, recall: 0.10, f1-score: 0.11,\n","(Epoch 64), time: 8.8s, loss: 0.826\n","    Training Set - accuracy: 0.38, precision: 0.47, recall: 0.69, f1-score: 0.49,\n","    Validation Set - accuracy: 0.12, precision: 0.08, recall: 0.10, f1-score: 0.09,\n","(Epoch 65), time: 8.8s, loss: 0.813\n","    Training Set - accuracy: 0.40, precision: 0.46, recall: 0.71, f1-score: 0.49,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 66), time: 8.8s, loss: 0.820\n","    Training Set - accuracy: 0.39, precision: 0.47, recall: 0.71, f1-score: 0.49,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 67), time: 8.8s, loss: 0.816\n","    Training Set - accuracy: 0.39, precision: 0.49, recall: 0.71, f1-score: 0.50,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.31, f1-score: 0.15,\n","(Epoch 68), time: 8.8s, loss: 0.814\n","    Training Set - accuracy: 0.37, precision: 0.49, recall: 0.69, f1-score: 0.49,\n","    Validation Set - accuracy: 0.17, precision: 0.07, recall: 0.15, f1-score: 0.09,\n","(Epoch 69), time: 8.8s, loss: 0.799\n","    Training Set - accuracy: 0.38, precision: 0.49, recall: 0.70, f1-score: 0.50,\n","    Validation Set - accuracy: 0.15, precision: 0.12, recall: 0.23, f1-score: 0.12,\n","(Epoch 70), time: 8.8s, loss: 0.775\n","    Training Set - accuracy: 0.41, precision: 0.48, recall: 0.72, f1-score: 0.50,\n","    Validation Set - accuracy: 0.15, precision: 0.09, recall: 0.12, f1-score: 0.10,\n","(Epoch 71), time: 8.8s, loss: 0.758\n","    Training Set - accuracy: 0.41, precision: 0.49, recall: 0.72, f1-score: 0.51,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 72), time: 8.8s, loss: 0.741\n","    Training Set - accuracy: 0.41, precision: 0.51, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 73), time: 8.8s, loss: 0.732\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.10, recall: 0.19, f1-score: 0.13,\n","(Epoch 74), time: 8.8s, loss: 0.731\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.20, precision: 0.10, recall: 0.17, f1-score: 0.12,\n","(Epoch 75), time: 8.8s, loss: 0.720\n","    Training Set - accuracy: 0.41, precision: 0.50, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.15, precision: 0.07, recall: 0.12, f1-score: 0.09,\n","(Epoch 76), time: 8.8s, loss: 0.716\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 77), time: 8.8s, loss: 0.709\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.15, precision: 0.07, recall: 0.12, f1-score: 0.09,\n","(Epoch 78), time: 8.8s, loss: 0.701\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 79), time: 8.8s, loss: 0.702\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 80), time: 8.8s, loss: 0.697\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.15, f1-score: 0.11,\n","(Epoch 81), time: 8.8s, loss: 0.692\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 82), time: 8.8s, loss: 0.686\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 83), time: 8.8s, loss: 0.682\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 84), time: 8.8s, loss: 0.681\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 85), time: 8.8s, loss: 0.677\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 86), time: 8.8s, loss: 0.675\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 87), time: 8.8s, loss: 0.672\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.23, precision: 0.10, recall: 0.19, f1-score: 0.13,\n","(Epoch 88), time: 8.8s, loss: 0.670\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 89), time: 8.8s, loss: 0.670\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.10, recall: 0.19, f1-score: 0.13,\n","(Epoch 90), time: 8.8s, loss: 0.667\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 91), time: 8.8s, loss: 0.666\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 92), time: 8.8s, loss: 0.662\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 93), time: 8.8s, loss: 0.661\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.10, recall: 0.19, f1-score: 0.13,\n","(Epoch 94), time: 8.8s, loss: 0.658\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 95), time: 8.8s, loss: 0.654\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 96), time: 8.8s, loss: 0.655\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 97), time: 8.8s, loss: 0.652\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 98), time: 8.8s, loss: 0.653\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 99), time: 8.8s, loss: 0.651\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 100), time: 8.8s, loss: 0.659\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.15, f1-score: 0.11,\n","(Epoch 101), time: 8.8s, loss: 0.650\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 102), time: 8.8s, loss: 0.645\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 103), time: 8.8s, loss: 0.642\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 104), time: 8.8s, loss: 0.642\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 105), time: 8.8s, loss: 0.642\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.10, recall: 0.19, f1-score: 0.13,\n","(Epoch 106), time: 8.8s, loss: 0.641\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 107), time: 8.8s, loss: 0.636\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 108), time: 8.8s, loss: 0.636\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.53,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 109), time: 8.8s, loss: 0.633\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 110), time: 8.8s, loss: 0.632\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 111), time: 8.8s, loss: 0.633\n","    Training Set - accuracy: 0.41, precision: 0.52, recall: 0.72, f1-score: 0.52,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 112), time: 8.8s, loss: 0.631\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 113), time: 8.8s, loss: 0.630\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.11,\n","(Epoch 114), time: 8.8s, loss: 0.628\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 115), time: 8.8s, loss: 0.627\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 116), time: 8.8s, loss: 0.624\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.34, recall: 0.20, f1-score: 0.17,\n","(Epoch 117), time: 8.8s, loss: 0.621\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.74, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.07, recall: 0.17, f1-score: 0.10,\n","(Epoch 118), time: 8.8s, loss: 0.621\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 119), time: 8.8s, loss: 0.617\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.10, recall: 0.19, f1-score: 0.13,\n","(Epoch 120), time: 8.8s, loss: 0.619\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 121), time: 8.8s, loss: 0.615\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 122), time: 8.8s, loss: 0.611\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 123), time: 8.8s, loss: 0.612\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.12, precision: 0.06, recall: 0.10, f1-score: 0.08,\n","(Epoch 124), time: 8.7s, loss: 0.611\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 125), time: 8.8s, loss: 0.608\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 126), time: 8.8s, loss: 0.609\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 127), time: 8.8s, loss: 0.607\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 128), time: 8.8s, loss: 0.608\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 129), time: 8.8s, loss: 0.607\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.33, recall: 0.18, f1-score: 0.16,\n","(Epoch 130), time: 8.8s, loss: 0.606\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 131), time: 8.8s, loss: 0.605\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.35, recall: 0.24, f1-score: 0.19,\n","(Epoch 132), time: 8.8s, loss: 0.604\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 133), time: 8.8s, loss: 0.603\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.10, recall: 0.19, f1-score: 0.13,\n","(Epoch 134), time: 8.8s, loss: 0.602\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 135), time: 8.8s, loss: 0.608\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.15, precision: 0.10, recall: 0.23, f1-score: 0.11,\n","(Epoch 136), time: 8.8s, loss: 0.603\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.33, recall: 0.18, f1-score: 0.16,\n","(Epoch 137), time: 8.8s, loss: 0.601\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.34, recall: 0.20, f1-score: 0.17,\n","(Epoch 138), time: 8.8s, loss: 0.600\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.11, recall: 0.29, f1-score: 0.15,\n","(Epoch 139), time: 8.8s, loss: 0.600\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 140), time: 8.8s, loss: 0.599\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.11,\n","(Epoch 141), time: 8.8s, loss: 0.599\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.11,\n","(Epoch 142), time: 8.8s, loss: 0.598\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 143), time: 8.8s, loss: 0.597\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.32, recall: 0.18, f1-score: 0.15,\n","(Epoch 144), time: 8.8s, loss: 0.597\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 145), time: 8.8s, loss: 0.597\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 146), time: 8.8s, loss: 0.596\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 147), time: 8.8s, loss: 0.596\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 148), time: 8.8s, loss: 0.595\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 149), time: 8.8s, loss: 0.595\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 150), time: 8.8s, loss: 0.594\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 151), time: 8.8s, loss: 0.593\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 152), time: 8.8s, loss: 0.593\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 153), time: 8.8s, loss: 0.594\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 154), time: 8.8s, loss: 0.593\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.11,\n","(Epoch 155), time: 8.8s, loss: 0.592\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 156), time: 8.8s, loss: 0.592\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 157), time: 8.8s, loss: 0.591\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 158), time: 8.8s, loss: 0.591\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.10, recall: 0.23, f1-score: 0.14,\n","(Epoch 159), time: 8.8s, loss: 0.590\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 160), time: 8.8s, loss: 0.591\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 161), time: 8.8s, loss: 0.590\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 162), time: 8.8s, loss: 0.589\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 163), time: 8.8s, loss: 0.589\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.35, recall: 0.26, f1-score: 0.19,\n","(Epoch 164), time: 8.8s, loss: 0.589\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.12,\n","(Epoch 165), time: 8.8s, loss: 0.588\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.12,\n","(Epoch 166), time: 8.8s, loss: 0.588\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.34, recall: 0.24, f1-score: 0.18,\n","(Epoch 167), time: 8.8s, loss: 0.587\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 168), time: 8.8s, loss: 0.588\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 169), time: 8.8s, loss: 0.587\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.34, recall: 0.20, f1-score: 0.17,\n","(Epoch 170), time: 8.8s, loss: 0.587\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 171), time: 8.8s, loss: 0.587\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 172), time: 8.8s, loss: 0.586\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 173), time: 8.8s, loss: 0.586\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 174), time: 8.8s, loss: 0.587\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 175), time: 8.8s, loss: 0.586\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.11,\n","(Epoch 176), time: 8.8s, loss: 0.585\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.32, recall: 0.18, f1-score: 0.15,\n","(Epoch 177), time: 8.8s, loss: 0.584\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 178), time: 8.8s, loss: 0.584\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.15, precision: 0.07, recall: 0.12, f1-score: 0.09,\n","(Epoch 179), time: 8.8s, loss: 0.584\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 180), time: 8.8s, loss: 0.584\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 181), time: 8.8s, loss: 0.584\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 182), time: 8.8s, loss: 0.583\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.34, recall: 0.20, f1-score: 0.17,\n","(Epoch 183), time: 8.8s, loss: 0.583\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 184), time: 8.8s, loss: 0.582\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 185), time: 8.8s, loss: 0.583\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 186), time: 8.8s, loss: 0.583\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 187), time: 8.8s, loss: 0.582\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 188), time: 8.8s, loss: 0.581\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 189), time: 8.8s, loss: 0.581\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 190), time: 8.8s, loss: 0.580\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 191), time: 8.7s, loss: 0.581\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 192), time: 8.8s, loss: 0.581\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 193), time: 8.8s, loss: 0.581\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 194), time: 8.8s, loss: 0.583\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.25, f1-score: 0.12,\n","(Epoch 195), time: 8.8s, loss: 0.581\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.11,\n","(Epoch 196), time: 8.8s, loss: 0.580\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 197), time: 8.8s, loss: 0.579\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.34, recall: 0.22, f1-score: 0.17,\n","(Epoch 198), time: 8.8s, loss: 0.579\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 199), time: 8.8s, loss: 0.579\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 200), time: 8.8s, loss: 0.579\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.34, recall: 0.20, f1-score: 0.17,\n","(Epoch 201), time: 8.8s, loss: 0.578\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 202), time: 8.8s, loss: 0.578\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 203), time: 8.8s, loss: 0.578\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 204), time: 8.8s, loss: 0.578\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 205), time: 8.8s, loss: 0.577\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 206), time: 8.8s, loss: 0.578\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 207), time: 8.8s, loss: 0.577\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 208), time: 8.8s, loss: 0.577\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.11, recall: 0.23, f1-score: 0.15,\n","(Epoch 209), time: 8.8s, loss: 0.576\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 210), time: 8.8s, loss: 0.577\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 211), time: 8.8s, loss: 0.577\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 212), time: 8.8s, loss: 0.576\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 213), time: 8.8s, loss: 0.577\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 214), time: 8.8s, loss: 0.576\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 215), time: 8.7s, loss: 0.576\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 216), time: 8.8s, loss: 0.576\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 217), time: 8.8s, loss: 0.575\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 218), time: 8.8s, loss: 0.575\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 219), time: 8.8s, loss: 0.575\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 220), time: 8.8s, loss: 0.575\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 221), time: 8.7s, loss: 0.576\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 222), time: 8.8s, loss: 0.575\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 223), time: 8.8s, loss: 0.575\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.33, recall: 0.20, f1-score: 0.16,\n","(Epoch 224), time: 8.7s, loss: 0.574\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.11,\n","(Epoch 225), time: 8.8s, loss: 0.574\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 226), time: 8.8s, loss: 0.574\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 227), time: 8.8s, loss: 0.574\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 228), time: 8.8s, loss: 0.574\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 229), time: 8.8s, loss: 0.573\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 230), time: 8.8s, loss: 0.573\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 231), time: 8.8s, loss: 0.573\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 232), time: 8.8s, loss: 0.573\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.11, recall: 0.29, f1-score: 0.15,\n","(Epoch 233), time: 8.8s, loss: 0.573\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.12,\n","(Epoch 234), time: 8.7s, loss: 0.573\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 235), time: 8.8s, loss: 0.573\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.11, recall: 0.29, f1-score: 0.15,\n","(Epoch 236), time: 8.8s, loss: 0.572\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 237), time: 8.8s, loss: 0.572\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 238), time: 8.8s, loss: 0.572\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 239), time: 8.8s, loss: 0.572\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.34, recall: 0.22, f1-score: 0.18,\n","(Epoch 240), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.17, precision: 0.08, recall: 0.15, f1-score: 0.10,\n","(Epoch 241), time: 8.8s, loss: 0.572\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 242), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 243), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 244), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 245), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 246), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.34, recall: 0.22, f1-score: 0.18,\n","(Epoch 247), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 248), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 249), time: 8.8s, loss: 0.570\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 250), time: 8.8s, loss: 0.571\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 251), time: 8.8s, loss: 0.570\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 252), time: 8.8s, loss: 0.570\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 253), time: 8.8s, loss: 0.570\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.10, recall: 0.23, f1-score: 0.14,\n","(Epoch 254), time: 8.7s, loss: 0.570\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.34, recall: 0.22, f1-score: 0.17,\n","(Epoch 255), time: 8.8s, loss: 0.570\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 256), time: 8.8s, loss: 0.570\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 257), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.33, recall: 0.22, f1-score: 0.17,\n","(Epoch 258), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.35, recall: 0.24, f1-score: 0.19,\n","(Epoch 259), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.07, recall: 0.17, f1-score: 0.10,\n","(Epoch 260), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 261), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 262), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 263), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 264), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 265), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.09, recall: 0.17, f1-score: 0.11,\n","(Epoch 266), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 267), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.08, recall: 0.21, f1-score: 0.12,\n","(Epoch 268), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 269), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.33, recall: 0.22, f1-score: 0.17,\n","(Epoch 270), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 271), time: 8.8s, loss: 0.569\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 272), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.34, recall: 0.24, f1-score: 0.18,\n","(Epoch 273), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.13,\n","(Epoch 274), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 275), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.10, recall: 0.23, f1-score: 0.14,\n","(Epoch 276), time: 8.7s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 277), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 278), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.08, recall: 0.21, f1-score: 0.12,\n","(Epoch 279), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 280), time: 8.8s, loss: 0.568\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 281), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 282), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 283), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 284), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.14,\n","(Epoch 285), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.33, recall: 0.20, f1-score: 0.16,\n","(Epoch 286), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.35, recall: 0.24, f1-score: 0.19,\n","(Epoch 287), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.19, f1-score: 0.12,\n","(Epoch 288), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.34, recall: 0.26, f1-score: 0.19,\n","(Epoch 289), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.10, recall: 0.21, f1-score: 0.13,\n","(Epoch 290), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.09, recall: 0.23, f1-score: 0.13,\n","(Epoch 291), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n","(Epoch 292), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.09, recall: 0.23, f1-score: 0.13,\n","(Epoch 293), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.10, recall: 0.23, f1-score: 0.14,\n","(Epoch 294), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.28, precision: 0.10, recall: 0.23, f1-score: 0.14,\n","(Epoch 295), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 296), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.09, recall: 0.19, f1-score: 0.12,\n","(Epoch 297), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.34, recall: 0.22, f1-score: 0.18,\n","(Epoch 298), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.21, f1-score: 0.12,\n","(Epoch 299), time: 8.8s, loss: 0.565\n","    Training Set - accuracy: 0.42, precision: 0.52, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.20, precision: 0.08, recall: 0.17, f1-score: 0.11,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 (val 169 - 210)\n","(Epoch 0), time: 8.8s, loss: 1.419\n","    Training Set - accuracy: 0.25, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","    Validation Set - accuracy: 0.47, precision: 0.12, recall: 0.25, f1-score: 0.16,\n","(Epoch 1), time: 8.8s, loss: 1.415\n","    Training Set - accuracy: 0.25, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","    Validation Set - accuracy: 0.47, precision: 0.12, recall: 0.25, f1-score: 0.16,\n","(Epoch 2), time: 8.8s, loss: 1.412\n","    Training Set - accuracy: 0.25, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","    Validation Set - accuracy: 0.47, precision: 0.12, recall: 0.25, f1-score: 0.16,\n","(Epoch 3), time: 8.8s, loss: 1.408\n","    Training Set - accuracy: 0.27, precision: 0.25, recall: 0.26, f1-score: 0.12,\n","    Validation Set - accuracy: 0.47, precision: 0.12, recall: 0.25, f1-score: 0.16,\n","(Epoch 4), time: 8.8s, loss: 1.404\n","    Training Set - accuracy: 0.28, precision: 0.26, recall: 0.26, f1-score: 0.13,\n","    Validation Set - accuracy: 0.47, precision: 0.24, recall: 0.25, f1-score: 0.19,\n","(Epoch 5), time: 8.8s, loss: 1.387\n","    Training Set - accuracy: 0.32, precision: 0.33, recall: 0.28, f1-score: 0.20,\n","    Validation Set - accuracy: 0.38, precision: 0.15, recall: 0.31, f1-score: 0.20,\n","(Epoch 6), time: 8.8s, loss: 1.387\n","    Training Set - accuracy: 0.29, precision: 0.28, recall: 0.34, f1-score: 0.24,\n","    Validation Set - accuracy: 0.38, precision: 0.32, recall: 0.44, f1-score: 0.29,\n","(Epoch 7), time: 8.8s, loss: 1.368\n","    Training Set - accuracy: 0.46, precision: 0.24, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.38, precision: 0.31, recall: 0.46, f1-score: 0.28,\n","(Epoch 8), time: 8.8s, loss: 1.328\n","    Training Set - accuracy: 0.56, precision: 0.34, recall: 0.42, f1-score: 0.28,\n","    Validation Set - accuracy: 0.30, precision: 0.22, recall: 0.41, f1-score: 0.24,\n","(Epoch 9), time: 8.8s, loss: 1.321\n","    Training Set - accuracy: 0.57, precision: 0.36, recall: 0.33, f1-score: 0.28,\n","    Validation Set - accuracy: 0.40, precision: 0.27, recall: 0.37, f1-score: 0.28,\n","(Epoch 10), time: 8.8s, loss: 1.272\n","    Training Set - accuracy: 0.58, precision: 0.31, recall: 0.42, f1-score: 0.29,\n","    Validation Set - accuracy: 0.30, precision: 0.25, recall: 0.42, f1-score: 0.22,\n","(Epoch 11), time: 8.8s, loss: 1.286\n","    Training Set - accuracy: 0.59, precision: 0.36, recall: 0.38, f1-score: 0.31,\n","    Validation Set - accuracy: 0.42, precision: 0.22, recall: 0.29, f1-score: 0.21,\n","(Epoch 12), time: 8.8s, loss: 1.251\n","    Training Set - accuracy: 0.64, precision: 0.39, recall: 0.41, f1-score: 0.39,\n","    Validation Set - accuracy: 0.47, precision: 0.36, recall: 0.39, f1-score: 0.38,\n","(Epoch 13), time: 8.8s, loss: 1.254\n","    Training Set - accuracy: 0.59, precision: 0.34, recall: 0.43, f1-score: 0.36,\n","    Validation Set - accuracy: 0.45, precision: 0.25, recall: 0.27, f1-score: 0.26,\n","(Epoch 14), time: 8.8s, loss: 1.211\n","    Training Set - accuracy: 0.59, precision: 0.35, recall: 0.44, f1-score: 0.37,\n","    Validation Set - accuracy: 0.47, precision: 0.31, recall: 0.39, f1-score: 0.34,\n","(Epoch 15), time: 8.8s, loss: 1.204\n","    Training Set - accuracy: 0.63, precision: 0.37, recall: 0.45, f1-score: 0.40,\n","    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.41, f1-score: 0.34,\n","(Epoch 16), time: 8.8s, loss: 1.189\n","    Training Set - accuracy: 0.63, precision: 0.39, recall: 0.49, f1-score: 0.43,\n","    Validation Set - accuracy: 0.53, precision: 0.27, recall: 0.32, f1-score: 0.29,\n","(Epoch 17), time: 8.8s, loss: 1.190\n","    Training Set - accuracy: 0.66, precision: 0.47, recall: 0.49, f1-score: 0.48,\n","    Validation Set - accuracy: 0.42, precision: 0.23, recall: 0.25, f1-score: 0.23,\n","(Epoch 18), time: 8.8s, loss: 1.159\n","    Training Set - accuracy: 0.66, precision: 0.40, recall: 0.48, f1-score: 0.44,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.27, f1-score: 0.25,\n","(Epoch 19), time: 8.8s, loss: 1.141\n","    Training Set - accuracy: 0.69, precision: 0.45, recall: 0.54, f1-score: 0.49,\n","    Validation Set - accuracy: 0.55, precision: 0.41, recall: 0.44, f1-score: 0.42,\n","(Epoch 20), time: 8.8s, loss: 1.145\n","    Training Set - accuracy: 0.66, precision: 0.43, recall: 0.52, f1-score: 0.46,\n","    Validation Set - accuracy: 0.47, precision: 0.42, recall: 0.50, f1-score: 0.35,\n","(Epoch 21), time: 8.8s, loss: 1.135\n","    Training Set - accuracy: 0.66, precision: 0.41, recall: 0.52, f1-score: 0.45,\n","    Validation Set - accuracy: 0.45, precision: 0.35, recall: 0.39, f1-score: 0.37,\n","(Epoch 22), time: 8.8s, loss: 1.132\n","    Training Set - accuracy: 0.64, precision: 0.40, recall: 0.51, f1-score: 0.43,\n","    Validation Set - accuracy: 0.45, precision: 0.32, recall: 0.38, f1-score: 0.31,\n","(Epoch 23), time: 8.8s, loss: 1.082\n","    Training Set - accuracy: 0.69, precision: 0.43, recall: 0.54, f1-score: 0.47,\n","    Validation Set - accuracy: 0.50, precision: 0.33, recall: 0.42, f1-score: 0.36,\n","(Epoch 24), time: 8.8s, loss: 1.070\n","    Training Set - accuracy: 0.70, precision: 0.46, recall: 0.55, f1-score: 0.49,\n","    Validation Set - accuracy: 0.53, precision: 0.34, recall: 0.41, f1-score: 0.36,\n","(Epoch 25), time: 8.8s, loss: 1.068\n","    Training Set - accuracy: 0.68, precision: 0.44, recall: 0.50, f1-score: 0.46,\n","    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.40, f1-score: 0.36,\n","(Epoch 26), time: 8.8s, loss: 1.058\n","    Training Set - accuracy: 0.70, precision: 0.44, recall: 0.57, f1-score: 0.48,\n","    Validation Set - accuracy: 0.47, precision: 0.31, recall: 0.39, f1-score: 0.32,\n","(Epoch 27), time: 8.8s, loss: 1.030\n","    Training Set - accuracy: 0.71, precision: 0.44, recall: 0.54, f1-score: 0.48,\n","    Validation Set - accuracy: 0.45, precision: 0.30, recall: 0.39, f1-score: 0.32,\n","(Epoch 28), time: 8.8s, loss: 1.057\n","    Training Set - accuracy: 0.71, precision: 0.44, recall: 0.55, f1-score: 0.48,\n","    Validation Set - accuracy: 0.40, precision: 0.44, recall: 0.36, f1-score: 0.37,\n","(Epoch 29), time: 8.8s, loss: 1.005\n","    Training Set - accuracy: 0.76, precision: 0.49, recall: 0.59, f1-score: 0.53,\n","    Validation Set - accuracy: 0.45, precision: 0.24, recall: 0.27, f1-score: 0.26,\n","(Epoch 30), time: 8.8s, loss: 0.997\n","    Training Set - accuracy: 0.79, precision: 0.55, recall: 0.62, f1-score: 0.58,\n","    Validation Set - accuracy: 0.40, precision: 0.28, recall: 0.36, f1-score: 0.30,\n","(Epoch 31), time: 8.8s, loss: 0.972\n","    Training Set - accuracy: 0.79, precision: 0.51, recall: 0.61, f1-score: 0.56,\n","    Validation Set - accuracy: 0.40, precision: 0.29, recall: 0.36, f1-score: 0.31,\n","(Epoch 32), time: 8.8s, loss: 0.970\n","    Training Set - accuracy: 0.77, precision: 0.74, recall: 0.58, f1-score: 0.56,\n","    Validation Set - accuracy: 0.35, precision: 0.18, recall: 0.22, f1-score: 0.20,\n","(Epoch 33), time: 8.8s, loss: 0.955\n","    Training Set - accuracy: 0.81, precision: 0.54, recall: 0.63, f1-score: 0.58,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.22, f1-score: 0.17,\n","(Epoch 34), time: 8.8s, loss: 0.946\n","    Training Set - accuracy: 0.81, precision: 0.55, recall: 0.61, f1-score: 0.58,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.21, f1-score: 0.17,\n","(Epoch 35), time: 8.8s, loss: 0.924\n","    Training Set - accuracy: 0.81, precision: 0.55, recall: 0.61, f1-score: 0.58,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.22, f1-score: 0.17,\n","(Epoch 36), time: 8.8s, loss: 0.918\n","    Training Set - accuracy: 0.77, precision: 0.46, recall: 0.58, f1-score: 0.50,\n","    Validation Set - accuracy: 0.40, precision: 0.21, recall: 0.25, f1-score: 0.23,\n","(Epoch 37), time: 8.8s, loss: 0.909\n","    Training Set - accuracy: 0.83, precision: 0.56, recall: 0.67, f1-score: 0.60,\n","    Validation Set - accuracy: 0.40, precision: 0.21, recall: 0.26, f1-score: 0.22,\n","(Epoch 38), time: 8.8s, loss: 0.909\n","    Training Set - accuracy: 0.81, precision: 0.52, recall: 0.63, f1-score: 0.56,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.24, f1-score: 0.20,\n","(Epoch 39), time: 8.8s, loss: 0.917\n","    Training Set - accuracy: 0.80, precision: 0.49, recall: 0.62, f1-score: 0.53,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.22, f1-score: 0.17,\n","(Epoch 40), time: 8.8s, loss: 1.004\n","    Training Set - accuracy: 0.67, precision: 0.41, recall: 0.51, f1-score: 0.42,\n","    Validation Set - accuracy: 0.42, precision: 0.29, recall: 0.36, f1-score: 0.29,\n","(Epoch 41), time: 8.8s, loss: 0.925\n","    Training Set - accuracy: 0.79, precision: 0.49, recall: 0.62, f1-score: 0.53,\n","    Validation Set - accuracy: 0.42, precision: 0.23, recall: 0.27, f1-score: 0.24,\n","(Epoch 42), time: 8.8s, loss: 0.918\n","    Training Set - accuracy: 0.78, precision: 0.48, recall: 0.61, f1-score: 0.52,\n","    Validation Set - accuracy: 0.35, precision: 0.23, recall: 0.33, f1-score: 0.26,\n","(Epoch 43), time: 8.8s, loss: 0.920\n","    Training Set - accuracy: 0.79, precision: 0.49, recall: 0.62, f1-score: 0.53,\n","    Validation Set - accuracy: 0.42, precision: 0.22, recall: 0.26, f1-score: 0.24,\n","(Epoch 44), time: 8.8s, loss: 0.898\n","    Training Set - accuracy: 0.82, precision: 0.51, recall: 0.64, f1-score: 0.56,\n","    Validation Set - accuracy: 0.38, precision: 0.20, recall: 0.24, f1-score: 0.21,\n","(Epoch 45), time: 8.8s, loss: 0.896\n","    Training Set - accuracy: 0.81, precision: 0.51, recall: 0.63, f1-score: 0.56,\n","    Validation Set - accuracy: 0.45, precision: 0.25, recall: 0.28, f1-score: 0.26,\n","(Epoch 46), time: 8.8s, loss: 0.895\n","    Training Set - accuracy: 0.79, precision: 0.49, recall: 0.61, f1-score: 0.52,\n","    Validation Set - accuracy: 0.38, precision: 0.21, recall: 0.24, f1-score: 0.22,\n","(Epoch 47), time: 8.8s, loss: 0.887\n","    Training Set - accuracy: 0.79, precision: 0.48, recall: 0.61, f1-score: 0.51,\n","    Validation Set - accuracy: 0.42, precision: 0.30, recall: 0.49, f1-score: 0.32,\n","(Epoch 48), time: 8.8s, loss: 0.878\n","    Training Set - accuracy: 0.80, precision: 0.49, recall: 0.62, f1-score: 0.53,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.38, f1-score: 0.30,\n","(Epoch 49), time: 8.8s, loss: 0.879\n","    Training Set - accuracy: 0.79, precision: 0.48, recall: 0.61, f1-score: 0.51,\n","    Validation Set - accuracy: 0.30, precision: 0.17, recall: 0.20, f1-score: 0.17,\n","(Epoch 50), time: 8.8s, loss: 0.885\n","    Training Set - accuracy: 0.78, precision: 0.48, recall: 0.60, f1-score: 0.51,\n","    Validation Set - accuracy: 0.35, precision: 0.20, recall: 0.22, f1-score: 0.20,\n","(Epoch 51), time: 8.8s, loss: 0.873\n","    Training Set - accuracy: 0.82, precision: 0.51, recall: 0.64, f1-score: 0.55,\n","    Validation Set - accuracy: 0.33, precision: 0.17, recall: 0.21, f1-score: 0.18,\n","(Epoch 52), time: 8.8s, loss: 0.867\n","    Training Set - accuracy: 0.81, precision: 0.50, recall: 0.63, f1-score: 0.54,\n","    Validation Set - accuracy: 0.35, precision: 0.20, recall: 0.23, f1-score: 0.19,\n","(Epoch 53), time: 8.8s, loss: 0.883\n","    Training Set - accuracy: 0.72, precision: 0.44, recall: 0.57, f1-score: 0.45,\n","    Validation Set - accuracy: 0.45, precision: 0.32, recall: 0.49, f1-score: 0.34,\n","(Epoch 54), time: 8.8s, loss: 0.864\n","    Training Set - accuracy: 0.81, precision: 0.75, recall: 0.65, f1-score: 0.59,\n","    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.28, f1-score: 0.25,\n","(Epoch 55), time: 8.8s, loss: 0.889\n","    Training Set - accuracy: 0.76, precision: 0.55, recall: 0.58, f1-score: 0.54,\n","    Validation Set - accuracy: 0.35, precision: 0.31, recall: 0.37, f1-score: 0.31,\n","(Epoch 56), time: 8.8s, loss: 0.856\n","    Training Set - accuracy: 0.78, precision: 0.62, recall: 0.71, f1-score: 0.63,\n","    Validation Set - accuracy: 0.30, precision: 0.26, recall: 0.30, f1-score: 0.23,\n","(Epoch 57), time: 8.8s, loss: 0.833\n","    Training Set - accuracy: 0.81, precision: 0.67, recall: 0.77, f1-score: 0.67,\n","    Validation Set - accuracy: 0.35, precision: 0.24, recall: 0.49, f1-score: 0.32,\n","(Epoch 58), time: 8.8s, loss: 0.817\n","    Training Set - accuracy: 0.80, precision: 0.73, recall: 0.79, f1-score: 0.67,\n","    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.38, f1-score: 0.23,\n","(Epoch 59), time: 8.7s, loss: 0.811\n","    Training Set - accuracy: 0.74, precision: 0.64, recall: 0.71, f1-score: 0.55,\n","    Validation Set - accuracy: 0.35, precision: 0.18, recall: 0.38, f1-score: 0.23,\n","(Epoch 60), time: 8.7s, loss: 0.801\n","    Training Set - accuracy: 0.70, precision: 0.44, recall: 0.68, f1-score: 0.50,\n","    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.38, f1-score: 0.23,\n","(Epoch 61), time: 8.8s, loss: 0.793\n","    Training Set - accuracy: 0.72, precision: 0.64, recall: 0.71, f1-score: 0.55,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","(Epoch 62), time: 8.7s, loss: 0.785\n","    Training Set - accuracy: 0.71, precision: 0.68, recall: 0.67, f1-score: 0.50,\n","    Validation Set - accuracy: 0.30, precision: 0.16, recall: 0.31, f1-score: 0.20,\n","(Epoch 63), time: 8.8s, loss: 0.774\n","    Training Set - accuracy: 0.71, precision: 0.44, recall: 0.68, f1-score: 0.50,\n","    Validation Set - accuracy: 0.28, precision: 0.13, recall: 0.26, f1-score: 0.17,\n","(Epoch 64), time: 8.8s, loss: 0.747\n","    Training Set - accuracy: 0.72, precision: 0.72, recall: 0.72, f1-score: 0.54,\n","    Validation Set - accuracy: 0.33, precision: 0.18, recall: 0.36, f1-score: 0.22,\n","(Epoch 65), time: 8.8s, loss: 0.745\n","    Training Set - accuracy: 0.71, precision: 0.46, recall: 0.71, f1-score: 0.53,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","(Epoch 66), time: 8.8s, loss: 0.738\n","    Training Set - accuracy: 0.71, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.19,\n","(Epoch 67), time: 8.8s, loss: 0.738\n","    Training Set - accuracy: 0.71, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.18, recall: 0.34, f1-score: 0.21,\n","(Epoch 68), time: 8.8s, loss: 0.730\n","    Training Set - accuracy: 0.71, precision: 0.50, recall: 0.71, f1-score: 0.55,\n","    Validation Set - accuracy: 0.30, precision: 0.14, recall: 0.28, f1-score: 0.18,\n","(Epoch 69), time: 8.8s, loss: 0.721\n","    Training Set - accuracy: 0.71, precision: 0.53, recall: 0.71, f1-score: 0.57,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.19,\n","(Epoch 70), time: 8.8s, loss: 0.710\n","    Training Set - accuracy: 0.71, precision: 0.46, recall: 0.71, f1-score: 0.52,\n","    Validation Set - accuracy: 0.28, precision: 0.15, recall: 0.29, f1-score: 0.18,\n","(Epoch 71), time: 8.8s, loss: 0.701\n","    Training Set - accuracy: 0.71, precision: 0.51, recall: 0.71, f1-score: 0.56,\n","    Validation Set - accuracy: 0.25, precision: 0.12, recall: 0.24, f1-score: 0.16,\n","(Epoch 72), time: 8.8s, loss: 0.689\n","    Training Set - accuracy: 0.71, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.14, recall: 0.28, f1-score: 0.18,\n","(Epoch 73), time: 8.8s, loss: 0.686\n","    Training Set - accuracy: 0.71, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","(Epoch 74), time: 8.8s, loss: 0.683\n","    Training Set - accuracy: 0.71, precision: 0.47, recall: 0.71, f1-score: 0.53,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","(Epoch 75), time: 8.7s, loss: 0.679\n","    Training Set - accuracy: 0.71, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.19,\n","(Epoch 76), time: 8.7s, loss: 0.667\n","    Training Set - accuracy: 0.71, precision: 0.51, recall: 0.71, f1-score: 0.56,\n","    Validation Set - accuracy: 0.35, precision: 0.19, recall: 0.38, f1-score: 0.23,\n","(Epoch 77), time: 8.7s, loss: 0.656\n","    Training Set - accuracy: 0.72, precision: 0.51, recall: 0.71, f1-score: 0.56,\n","    Validation Set - accuracy: 0.35, precision: 0.18, recall: 0.38, f1-score: 0.23,\n","(Epoch 78), time: 8.8s, loss: 0.651\n","    Training Set - accuracy: 0.72, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.19,\n","(Epoch 79), time: 8.8s, loss: 0.651\n","    Training Set - accuracy: 0.72, precision: 0.51, recall: 0.71, f1-score: 0.56,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.19,\n","(Epoch 80), time: 8.8s, loss: 0.645\n","    Training Set - accuracy: 0.72, precision: 0.50, recall: 0.71, f1-score: 0.55,\n","    Validation Set - accuracy: 0.30, precision: 0.14, recall: 0.28, f1-score: 0.18,\n","(Epoch 81), time: 8.8s, loss: 0.636\n","    Training Set - accuracy: 0.72, precision: 0.50, recall: 0.71, f1-score: 0.55,\n","    Validation Set - accuracy: 0.28, precision: 0.13, recall: 0.26, f1-score: 0.17,\n","(Epoch 82), time: 8.7s, loss: 0.636\n","    Training Set - accuracy: 0.71, precision: 0.47, recall: 0.71, f1-score: 0.53,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.19,\n","(Epoch 83), time: 8.8s, loss: 0.631\n","    Training Set - accuracy: 0.71, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.19,\n","(Epoch 84), time: 8.8s, loss: 0.620\n","    Training Set - accuracy: 0.72, precision: 0.50, recall: 0.71, f1-score: 0.55,\n","    Validation Set - accuracy: 0.30, precision: 0.14, recall: 0.28, f1-score: 0.18,\n","(Epoch 85), time: 8.8s, loss: 0.623\n","    Training Set - accuracy: 0.72, precision: 0.50, recall: 0.71, f1-score: 0.55,\n","    Validation Set - accuracy: 0.33, precision: 0.17, recall: 0.36, f1-score: 0.22,\n","(Epoch 86), time: 8.8s, loss: 0.611\n","    Training Set - accuracy: 0.72, precision: 0.52, recall: 0.71, f1-score: 0.56,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","(Epoch 87), time: 8.7s, loss: 0.609\n","    Training Set - accuracy: 0.72, precision: 0.72, recall: 0.72, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.16, recall: 0.34, f1-score: 0.20,\n","(Epoch 88), time: 8.8s, loss: 0.601\n","    Training Set - accuracy: 0.72, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.20,\n","(Epoch 89), time: 8.8s, loss: 0.595\n","    Training Set - accuracy: 0.72, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.33, precision: 0.17, recall: 0.36, f1-score: 0.22,\n","(Epoch 90), time: 8.8s, loss: 0.593\n","    Training Set - accuracy: 0.72, precision: 0.48, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.28, f1-score: 0.19,\n","(Epoch 91), time: 8.8s, loss: 0.588\n","    Training Set - accuracy: 0.74, precision: 0.73, recall: 0.73, f1-score: 0.58,\n","    Validation Set - accuracy: 0.28, precision: 0.13, recall: 0.26, f1-score: 0.17,\n","(Epoch 92), time: 8.8s, loss: 0.580\n","    Training Set - accuracy: 0.74, precision: 0.77, recall: 0.72, f1-score: 0.58,\n","    Validation Set - accuracy: 0.33, precision: 0.17, recall: 0.36, f1-score: 0.22,\n","(Epoch 93), time: 8.8s, loss: 0.584\n","    Training Set - accuracy: 0.73, precision: 0.71, recall: 0.72, f1-score: 0.55,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","(Epoch 94), time: 8.8s, loss: 0.563\n","    Training Set - accuracy: 0.75, precision: 0.68, recall: 0.74, f1-score: 0.59,\n","    Validation Set - accuracy: 0.33, precision: 0.17, recall: 0.36, f1-score: 0.22,\n","(Epoch 95), time: 8.8s, loss: 0.552\n","    Training Set - accuracy: 0.79, precision: 0.74, recall: 0.78, f1-score: 0.66,\n","    Validation Set - accuracy: 0.33, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","(Epoch 96), time: 8.8s, loss: 0.537\n","    Training Set - accuracy: 0.80, precision: 0.71, recall: 0.80, f1-score: 0.68,\n","    Validation Set - accuracy: 0.28, precision: 0.13, recall: 0.26, f1-score: 0.17,\n","(Epoch 97), time: 8.8s, loss: 0.526\n","    Training Set - accuracy: 0.82, precision: 0.75, recall: 0.81, f1-score: 0.71,\n","    Validation Set - accuracy: 0.28, precision: 0.13, recall: 0.23, f1-score: 0.16,\n","(Epoch 98), time: 8.8s, loss: 0.519\n","    Training Set - accuracy: 0.80, precision: 0.73, recall: 0.79, f1-score: 0.68,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.31, f1-score: 0.20,\n","(Epoch 99), time: 8.7s, loss: 0.511\n","    Training Set - accuracy: 0.88, precision: 0.77, recall: 0.87, f1-score: 0.78,\n","    Validation Set - accuracy: 0.35, precision: 0.30, recall: 0.30, f1-score: 0.25,\n","(Epoch 100), time: 8.8s, loss: 0.505\n","    Training Set - accuracy: 0.86, precision: 0.77, recall: 0.86, f1-score: 0.77,\n","    Validation Set - accuracy: 0.25, precision: 0.14, recall: 0.24, f1-score: 0.17,\n","(Epoch 101), time: 8.8s, loss: 0.496\n","    Training Set - accuracy: 0.86, precision: 0.76, recall: 0.86, f1-score: 0.77,\n","    Validation Set - accuracy: 0.33, precision: 0.23, recall: 0.29, f1-score: 0.21,\n"]}],"source":["lost_hist_folds = train_model_cv5(model, dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZazCaiIwQNM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"24afdd77-2848-4cd2-9958-aba3642047a4"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Initialization success if you see a tensor: tensor([[0.0817, 0.2310, 0.1790]], grad_fn=<AddmmBackward0>).\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 1 (val 0 - 42)\n","(Epoch 0), time: 8.8s, loss: 1.110\n","    Training Set - accuracy: 0.47, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","    Validation Set - accuracy: 0.82, precision: 0.27, recall: 0.33, f1-score: 0.30,\n","(Epoch 1), time: 8.7s, loss: 1.109\n","    Training Set - accuracy: 0.47, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","    Validation Set - accuracy: 0.82, precision: 0.27, recall: 0.33, f1-score: 0.30,\n","(Epoch 2), time: 8.7s, loss: 1.101\n","    Training Set - accuracy: 0.47, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","    Validation Set - accuracy: 0.82, precision: 0.27, recall: 0.33, f1-score: 0.30,\n","(Epoch 3), time: 8.8s, loss: 1.105\n","    Training Set - accuracy: 0.47, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","    Validation Set - accuracy: 0.82, precision: 0.27, recall: 0.33, f1-score: 0.30,\n","(Epoch 4), time: 8.8s, loss: 1.105\n","    Training Set - accuracy: 0.47, precision: 0.16, recall: 0.33, f1-score: 0.21,\n","    Validation Set - accuracy: 0.80, precision: 0.27, recall: 0.32, f1-score: 0.30,\n","(Epoch 5), time: 8.7s, loss: 1.101\n","    Training Set - accuracy: 0.47, precision: 0.29, recall: 0.34, f1-score: 0.24,\n","    Validation Set - accuracy: 0.80, precision: 0.39, recall: 0.38, f1-score: 0.38,\n","(Epoch 6), time: 8.8s, loss: 1.089\n","    Training Set - accuracy: 0.47, precision: 0.31, recall: 0.35, f1-score: 0.28,\n","    Validation Set - accuracy: 0.78, precision: 0.36, recall: 0.37, f1-score: 0.36,\n","(Epoch 7), time: 8.8s, loss: 1.104\n","    Training Set - accuracy: 0.44, precision: 0.28, recall: 0.34, f1-score: 0.31,\n","    Validation Set - accuracy: 0.75, precision: 0.38, recall: 0.42, f1-score: 0.39,\n","(Epoch 8), time: 8.8s, loss: 1.082\n","    Training Set - accuracy: 0.49, precision: 0.33, recall: 0.40, f1-score: 0.36,\n","    Validation Set - accuracy: 0.70, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","(Epoch 9), time: 8.7s, loss: 1.082\n","    Training Set - accuracy: 0.47, precision: 0.32, recall: 0.39, f1-score: 0.35,\n","    Validation Set - accuracy: 0.57, precision: 0.32, recall: 0.35, f1-score: 0.31,\n","(Epoch 10), time: 8.8s, loss: 1.076\n","    Training Set - accuracy: 0.53, precision: 0.36, recall: 0.44, f1-score: 0.38,\n","    Validation Set - accuracy: 0.62, precision: 0.37, recall: 0.42, f1-score: 0.35,\n","(Epoch 11), time: 8.7s, loss: 1.061\n","    Training Set - accuracy: 0.57, precision: 0.39, recall: 0.48, f1-score: 0.42,\n","    Validation Set - accuracy: 0.68, precision: 0.40, recall: 0.50, f1-score: 0.40,\n","(Epoch 12), time: 8.8s, loss: 1.047\n","    Training Set - accuracy: 0.56, precision: 0.39, recall: 0.48, f1-score: 0.41,\n","    Validation Set - accuracy: 0.65, precision: 0.37, recall: 0.43, f1-score: 0.36,\n","(Epoch 13), time: 8.8s, loss: 1.034\n","    Training Set - accuracy: 0.59, precision: 0.40, recall: 0.49, f1-score: 0.44,\n","    Validation Set - accuracy: 0.55, precision: 0.32, recall: 0.34, f1-score: 0.30,\n","(Epoch 14), time: 8.8s, loss: 1.020\n","    Training Set - accuracy: 0.60, precision: 0.41, recall: 0.50, f1-score: 0.44,\n","    Validation Set - accuracy: 0.50, precision: 0.31, recall: 0.32, f1-score: 0.28,\n","(Epoch 15), time: 8.8s, loss: 1.018\n","    Training Set - accuracy: 0.57, precision: 0.38, recall: 0.48, f1-score: 0.42,\n","    Validation Set - accuracy: 0.72, precision: 0.36, recall: 0.41, f1-score: 0.38,\n","(Epoch 16), time: 8.8s, loss: 1.002\n","    Training Set - accuracy: 0.62, precision: 0.42, recall: 0.52, f1-score: 0.45,\n","    Validation Set - accuracy: 0.68, precision: 0.27, recall: 0.27, f1-score: 0.27,\n","(Epoch 17), time: 8.8s, loss: 0.978\n","    Training Set - accuracy: 0.66, precision: 0.44, recall: 0.55, f1-score: 0.49,\n","    Validation Set - accuracy: 0.60, precision: 0.33, recall: 0.36, f1-score: 0.32,\n","(Epoch 18), time: 8.8s, loss: 0.960\n","    Training Set - accuracy: 0.69, precision: 0.46, recall: 0.57, f1-score: 0.51,\n","    Validation Set - accuracy: 0.57, precision: 0.32, recall: 0.35, f1-score: 0.31,\n","(Epoch 19), time: 8.8s, loss: 0.929\n","    Training Set - accuracy: 0.67, precision: 0.45, recall: 0.56, f1-score: 0.49,\n","    Validation Set - accuracy: 0.65, precision: 0.31, recall: 0.32, f1-score: 0.31,\n","(Epoch 20), time: 8.8s, loss: 0.908\n","    Training Set - accuracy: 0.71, precision: 0.48, recall: 0.59, f1-score: 0.53,\n","    Validation Set - accuracy: 0.72, precision: 0.37, recall: 0.41, f1-score: 0.37,\n","(Epoch 21), time: 8.8s, loss: 0.903\n","    Training Set - accuracy: 0.74, precision: 0.50, recall: 0.60, f1-score: 0.54,\n","    Validation Set - accuracy: 0.65, precision: 0.31, recall: 0.32, f1-score: 0.31,\n","(Epoch 22), time: 8.8s, loss: 0.895\n","    Training Set - accuracy: 0.72, precision: 0.48, recall: 0.59, f1-score: 0.53,\n","    Validation Set - accuracy: 0.72, precision: 0.33, recall: 0.35, f1-score: 0.34,\n","(Epoch 23), time: 8.8s, loss: 0.893\n","    Training Set - accuracy: 0.70, precision: 0.47, recall: 0.58, f1-score: 0.51,\n","    Validation Set - accuracy: 0.65, precision: 0.31, recall: 0.32, f1-score: 0.31,\n","(Epoch 24), time: 8.8s, loss: 0.857\n","    Training Set - accuracy: 0.76, precision: 0.52, recall: 0.62, f1-score: 0.56,\n","    Validation Set - accuracy: 0.75, precision: 0.34, recall: 0.36, f1-score: 0.35,\n","(Epoch 25), time: 8.7s, loss: 0.820\n","    Training Set - accuracy: 0.76, precision: 0.52, recall: 0.62, f1-score: 0.56,\n","    Validation Set - accuracy: 0.70, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","(Epoch 26), time: 8.8s, loss: 0.807\n","    Training Set - accuracy: 0.78, precision: 0.52, recall: 0.64, f1-score: 0.57,\n","    Validation Set - accuracy: 0.65, precision: 0.31, recall: 0.32, f1-score: 0.31,\n","(Epoch 27), time: 8.8s, loss: 0.793\n","    Training Set - accuracy: 0.77, precision: 0.52, recall: 0.63, f1-score: 0.57,\n","    Validation Set - accuracy: 0.72, precision: 0.36, recall: 0.41, f1-score: 0.38,\n","(Epoch 28), time: 8.7s, loss: 0.791\n","    Training Set - accuracy: 0.77, precision: 0.86, recall: 0.63, f1-score: 0.59,\n","    Validation Set - accuracy: 0.72, precision: 0.33, recall: 0.35, f1-score: 0.34,\n","(Epoch 29), time: 8.8s, loss: 0.737\n","    Training Set - accuracy: 0.81, precision: 0.88, recall: 0.67, f1-score: 0.64,\n","    Validation Set - accuracy: 0.65, precision: 0.31, recall: 0.32, f1-score: 0.31,\n","(Epoch 30), time: 8.8s, loss: 0.757\n","    Training Set - accuracy: 0.79, precision: 0.87, recall: 0.65, f1-score: 0.60,\n","    Validation Set - accuracy: 0.70, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","(Epoch 31), time: 8.8s, loss: 0.731\n","    Training Set - accuracy: 0.79, precision: 0.71, recall: 0.66, f1-score: 0.61,\n","    Validation Set - accuracy: 0.62, precision: 0.34, recall: 0.37, f1-score: 0.33,\n","(Epoch 32), time: 8.8s, loss: 0.786\n","    Training Set - accuracy: 0.78, precision: 0.86, recall: 0.65, f1-score: 0.61,\n","    Validation Set - accuracy: 0.78, precision: 0.35, recall: 0.37, f1-score: 0.36,\n","(Epoch 33), time: 8.8s, loss: 0.761\n","    Training Set - accuracy: 0.79, precision: 0.55, recall: 0.64, f1-score: 0.59,\n","    Validation Set - accuracy: 0.62, precision: 0.31, recall: 0.31, f1-score: 0.30,\n","(Epoch 34), time: 8.8s, loss: 0.728\n","    Training Set - accuracy: 0.79, precision: 0.55, recall: 0.65, f1-score: 0.59,\n","    Validation Set - accuracy: 0.72, precision: 0.37, recall: 0.41, f1-score: 0.38,\n","(Epoch 35), time: 8.8s, loss: 0.703\n","    Training Set - accuracy: 0.81, precision: 0.56, recall: 0.66, f1-score: 0.60,\n","    Validation Set - accuracy: 0.65, precision: 0.31, recall: 0.32, f1-score: 0.31,\n","(Epoch 36), time: 8.8s, loss: 0.702\n","    Training Set - accuracy: 0.81, precision: 0.90, recall: 0.67, f1-score: 0.63,\n","    Validation Set - accuracy: 0.72, precision: 0.39, recall: 0.46, f1-score: 0.40,\n","(Epoch 37), time: 8.8s, loss: 0.692\n","    Training Set - accuracy: 0.80, precision: 0.55, recall: 0.65, f1-score: 0.60,\n","    Validation Set - accuracy: 0.78, precision: 0.35, recall: 0.37, f1-score: 0.36,\n","(Epoch 38), time: 8.7s, loss: 0.700\n","    Training Set - accuracy: 0.81, precision: 0.89, recall: 0.66, f1-score: 0.62,\n","    Validation Set - accuracy: 0.70, precision: 0.32, recall: 0.34, f1-score: 0.33,\n","(Epoch 39), time: 8.8s, loss: 0.697\n","    Training Set - accuracy: 0.80, precision: 0.55, recall: 0.65, f1-score: 0.60,\n","    Validation Set - accuracy: 0.68, precision: 0.35, recall: 0.39, f1-score: 0.35,\n","(Epoch 40), time: 8.8s, loss: 0.693\n","    Training Set - accuracy: 0.81, precision: 0.89, recall: 0.68, f1-score: 0.64,\n","    Validation Set - accuracy: 0.70, precision: 0.32, recall: 0.34, f1-score: 0.33,\n","(Epoch 41), time: 8.8s, loss: 0.689\n","    Training Set - accuracy: 0.82, precision: 0.90, recall: 0.68, f1-score: 0.65,\n","    Validation Set - accuracy: 0.68, precision: 0.35, recall: 0.39, f1-score: 0.36,\n","(Epoch 42), time: 8.8s, loss: 0.692\n","    Training Set - accuracy: 0.81, precision: 0.56, recall: 0.66, f1-score: 0.60,\n","    Validation Set - accuracy: 0.62, precision: 0.34, recall: 0.37, f1-score: 0.33,\n","(Epoch 43), time: 8.7s, loss: 0.693\n","    Training Set - accuracy: 0.81, precision: 0.90, recall: 0.67, f1-score: 0.63,\n","    Validation Set - accuracy: 0.72, precision: 0.36, recall: 0.41, f1-score: 0.38,\n","(Epoch 44), time: 8.8s, loss: 0.683\n","    Training Set - accuracy: 0.82, precision: 0.90, recall: 0.68, f1-score: 0.65,\n","    Validation Set - accuracy: 0.68, precision: 0.32, recall: 0.33, f1-score: 0.32,\n","(Epoch 45), time: 8.8s, loss: 0.689\n","    Training Set - accuracy: 0.81, precision: 0.57, recall: 0.66, f1-score: 0.61,\n","    Validation Set - accuracy: 0.65, precision: 0.35, recall: 0.38, f1-score: 0.35,\n","(Epoch 46), time: 8.8s, loss: 0.674\n","    Training Set - accuracy: 0.82, precision: 0.90, recall: 0.68, f1-score: 0.65,\n","    Validation Set - accuracy: 0.65, precision: 0.37, recall: 0.43, f1-score: 0.37,\n","(Epoch 47), time: 8.8s, loss: 0.678\n","    Training Set - accuracy: 0.82, precision: 0.57, recall: 0.67, f1-score: 0.61,\n","    Validation Set - accuracy: 0.72, precision: 0.33, recall: 0.35, f1-score: 0.34,\n","(Epoch 48), time: 8.8s, loss: 0.673\n","    Training Set - accuracy: 0.82, precision: 0.74, recall: 0.67, f1-score: 0.63,\n","    Validation Set - accuracy: 0.72, precision: 0.36, recall: 0.41, f1-score: 0.38,\n","(Epoch 49), time: 8.7s, loss: 0.671\n","    Training Set - accuracy: 0.82, precision: 0.90, recall: 0.69, f1-score: 0.67,\n","    Validation Set - accuracy: 0.57, precision: 0.31, recall: 0.29, f1-score: 0.29,\n","(Epoch 50), time: 8.7s, loss: 0.668\n","    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.69, f1-score: 0.67,\n","    Validation Set - accuracy: 0.75, precision: 0.39, recall: 0.42, f1-score: 0.40,\n","(Epoch 51), time: 8.7s, loss: 0.667\n","    Training Set - accuracy: 0.83, precision: 0.91, recall: 0.69, f1-score: 0.66,\n","    Validation Set - accuracy: 0.70, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","(Epoch 52), time: 8.7s, loss: 0.665\n","    Training Set - accuracy: 0.83, precision: 0.85, recall: 0.71, f1-score: 0.70,\n","    Validation Set - accuracy: 0.72, precision: 0.36, recall: 0.41, f1-score: 0.38,\n","(Epoch 53), time: 8.7s, loss: 0.665\n","    Training Set - accuracy: 0.81, precision: 0.57, recall: 0.66, f1-score: 0.61,\n","    Validation Set - accuracy: 0.68, precision: 0.35, recall: 0.39, f1-score: 0.36,\n","(Epoch 54), time: 8.8s, loss: 0.659\n","    Training Set - accuracy: 0.83, precision: 0.91, recall: 0.69, f1-score: 0.66,\n","    Validation Set - accuracy: 0.68, precision: 0.35, recall: 0.39, f1-score: 0.36,\n","(Epoch 55), time: 8.7s, loss: 0.664\n","    Training Set - accuracy: 0.84, precision: 0.86, recall: 0.72, f1-score: 0.71,\n","    Validation Set - accuracy: 0.62, precision: 0.34, recall: 0.37, f1-score: 0.33,\n","(Epoch 56), time: 8.8s, loss: 0.659\n","    Training Set - accuracy: 0.81, precision: 0.74, recall: 0.67, f1-score: 0.63,\n","    Validation Set - accuracy: 0.65, precision: 0.35, recall: 0.38, f1-score: 0.35,\n","(Epoch 57), time: 8.8s, loss: 0.670\n","    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.70, f1-score: 0.69,\n","    Validation Set - accuracy: 0.82, precision: 0.40, recall: 0.39, f1-score: 0.39,\n","(Epoch 58), time: 8.8s, loss: 0.666\n","    Training Set - accuracy: 0.84, precision: 0.85, recall: 0.71, f1-score: 0.69,\n","    Validation Set - accuracy: 0.57, precision: 0.35, recall: 0.40, f1-score: 0.33,\n","(Epoch 59), time: 8.7s, loss: 0.682\n","    Training Set - accuracy: 0.82, precision: 0.79, recall: 0.68, f1-score: 0.65,\n","    Validation Set - accuracy: 0.60, precision: 0.38, recall: 0.47, f1-score: 0.36,\n","(Epoch 60), time: 8.7s, loss: 0.662\n","    Training Set - accuracy: 0.82, precision: 0.76, recall: 0.69, f1-score: 0.68,\n","    Validation Set - accuracy: 0.72, precision: 0.36, recall: 0.41, f1-score: 0.38,\n","(Epoch 61), time: 8.7s, loss: 0.656\n","    Training Set - accuracy: 0.82, precision: 0.77, recall: 0.71, f1-score: 0.70,\n","    Validation Set - accuracy: 0.68, precision: 0.35, recall: 0.39, f1-score: 0.36,\n","(Epoch 62), time: 8.8s, loss: 0.658\n","    Training Set - accuracy: 0.85, precision: 0.87, recall: 0.73, f1-score: 0.73,\n","    Validation Set - accuracy: 0.70, precision: 0.53, recall: 0.67, f1-score: 0.55,\n","(Epoch 63), time: 8.7s, loss: 0.664\n","    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.69, f1-score: 0.67,\n","    Validation Set - accuracy: 0.70, precision: 0.36, recall: 0.40, f1-score: 0.37,\n","(Epoch 64), time: 8.8s, loss: 0.655\n","    Training Set - accuracy: 0.84, precision: 0.79, recall: 0.74, f1-score: 0.75,\n","    Validation Set - accuracy: 0.65, precision: 0.35, recall: 0.38, f1-score: 0.35,\n","(Epoch 65), time: 8.8s, loss: 0.656\n","    Training Set - accuracy: 0.84, precision: 0.82, recall: 0.72, f1-score: 0.71,\n","    Validation Set - accuracy: 0.68, precision: 0.36, recall: 0.39, f1-score: 0.36,\n","(Epoch 66), time: 8.7s, loss: 0.652\n","    Training Set - accuracy: 0.86, precision: 0.86, recall: 0.75, f1-score: 0.76,\n","    Validation Set - accuracy: 0.68, precision: 0.39, recall: 0.44, f1-score: 0.39,\n","(Epoch 67), time: 8.7s, loss: 0.658\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.75, f1-score: 0.76,\n","    Validation Set - accuracy: 0.75, precision: 0.40, recall: 0.36, f1-score: 0.37,\n","(Epoch 68), time: 8.8s, loss: 0.707\n","    Training Set - accuracy: 0.84, precision: 0.86, recall: 0.76, f1-score: 0.78,\n","    Validation Set - accuracy: 0.55, precision: 0.43, recall: 0.49, f1-score: 0.41,\n","(Epoch 69), time: 8.7s, loss: 0.651\n","    Training Set - accuracy: 0.85, precision: 0.81, recall: 0.82, f1-score: 0.81,\n","    Validation Set - accuracy: 0.57, precision: 0.48, recall: 0.62, f1-score: 0.46,\n","(Epoch 70), time: 8.7s, loss: 0.647\n","    Training Set - accuracy: 0.86, precision: 0.83, recall: 0.80, f1-score: 0.81,\n","    Validation Set - accuracy: 0.65, precision: 0.57, recall: 0.65, f1-score: 0.55,\n","(Epoch 71), time: 8.8s, loss: 0.645\n","    Training Set - accuracy: 0.85, precision: 0.81, recall: 0.79, f1-score: 0.79,\n","    Validation Set - accuracy: 0.55, precision: 0.40, recall: 0.49, f1-score: 0.39,\n","(Epoch 72), time: 8.7s, loss: 0.658\n","    Training Set - accuracy: 0.86, precision: 0.82, recall: 0.81, f1-score: 0.82,\n","    Validation Set - accuracy: 0.62, precision: 0.47, recall: 0.52, f1-score: 0.44,\n","(Epoch 73), time: 8.7s, loss: 0.647\n","    Training Set - accuracy: 0.84, precision: 0.80, recall: 0.81, f1-score: 0.81,\n","    Validation Set - accuracy: 0.47, precision: 0.43, recall: 0.57, f1-score: 0.38,\n","(Epoch 74), time: 8.8s, loss: 0.643\n","    Training Set - accuracy: 0.85, precision: 0.81, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.57, precision: 0.39, recall: 0.45, f1-score: 0.36,\n","(Epoch 75), time: 8.7s, loss: 0.642\n","    Training Set - accuracy: 0.87, precision: 0.83, recall: 0.84, f1-score: 0.83,\n","    Validation Set - accuracy: 0.62, precision: 0.47, recall: 0.58, f1-score: 0.46,\n","(Epoch 76), time: 8.7s, loss: 0.633\n","    Training Set - accuracy: 0.85, precision: 0.82, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.47, precision: 0.43, recall: 0.52, f1-score: 0.37,\n","(Epoch 77), time: 8.7s, loss: 0.635\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.50, precision: 0.39, recall: 0.47, f1-score: 0.36,\n","(Epoch 78), time: 8.7s, loss: 0.627\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.84, f1-score: 0.81,\n","    Validation Set - accuracy: 0.45, precision: 0.41, recall: 0.51, f1-score: 0.35,\n","(Epoch 79), time: 8.7s, loss: 0.655\n","    Training Set - accuracy: 0.85, precision: 0.82, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.53, precision: 0.43, recall: 0.48, f1-score: 0.39,\n","(Epoch 80), time: 8.7s, loss: 0.638\n","    Training Set - accuracy: 0.80, precision: 0.78, recall: 0.81, f1-score: 0.78,\n","    Validation Set - accuracy: 0.45, precision: 0.42, recall: 0.51, f1-score: 0.36,\n","(Epoch 81), time: 8.8s, loss: 0.629\n","    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.83, f1-score: 0.80,\n","    Validation Set - accuracy: 0.53, precision: 0.44, recall: 0.54, f1-score: 0.40,\n","(Epoch 82), time: 8.8s, loss: 0.620\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.84, f1-score: 0.81,\n","    Validation Set - accuracy: 0.50, precision: 0.45, recall: 0.53, f1-score: 0.40,\n","(Epoch 83), time: 8.7s, loss: 0.616\n","    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.83, f1-score: 0.80,\n","    Validation Set - accuracy: 0.53, precision: 0.44, recall: 0.54, f1-score: 0.41,\n","(Epoch 84), time: 8.7s, loss: 0.608\n","    Training Set - accuracy: 0.84, precision: 0.82, recall: 0.85, f1-score: 0.82,\n","    Validation Set - accuracy: 0.50, precision: 0.43, recall: 0.53, f1-score: 0.38,\n","(Epoch 85), time: 8.8s, loss: 0.610\n","    Training Set - accuracy: 0.83, precision: 0.81, recall: 0.84, f1-score: 0.81,\n","    Validation Set - accuracy: 0.47, precision: 0.38, recall: 0.46, f1-score: 0.34,\n","(Epoch 86), time: 8.8s, loss: 0.608\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.84, f1-score: 0.81,\n","    Validation Set - accuracy: 0.50, precision: 0.44, recall: 0.53, f1-score: 0.39,\n","(Epoch 87), time: 8.8s, loss: 0.608\n","    Training Set - accuracy: 0.85, precision: 0.82, recall: 0.85, f1-score: 0.83,\n","    Validation Set - accuracy: 0.53, precision: 0.42, recall: 0.48, f1-score: 0.38,\n","(Epoch 88), time: 8.8s, loss: 0.599\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.45, precision: 0.42, recall: 0.51, f1-score: 0.35,\n","(Epoch 89), time: 8.7s, loss: 0.601\n","    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.83, f1-score: 0.80,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.35,\n","(Epoch 90), time: 8.7s, loss: 0.597\n","    Training Set - accuracy: 0.86, precision: 0.83, recall: 0.86, f1-score: 0.84,\n","    Validation Set - accuracy: 0.45, precision: 0.38, recall: 0.45, f1-score: 0.33,\n","(Epoch 91), time: 8.7s, loss: 0.591\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.47, f1-score: 0.36,\n","(Epoch 92), time: 8.7s, loss: 0.590\n","    Training Set - accuracy: 0.84, precision: 0.82, recall: 0.85, f1-score: 0.82,\n","    Validation Set - accuracy: 0.45, precision: 0.40, recall: 0.45, f1-score: 0.34,\n","(Epoch 93), time: 8.8s, loss: 0.582\n","    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.83, f1-score: 0.80,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.34,\n","(Epoch 94), time: 8.7s, loss: 0.590\n","    Training Set - accuracy: 0.87, precision: 0.84, recall: 0.86, f1-score: 0.85,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.35,\n","(Epoch 95), time: 8.7s, loss: 0.587\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.47, precision: 0.40, recall: 0.46, f1-score: 0.35,\n","(Epoch 96), time: 8.7s, loss: 0.577\n","    Training Set - accuracy: 0.86, precision: 0.83, recall: 0.86, f1-score: 0.83,\n","    Validation Set - accuracy: 0.45, precision: 0.41, recall: 0.45, f1-score: 0.35,\n","(Epoch 97), time: 8.7s, loss: 0.573\n","    Training Set - accuracy: 0.88, precision: 0.85, recall: 0.88, f1-score: 0.85,\n","    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.47, f1-score: 0.36,\n","(Epoch 98), time: 8.8s, loss: 0.567\n","    Training Set - accuracy: 0.87, precision: 0.84, recall: 0.86, f1-score: 0.85,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.34,\n","(Epoch 99), time: 8.7s, loss: 0.558\n","    Training Set - accuracy: 0.88, precision: 0.85, recall: 0.87, f1-score: 0.86,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.34,\n","(Epoch 100), time: 8.8s, loss: 0.561\n","    Training Set - accuracy: 0.87, precision: 0.84, recall: 0.86, f1-score: 0.85,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.35,\n","(Epoch 101), time: 8.8s, loss: 0.556\n","    Training Set - accuracy: 0.89, precision: 0.86, recall: 0.88, f1-score: 0.86,\n","    Validation Set - accuracy: 0.45, precision: 0.38, recall: 0.45, f1-score: 0.33,\n","(Epoch 102), time: 8.7s, loss: 0.554\n","    Training Set - accuracy: 0.86, precision: 0.83, recall: 0.86, f1-score: 0.83,\n","    Validation Set - accuracy: 0.50, precision: 0.39, recall: 0.47, f1-score: 0.36,\n","(Epoch 103), time: 8.7s, loss: 0.549\n","    Training Set - accuracy: 0.91, precision: 0.88, recall: 0.90, f1-score: 0.89,\n","    Validation Set - accuracy: 0.42, precision: 0.38, recall: 0.44, f1-score: 0.32,\n","(Epoch 104), time: 8.7s, loss: 0.545\n","    Training Set - accuracy: 0.89, precision: 0.86, recall: 0.88, f1-score: 0.86,\n","    Validation Set - accuracy: 0.53, precision: 0.40, recall: 0.48, f1-score: 0.37,\n","(Epoch 105), time: 8.7s, loss: 0.542\n","    Training Set - accuracy: 0.89, precision: 0.86, recall: 0.88, f1-score: 0.87,\n","    Validation Set - accuracy: 0.47, precision: 0.40, recall: 0.46, f1-score: 0.35,\n","(Epoch 106), time: 8.7s, loss: 0.532\n","    Training Set - accuracy: 0.90, precision: 0.87, recall: 0.89, f1-score: 0.88,\n","    Validation Set - accuracy: 0.45, precision: 0.38, recall: 0.45, f1-score: 0.33,\n","(Epoch 107), time: 8.7s, loss: 0.534\n","    Training Set - accuracy: 0.90, precision: 0.87, recall: 0.89, f1-score: 0.88,\n","    Validation Set - accuracy: 0.53, precision: 0.41, recall: 0.48, f1-score: 0.38,\n","(Epoch 108), time: 8.8s, loss: 0.524\n","    Training Set - accuracy: 0.93, precision: 0.91, recall: 0.91, f1-score: 0.91,\n","    Validation Set - accuracy: 0.50, precision: 0.44, recall: 0.53, f1-score: 0.39,\n","(Epoch 109), time: 8.8s, loss: 0.528\n","    Training Set - accuracy: 0.88, precision: 0.85, recall: 0.87, f1-score: 0.86,\n","    Validation Set - accuracy: 0.47, precision: 0.40, recall: 0.46, f1-score: 0.35,\n","(Epoch 110), time: 8.7s, loss: 0.523\n","    Training Set - accuracy: 0.93, precision: 0.90, recall: 0.90, f1-score: 0.90,\n","    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.47, f1-score: 0.36,\n","(Epoch 111), time: 8.7s, loss: 0.526\n","    Training Set - accuracy: 0.92, precision: 0.89, recall: 0.91, f1-score: 0.90,\n","    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.47, f1-score: 0.36,\n","(Epoch 112), time: 8.8s, loss: 0.516\n","    Training Set - accuracy: 0.91, precision: 0.89, recall: 0.90, f1-score: 0.89,\n","    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.47, f1-score: 0.36,\n","(Epoch 113), time: 8.8s, loss: 0.508\n","    Training Set - accuracy: 0.94, precision: 0.92, recall: 0.92, f1-score: 0.92,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.34,\n","(Epoch 114), time: 8.7s, loss: 0.508\n","    Training Set - accuracy: 0.92, precision: 0.90, recall: 0.90, f1-score: 0.90,\n","    Validation Set - accuracy: 0.55, precision: 0.41, recall: 0.49, f1-score: 0.39,\n","(Epoch 115), time: 8.7s, loss: 0.503\n","    Training Set - accuracy: 0.93, precision: 0.91, recall: 0.91, f1-score: 0.91,\n","    Validation Set - accuracy: 0.47, precision: 0.39, recall: 0.46, f1-score: 0.34,\n","(Epoch 116), time: 8.7s, loss: 0.483\n","    Training Set - accuracy: 0.93, precision: 0.91, recall: 0.92, f1-score: 0.91,\n","    Validation Set - accuracy: 0.53, precision: 0.44, recall: 0.54, f1-score: 0.40,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 2 (val 43 - 84)\n","(Epoch 0), time: 8.8s, loss: 1.128\n","    Training Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.07, precision: 0.02, recall: 0.33, f1-score: 0.05,\n","(Epoch 1), time: 8.7s, loss: 1.123\n","    Training Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.07, precision: 0.02, recall: 0.33, f1-score: 0.05,\n","(Epoch 2), time: 8.8s, loss: 1.120\n","    Training Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.07, precision: 0.02, recall: 0.33, f1-score: 0.05,\n","(Epoch 3), time: 8.7s, loss: 1.120\n","    Training Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.07, precision: 0.02, recall: 0.33, f1-score: 0.05,\n","(Epoch 4), time: 8.8s, loss: 1.120\n","    Training Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.07, precision: 0.02, recall: 0.33, f1-score: 0.05,\n","(Epoch 5), time: 8.7s, loss: 1.114\n","    Training Set - accuracy: 0.18, precision: 0.14, recall: 0.34, f1-score: 0.11,\n","    Validation Set - accuracy: 0.07, precision: 0.13, recall: 0.26, f1-score: 0.09,\n","(Epoch 6), time: 8.8s, loss: 1.114\n","    Training Set - accuracy: 0.22, precision: 0.20, recall: 0.36, f1-score: 0.20,\n","    Validation Set - accuracy: 0.10, precision: 0.07, recall: 0.22, f1-score: 0.10,\n","(Epoch 7), time: 8.8s, loss: 1.109\n","    Training Set - accuracy: 0.31, precision: 0.19, recall: 0.40, f1-score: 0.26,\n","    Validation Set - accuracy: 0.23, precision: 0.08, recall: 0.33, f1-score: 0.13,\n","(Epoch 8), time: 8.8s, loss: 1.100\n","    Training Set - accuracy: 0.32, precision: 0.17, recall: 0.35, f1-score: 0.20,\n","    Validation Set - accuracy: 0.23, precision: 0.07, recall: 0.33, f1-score: 0.12,\n","(Epoch 9), time: 8.7s, loss: 1.092\n","    Training Set - accuracy: 0.33, precision: 0.24, recall: 0.37, f1-score: 0.23,\n","    Validation Set - accuracy: 0.23, precision: 0.34, recall: 0.38, f1-score: 0.24,\n","(Epoch 10), time: 8.7s, loss: 1.078\n","    Training Set - accuracy: 0.34, precision: 0.50, recall: 0.40, f1-score: 0.28,\n","    Validation Set - accuracy: 0.23, precision: 0.26, recall: 0.26, f1-score: 0.16,\n","(Epoch 11), time: 8.7s, loss: 1.068\n","    Training Set - accuracy: 0.39, precision: 0.51, recall: 0.43, f1-score: 0.38,\n","    Validation Set - accuracy: 0.33, precision: 0.40, recall: 0.43, f1-score: 0.31,\n","(Epoch 12), time: 8.7s, loss: 1.065\n","    Training Set - accuracy: 0.48, precision: 0.55, recall: 0.51, f1-score: 0.47,\n","    Validation Set - accuracy: 0.33, precision: 0.31, recall: 0.31, f1-score: 0.23,\n","(Epoch 13), time: 8.8s, loss: 1.048\n","    Training Set - accuracy: 0.52, precision: 0.55, recall: 0.52, f1-score: 0.51,\n","    Validation Set - accuracy: 0.42, precision: 0.30, recall: 0.30, f1-score: 0.28,\n","(Epoch 14), time: 8.8s, loss: 1.028\n","    Training Set - accuracy: 0.56, precision: 0.56, recall: 0.58, f1-score: 0.56,\n","    Validation Set - accuracy: 0.35, precision: 0.38, recall: 0.34, f1-score: 0.26,\n","(Epoch 15), time: 8.7s, loss: 1.013\n","    Training Set - accuracy: 0.61, precision: 0.58, recall: 0.62, f1-score: 0.59,\n","    Validation Set - accuracy: 0.38, precision: 0.28, recall: 0.25, f1-score: 0.25,\n","(Epoch 16), time: 8.7s, loss: 0.979\n","    Training Set - accuracy: 0.64, precision: 0.63, recall: 0.68, f1-score: 0.64,\n","    Validation Set - accuracy: 0.25, precision: 0.24, recall: 0.19, f1-score: 0.18,\n","(Epoch 17), time: 8.7s, loss: 0.961\n","    Training Set - accuracy: 0.54, precision: 0.58, recall: 0.61, f1-score: 0.56,\n","    Validation Set - accuracy: 0.40, precision: 0.29, recall: 0.27, f1-score: 0.27,\n","(Epoch 18), time: 8.7s, loss: 0.908\n","    Training Set - accuracy: 0.65, precision: 0.66, recall: 0.69, f1-score: 0.66,\n","    Validation Set - accuracy: 0.53, precision: 0.37, recall: 0.38, f1-score: 0.35,\n","(Epoch 19), time: 8.7s, loss: 0.862\n","    Training Set - accuracy: 0.65, precision: 0.67, recall: 0.72, f1-score: 0.67,\n","    Validation Set - accuracy: 0.35, precision: 0.29, recall: 0.22, f1-score: 0.24,\n","(Epoch 20), time: 8.8s, loss: 0.836\n","    Training Set - accuracy: 0.69, precision: 0.72, recall: 0.75, f1-score: 0.71,\n","    Validation Set - accuracy: 0.45, precision: 0.33, recall: 0.31, f1-score: 0.30,\n","(Epoch 21), time: 8.7s, loss: 0.800\n","    Training Set - accuracy: 0.71, precision: 0.72, recall: 0.76, f1-score: 0.73,\n","    Validation Set - accuracy: 0.45, precision: 0.31, recall: 0.29, f1-score: 0.28,\n","(Epoch 22), time: 8.7s, loss: 0.789\n","    Training Set - accuracy: 0.69, precision: 0.69, recall: 0.76, f1-score: 0.70,\n","    Validation Set - accuracy: 0.33, precision: 0.42, recall: 0.38, f1-score: 0.22,\n","(Epoch 23), time: 8.7s, loss: 0.781\n","    Training Set - accuracy: 0.64, precision: 0.65, recall: 0.71, f1-score: 0.65,\n","    Validation Set - accuracy: 0.38, precision: 0.42, recall: 0.40, f1-score: 0.26,\n","(Epoch 24), time: 8.7s, loss: 0.811\n","    Training Set - accuracy: 0.64, precision: 0.69, recall: 0.67, f1-score: 0.66,\n","    Validation Set - accuracy: 0.50, precision: 0.27, recall: 0.26, f1-score: 0.27,\n","(Epoch 25), time: 8.7s, loss: 0.696\n","    Training Set - accuracy: 0.76, precision: 0.77, recall: 0.81, f1-score: 0.78,\n","    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.28, f1-score: 0.25,\n","(Epoch 26), time: 8.7s, loss: 0.651\n","    Training Set - accuracy: 0.81, precision: 0.82, recall: 0.86, f1-score: 0.83,\n","    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.28, f1-score: 0.25,\n","(Epoch 27), time: 8.7s, loss: 0.638\n","    Training Set - accuracy: 0.78, precision: 0.80, recall: 0.84, f1-score: 0.80,\n","    Validation Set - accuracy: 0.45, precision: 0.33, recall: 0.34, f1-score: 0.30,\n","(Epoch 28), time: 8.7s, loss: 0.601\n","    Training Set - accuracy: 0.82, precision: 0.83, recall: 0.87, f1-score: 0.83,\n","    Validation Set - accuracy: 0.47, precision: 0.31, recall: 0.33, f1-score: 0.30,\n","(Epoch 29), time: 8.7s, loss: 0.550\n","    Training Set - accuracy: 0.86, precision: 0.87, recall: 0.90, f1-score: 0.87,\n","    Validation Set - accuracy: 0.50, precision: 0.29, recall: 0.29, f1-score: 0.29,\n","(Epoch 30), time: 8.8s, loss: 0.521\n","    Training Set - accuracy: 0.89, precision: 0.90, recall: 0.93, f1-score: 0.91,\n","    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.34, f1-score: 0.33,\n","(Epoch 31), time: 8.7s, loss: 0.505\n","    Training Set - accuracy: 0.88, precision: 0.88, recall: 0.92, f1-score: 0.89,\n","    Validation Set - accuracy: 0.50, precision: 0.31, recall: 0.31, f1-score: 0.30,\n","(Epoch 32), time: 8.7s, loss: 0.475\n","    Training Set - accuracy: 0.90, precision: 0.90, recall: 0.93, f1-score: 0.91,\n","    Validation Set - accuracy: 0.55, precision: 0.36, recall: 0.39, f1-score: 0.35,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 (val 85 - 126)\n","(Epoch 0), time: 8.8s, loss: 1.094\n","    Training Set - accuracy: 0.57, precision: 0.20, recall: 0.32, f1-score: 0.24,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 1), time: 8.7s, loss: 1.100\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 2), time: 8.7s, loss: 1.085\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 3), time: 8.7s, loss: 1.086\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 4), time: 8.7s, loss: 1.090\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 5), time: 8.7s, loss: 1.085\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 6), time: 8.8s, loss: 1.082\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 7), time: 8.7s, loss: 1.078\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 8), time: 8.7s, loss: 1.072\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 9), time: 8.7s, loss: 1.070\n","    Training Set - accuracy: 0.59, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.40, precision: 0.46, recall: 0.35, f1-score: 0.22,\n","(Epoch 10), time: 8.8s, loss: 1.054\n","    Training Set - accuracy: 0.60, precision: 0.37, recall: 0.34, f1-score: 0.26,\n","    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.33, f1-score: 0.21,\n","(Epoch 11), time: 8.8s, loss: 1.028\n","    Training Set - accuracy: 0.66, precision: 0.42, recall: 0.43, f1-score: 0.40,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.37, f1-score: 0.32,\n","(Epoch 12), time: 8.8s, loss: 0.994\n","    Training Set - accuracy: 0.65, precision: 0.40, recall: 0.45, f1-score: 0.42,\n","    Validation Set - accuracy: 0.47, precision: 0.32, recall: 0.41, f1-score: 0.35,\n","(Epoch 13), time: 8.8s, loss: 0.974\n","    Training Set - accuracy: 0.66, precision: 0.42, recall: 0.49, f1-score: 0.45,\n","    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.43, f1-score: 0.38,\n","(Epoch 14), time: 8.7s, loss: 0.927\n","    Training Set - accuracy: 0.68, precision: 0.43, recall: 0.51, f1-score: 0.46,\n","    Validation Set - accuracy: 0.45, precision: 0.30, recall: 0.39, f1-score: 0.34,\n","(Epoch 15), time: 8.7s, loss: 0.888\n","    Training Set - accuracy: 0.69, precision: 0.45, recall: 0.53, f1-score: 0.47,\n","    Validation Set - accuracy: 0.53, precision: 0.35, recall: 0.45, f1-score: 0.39,\n","(Epoch 16), time: 8.8s, loss: 0.846\n","    Training Set - accuracy: 0.73, precision: 0.47, recall: 0.56, f1-score: 0.50,\n","    Validation Set - accuracy: 0.50, precision: 0.33, recall: 0.43, f1-score: 0.37,\n","(Epoch 17), time: 8.8s, loss: 0.812\n","    Training Set - accuracy: 0.73, precision: 0.47, recall: 0.55, f1-score: 0.50,\n","    Validation Set - accuracy: 0.50, precision: 0.33, recall: 0.43, f1-score: 0.37,\n","(Epoch 18), time: 8.8s, loss: 0.786\n","    Training Set - accuracy: 0.75, precision: 0.48, recall: 0.57, f1-score: 0.51,\n","    Validation Set - accuracy: 0.45, precision: 0.30, recall: 0.39, f1-score: 0.34,\n","(Epoch 19), time: 8.7s, loss: 0.748\n","    Training Set - accuracy: 0.77, precision: 0.50, recall: 0.59, f1-score: 0.53,\n","    Validation Set - accuracy: 0.38, precision: 0.25, recall: 0.33, f1-score: 0.27,\n","(Epoch 20), time: 8.7s, loss: 0.716\n","    Training Set - accuracy: 0.77, precision: 0.50, recall: 0.60, f1-score: 0.53,\n","    Validation Set - accuracy: 0.40, precision: 0.27, recall: 0.35, f1-score: 0.29,\n","(Epoch 21), time: 8.7s, loss: 0.721\n","    Training Set - accuracy: 0.76, precision: 0.49, recall: 0.58, f1-score: 0.52,\n","    Validation Set - accuracy: 0.47, precision: 0.31, recall: 0.40, f1-score: 0.34,\n","(Epoch 22), time: 8.7s, loss: 0.670\n","    Training Set - accuracy: 0.81, precision: 0.52, recall: 0.62, f1-score: 0.56,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.36, f1-score: 0.31,\n","(Epoch 23), time: 8.7s, loss: 0.658\n","    Training Set - accuracy: 0.79, precision: 0.51, recall: 0.60, f1-score: 0.55,\n","    Validation Set - accuracy: 0.38, precision: 0.25, recall: 0.33, f1-score: 0.28,\n","(Epoch 24), time: 8.8s, loss: 0.620\n","    Training Set - accuracy: 0.81, precision: 0.53, recall: 0.63, f1-score: 0.56,\n","    Validation Set - accuracy: 0.40, precision: 0.26, recall: 0.35, f1-score: 0.29,\n","(Epoch 25), time: 8.8s, loss: 0.601\n","    Training Set - accuracy: 0.81, precision: 0.52, recall: 0.62, f1-score: 0.56,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.37, f1-score: 0.32,\n","(Epoch 26), time: 8.8s, loss: 0.570\n","    Training Set - accuracy: 0.83, precision: 0.53, recall: 0.64, f1-score: 0.58,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.36, f1-score: 0.32,\n","(Epoch 27), time: 8.8s, loss: 0.540\n","    Training Set - accuracy: 0.83, precision: 0.54, recall: 0.64, f1-score: 0.58,\n","    Validation Set - accuracy: 0.45, precision: 0.30, recall: 0.39, f1-score: 0.34,\n","(Epoch 28), time: 8.7s, loss: 0.524\n","    Training Set - accuracy: 0.84, precision: 0.54, recall: 0.65, f1-score: 0.58,\n","    Validation Set - accuracy: 0.38, precision: 0.25, recall: 0.33, f1-score: 0.27,\n","(Epoch 29), time: 8.7s, loss: 0.509\n","    Training Set - accuracy: 0.85, precision: 0.55, recall: 0.65, f1-score: 0.59,\n","    Validation Set - accuracy: 0.40, precision: 0.27, recall: 0.35, f1-score: 0.30,\n","(Epoch 30), time: 8.8s, loss: 0.498\n","    Training Set - accuracy: 0.85, precision: 0.55, recall: 0.65, f1-score: 0.59,\n","    Validation Set - accuracy: 0.53, precision: 0.35, recall: 0.45, f1-score: 0.39,\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 (val 127 - 168)\n","(Epoch 0), time: 8.8s, loss: 1.087\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 1), time: 8.7s, loss: 1.086\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 2), time: 8.7s, loss: 1.083\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 3), time: 8.8s, loss: 1.086\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 4), time: 8.7s, loss: 1.086\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 5), time: 8.7s, loss: 1.084\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 6), time: 8.7s, loss: 1.086\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 7), time: 8.8s, loss: 1.079\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 8), time: 8.7s, loss: 1.090\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 9), time: 8.7s, loss: 1.081\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 10), time: 8.7s, loss: 1.081\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 11), time: 8.7s, loss: 1.079\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 12), time: 8.7s, loss: 1.073\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 13), time: 8.7s, loss: 1.070\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 14), time: 8.8s, loss: 1.058\n","    Training Set - accuracy: 0.58, precision: 0.53, recall: 0.34, f1-score: 0.26,\n","    Validation Set - accuracy: 0.42, precision: 0.15, recall: 0.31, f1-score: 0.20,\n","(Epoch 15), time: 8.7s, loss: 1.042\n","    Training Set - accuracy: 0.58, precision: 0.42, recall: 0.34, f1-score: 0.27,\n","    Validation Set - accuracy: 0.45, precision: 0.32, recall: 0.34, f1-score: 0.25,\n","(Epoch 16), time: 8.7s, loss: 1.026\n","    Training Set - accuracy: 0.55, precision: 0.24, recall: 0.32, f1-score: 0.25,\n","    Validation Set - accuracy: 0.33, precision: 0.13, recall: 0.24, f1-score: 0.17,\n","(Epoch 17), time: 8.8s, loss: 1.025\n","    Training Set - accuracy: 0.59, precision: 0.39, recall: 0.39, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.29, f1-score: 0.22,\n","(Epoch 18), time: 8.7s, loss: 0.997\n","    Training Set - accuracy: 0.58, precision: 0.37, recall: 0.39, f1-score: 0.37,\n","    Validation Set - accuracy: 0.33, precision: 0.21, recall: 0.29, f1-score: 0.24,\n","(Epoch 19), time: 8.8s, loss: 1.006\n","    Training Set - accuracy: 0.49, precision: 0.32, recall: 0.37, f1-score: 0.34,\n","    Validation Set - accuracy: 0.40, precision: 0.22, recall: 0.31, f1-score: 0.25,\n","(Epoch 20), time: 8.7s, loss: 0.986\n","    Training Set - accuracy: 0.59, precision: 0.38, recall: 0.42, f1-score: 0.40,\n","    Validation Set - accuracy: 0.35, precision: 0.24, recall: 0.31, f1-score: 0.27,\n","(Epoch 21), time: 8.8s, loss: 0.966\n","    Training Set - accuracy: 0.56, precision: 0.36, recall: 0.42, f1-score: 0.39,\n","    Validation Set - accuracy: 0.35, precision: 0.26, recall: 0.32, f1-score: 0.27,\n","(Epoch 22), time: 8.7s, loss: 0.949\n","    Training Set - accuracy: 0.52, precision: 0.34, recall: 0.41, f1-score: 0.37,\n","    Validation Set - accuracy: 0.28, precision: 0.21, recall: 0.28, f1-score: 0.20,\n","(Epoch 23), time: 8.7s, loss: 0.949\n","    Training Set - accuracy: 0.44, precision: 0.29, recall: 0.36, f1-score: 0.31,\n","    Validation Set - accuracy: 0.40, precision: 0.27, recall: 0.35, f1-score: 0.30,\n","(Epoch 24), time: 8.7s, loss: 0.930\n","    Training Set - accuracy: 0.56, precision: 0.37, recall: 0.44, f1-score: 0.40,\n","    Validation Set - accuracy: 0.42, precision: 0.36, recall: 0.42, f1-score: 0.32,\n","(Epoch 25), time: 8.7s, loss: 0.898\n","    Training Set - accuracy: 0.52, precision: 0.35, recall: 0.42, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.26, recall: 0.34, f1-score: 0.29,\n","(Epoch 26), time: 8.7s, loss: 0.867\n","    Training Set - accuracy: 0.57, precision: 0.70, recall: 0.46, f1-score: 0.46,\n","    Validation Set - accuracy: 0.40, precision: 0.26, recall: 0.34, f1-score: 0.29,\n","(Epoch 27), time: 8.8s, loss: 0.855\n","    Training Set - accuracy: 0.65, precision: 0.70, recall: 0.55, f1-score: 0.57,\n","    Validation Set - accuracy: 0.35, precision: 0.25, recall: 0.30, f1-score: 0.27,\n","(Epoch 28), time: 8.8s, loss: 0.809\n","    Training Set - accuracy: 0.65, precision: 0.66, recall: 0.67, f1-score: 0.66,\n","    Validation Set - accuracy: 0.38, precision: 0.31, recall: 0.35, f1-score: 0.29,\n","(Epoch 29), time: 8.7s, loss: 0.763\n","    Training Set - accuracy: 0.67, precision: 0.72, recall: 0.72, f1-score: 0.70,\n","    Validation Set - accuracy: 0.45, precision: 0.30, recall: 0.38, f1-score: 0.33,\n","(Epoch 30), time: 8.7s, loss: 0.727\n","    Training Set - accuracy: 0.74, precision: 0.72, recall: 0.81, f1-score: 0.74,\n","    Validation Set - accuracy: 0.30, precision: 0.21, recall: 0.30, f1-score: 0.23,\n","(Epoch 31), time: 8.7s, loss: 0.721\n","    Training Set - accuracy: 0.66, precision: 0.72, recall: 0.77, f1-score: 0.71,\n","    Validation Set - accuracy: 0.38, precision: 0.38, recall: 0.35, f1-score: 0.33,\n","(Epoch 32), time: 8.8s, loss: 0.686\n","    Training Set - accuracy: 0.74, precision: 0.77, recall: 0.83, f1-score: 0.77,\n","    Validation Set - accuracy: 0.45, precision: 0.52, recall: 0.43, f1-score: 0.39,\n","(Epoch 33), time: 8.7s, loss: 0.676\n","    Training Set - accuracy: 0.71, precision: 0.75, recall: 0.82, f1-score: 0.73,\n","    Validation Set - accuracy: 0.50, precision: 0.54, recall: 0.46, f1-score: 0.46,\n","(Epoch 34), time: 8.8s, loss: 0.663\n","    Training Set - accuracy: 0.75, precision: 0.78, recall: 0.83, f1-score: 0.78,\n","    Validation Set - accuracy: 0.45, precision: 0.32, recall: 0.41, f1-score: 0.35,\n","(Epoch 35), time: 8.7s, loss: 0.631\n","    Training Set - accuracy: 0.77, precision: 0.80, recall: 0.85, f1-score: 0.80,\n","    Validation Set - accuracy: 0.38, precision: 0.38, recall: 0.35, f1-score: 0.33,\n","(Epoch 36), time: 8.8s, loss: 0.619\n","    Training Set - accuracy: 0.78, precision: 0.80, recall: 0.85, f1-score: 0.81,\n","    Validation Set - accuracy: 0.45, precision: 0.46, recall: 0.40, f1-score: 0.38,\n","(Epoch 37), time: 8.7s, loss: 0.578\n","    Training Set - accuracy: 0.78, precision: 0.83, recall: 0.86, f1-score: 0.82,\n","    Validation Set - accuracy: 0.40, precision: 0.31, recall: 0.36, f1-score: 0.32,\n","(Epoch 38), time: 8.7s, loss: 0.568\n","    Training Set - accuracy: 0.81, precision: 0.82, recall: 0.88, f1-score: 0.84,\n","    Validation Set - accuracy: 0.47, precision: 0.32, recall: 0.43, f1-score: 0.36,\n","(Epoch 39), time: 8.7s, loss: 0.539\n","    Training Set - accuracy: 0.81, precision: 0.84, recall: 0.88, f1-score: 0.84,\n","    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.44, f1-score: 0.38,\n","(Epoch 40), time: 8.7s, loss: 0.531\n","    Training Set - accuracy: 0.82, precision: 0.84, recall: 0.88, f1-score: 0.85,\n","    Validation Set - accuracy: 0.38, precision: 0.26, recall: 0.31, f1-score: 0.28,\n","(Epoch 41), time: 8.8s, loss: 0.509\n","    Training Set - accuracy: 0.85, precision: 0.87, recall: 0.90, f1-score: 0.88,\n","    Validation Set - accuracy: 0.45, precision: 0.31, recall: 0.41, f1-score: 0.35,\n","(Epoch 42), time: 8.7s, loss: 0.502\n","    Training Set - accuracy: 0.85, precision: 0.89, recall: 0.91, f1-score: 0.88,\n","    Validation Set - accuracy: 0.40, precision: 0.39, recall: 0.37, f1-score: 0.35,\n","(Epoch 43), time: 8.7s, loss: 0.490\n","    Training Set - accuracy: 0.87, precision: 0.87, recall: 0.92, f1-score: 0.89,\n","    Validation Set - accuracy: 0.40, precision: 0.27, recall: 0.34, f1-score: 0.30,\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 (val 169 - 210)\n","(Epoch 0), time: 8.8s, loss: 1.118\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.20, precision: 0.39, recall: 0.36, f1-score: 0.15,\n","(Epoch 1), time: 8.8s, loss: 1.112\n","    Training Set - accuracy: 0.17, precision: 0.18, recall: 0.33, f1-score: 0.11,\n","    Validation Set - accuracy: 0.23, precision: 0.39, recall: 0.38, f1-score: 0.19,\n","(Epoch 2), time: 8.7s, loss: 1.110\n","    Training Set - accuracy: 0.20, precision: 0.24, recall: 0.35, f1-score: 0.14,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 3), time: 8.7s, loss: 1.108\n","    Training Set - accuracy: 0.21, precision: 0.22, recall: 0.35, f1-score: 0.16,\n","    Validation Set - accuracy: 0.23, precision: 0.23, recall: 0.36, f1-score: 0.20,\n","(Epoch 4), time: 8.8s, loss: 1.105\n","    Training Set - accuracy: 0.25, precision: 0.21, recall: 0.30, f1-score: 0.19,\n","    Validation Set - accuracy: 0.25, precision: 0.18, recall: 0.36, f1-score: 0.22,\n","(Epoch 5), time: 8.7s, loss: 1.104\n","    Training Set - accuracy: 0.51, precision: 0.24, recall: 0.33, f1-score: 0.28,\n","    Validation Set - accuracy: 0.35, precision: 0.20, recall: 0.36, f1-score: 0.23,\n","(Epoch 6), time: 8.7s, loss: 1.100\n","    Training Set - accuracy: 0.60, precision: 0.37, recall: 0.34, f1-score: 0.27,\n","    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n","(Epoch 7), time: 8.7s, loss: 1.093\n","    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n","(Epoch 8), time: 8.7s, loss: 1.086\n","    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n","(Epoch 9), time: 8.8s, loss: 1.066\n","    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n","(Epoch 10), time: 8.7s, loss: 1.043\n","    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n","(Epoch 11), time: 8.7s, loss: 1.015\n","    Training Set - accuracy: 0.60, precision: 0.20, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.17,\n","(Epoch 12), time: 8.7s, loss: 0.975\n","    Training Set - accuracy: 0.61, precision: 0.54, recall: 0.36, f1-score: 0.30,\n","    Validation Set - accuracy: 0.35, precision: 0.12, recall: 0.33, f1-score: 0.18,\n","(Epoch 13), time: 8.8s, loss: 0.940\n","    Training Set - accuracy: 0.63, precision: 0.54, recall: 0.40, f1-score: 0.37,\n"]}],"source":["from dataset import YouTubeDataset\n","from model import SimpleBert\n","splits = [10,20]\n","num_classes = len(splits)+1\n","dataset = YouTubeDataset(splits)\n","model = SimpleBert(num_classes)\n","\n","hist = train_model_cv5(model, dataset)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":495818,"status":"ok","timestamp":1661801454322,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"sraz31H1wSih","colab":{"base_uri":"https://localhost:8080/"},"outputId":"07438c30-fe24-4c7e-fcd0-ac82b9dd9ac4"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Initialization success if you see a tensor: tensor([[0.2250, 0.2336]], grad_fn=<AddmmBackward0>).\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 1 (val 0 - 42)\n","(Epoch 0), time: 8.8s, loss: 0.696\n","    Training Set - accuracy: 0.47, precision: 0.23, recall: 0.50, f1-score: 0.32,\n","    Validation Set - accuracy: 0.85, precision: 0.92, recall: 0.57, f1-score: 0.58,\n","(Epoch 1), time: 8.8s, loss: 0.694\n","    Training Set - accuracy: 0.49, precision: 0.74, recall: 0.52, f1-score: 0.37,\n","    Validation Set - accuracy: 0.82, precision: 0.41, recall: 0.50, f1-score: 0.45,\n","(Epoch 2), time: 8.7s, loss: 0.694\n","    Training Set - accuracy: 0.48, precision: 0.52, recall: 0.51, f1-score: 0.39,\n","    Validation Set - accuracy: 0.70, precision: 0.40, recall: 0.42, f1-score: 0.41,\n","(Epoch 3), time: 8.7s, loss: 0.694\n","    Training Set - accuracy: 0.46, precision: 0.45, recall: 0.48, f1-score: 0.37,\n","    Validation Set - accuracy: 0.72, precision: 0.40, recall: 0.44, f1-score: 0.42,\n","(Epoch 4), time: 8.7s, loss: 0.695\n","    Training Set - accuracy: 0.43, precision: 0.39, recall: 0.46, f1-score: 0.35,\n","    Validation Set - accuracy: 0.80, precision: 0.41, recall: 0.48, f1-score: 0.44,\n","(Epoch 5), time: 8.8s, loss: 0.691\n","    Training Set - accuracy: 0.49, precision: 0.59, recall: 0.52, f1-score: 0.39,\n","    Validation Set - accuracy: 0.78, precision: 0.41, recall: 0.47, f1-score: 0.44,\n","(Epoch 6), time: 8.7s, loss: 0.691\n","    Training Set - accuracy: 0.46, precision: 0.46, recall: 0.49, f1-score: 0.36,\n","    Validation Set - accuracy: 0.82, precision: 0.68, recall: 0.61, f1-score: 0.63,\n","(Epoch 7), time: 8.8s, loss: 0.690\n","    Training Set - accuracy: 0.49, precision: 0.51, recall: 0.51, f1-score: 0.44,\n","    Validation Set - accuracy: 0.82, precision: 0.68, recall: 0.61, f1-score: 0.63,\n","(Epoch 8), time: 8.7s, loss: 0.689\n","    Training Set - accuracy: 0.56, precision: 0.59, recall: 0.57, f1-score: 0.54,\n","    Validation Set - accuracy: 0.78, precision: 0.59, recall: 0.58, f1-score: 0.59,\n","(Epoch 9), time: 8.7s, loss: 0.686\n","    Training Set - accuracy: 0.62, precision: 0.66, recall: 0.64, f1-score: 0.62,\n","    Validation Set - accuracy: 0.75, precision: 0.63, recall: 0.68, f1-score: 0.64,\n","(Epoch 10), time: 8.8s, loss: 0.678\n","    Training Set - accuracy: 0.67, precision: 0.67, recall: 0.67, f1-score: 0.67,\n","    Validation Set - accuracy: 0.62, precision: 0.56, recall: 0.60, f1-score: 0.54,\n","(Epoch 11), time: 8.7s, loss: 0.666\n","    Training Set - accuracy: 0.72, precision: 0.72, recall: 0.71, f1-score: 0.71,\n","    Validation Set - accuracy: 0.60, precision: 0.52, recall: 0.53, f1-score: 0.50,\n","(Epoch 12), time: 8.7s, loss: 0.629\n","    Training Set - accuracy: 0.73, precision: 0.73, recall: 0.73, f1-score: 0.73,\n","    Validation Set - accuracy: 0.65, precision: 0.57, recall: 0.62, f1-score: 0.56,\n","(Epoch 13), time: 8.7s, loss: 0.598\n","    Training Set - accuracy: 0.76, precision: 0.76, recall: 0.75, f1-score: 0.75,\n","    Validation Set - accuracy: 0.57, precision: 0.51, recall: 0.52, f1-score: 0.48,\n","(Epoch 14), time: 8.7s, loss: 0.559\n","    Training Set - accuracy: 0.78, precision: 0.78, recall: 0.78, f1-score: 0.78,\n","    Validation Set - accuracy: 0.53, precision: 0.53, recall: 0.54, f1-score: 0.47,\n","(Epoch 15), time: 8.7s, loss: 0.523\n","    Training Set - accuracy: 0.79, precision: 0.80, recall: 0.79, f1-score: 0.79,\n","    Validation Set - accuracy: 0.65, precision: 0.54, recall: 0.56, f1-score: 0.53,\n","(Epoch 16), time: 8.7s, loss: 0.484\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.81, f1-score: 0.81,\n","    Validation Set - accuracy: 0.70, precision: 0.57, recall: 0.59, f1-score: 0.57,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 2 (val 43 - 84)\n","(Epoch 0), time: 8.8s, loss: 0.695\n","    Training Set - accuracy: 0.47, precision: 0.43, recall: 0.48, f1-score: 0.36,\n","    Validation Set - accuracy: 0.38, precision: 0.66, recall: 0.55, f1-score: 0.34,\n","(Epoch 1), time: 8.7s, loss: 0.694\n","    Training Set - accuracy: 0.46, precision: 0.41, recall: 0.47, f1-score: 0.36,\n","    Validation Set - accuracy: 0.40, precision: 0.53, recall: 0.52, f1-score: 0.39,\n","(Epoch 2), time: 8.8s, loss: 0.691\n","    Training Set - accuracy: 0.53, precision: 0.61, recall: 0.54, f1-score: 0.43,\n","    Validation Set - accuracy: 0.40, precision: 0.67, recall: 0.57, f1-score: 0.38,\n","(Epoch 3), time: 8.8s, loss: 0.693\n","    Training Set - accuracy: 0.47, precision: 0.47, recall: 0.48, f1-score: 0.41,\n","    Validation Set - accuracy: 0.28, precision: 0.30, recall: 0.43, f1-score: 0.24,\n","(Epoch 4), time: 8.8s, loss: 0.690\n","    Training Set - accuracy: 0.52, precision: 0.56, recall: 0.53, f1-score: 0.45,\n","    Validation Set - accuracy: 0.42, precision: 0.67, recall: 0.59, f1-score: 0.41,\n","(Epoch 5), time: 8.7s, loss: 0.687\n","    Training Set - accuracy: 0.64, precision: 0.72, recall: 0.65, f1-score: 0.62,\n","    Validation Set - accuracy: 0.50, precision: 0.57, recall: 0.57, f1-score: 0.50,\n","(Epoch 6), time: 8.7s, loss: 0.686\n","    Training Set - accuracy: 0.68, precision: 0.69, recall: 0.68, f1-score: 0.68,\n","    Validation Set - accuracy: 0.50, precision: 0.48, recall: 0.48, f1-score: 0.47,\n","(Epoch 7), time: 8.7s, loss: 0.674\n","    Training Set - accuracy: 0.70, precision: 0.72, recall: 0.70, f1-score: 0.69,\n","    Validation Set - accuracy: 0.47, precision: 0.36, recall: 0.36, f1-score: 0.36,\n","(Epoch 8), time: 8.7s, loss: 0.657\n","    Training Set - accuracy: 0.70, precision: 0.71, recall: 0.70, f1-score: 0.69,\n","    Validation Set - accuracy: 0.50, precision: 0.48, recall: 0.48, f1-score: 0.47,\n","(Epoch 9), time: 8.8s, loss: 0.633\n","    Training Set - accuracy: 0.73, precision: 0.73, recall: 0.73, f1-score: 0.73,\n","    Validation Set - accuracy: 0.55, precision: 0.49, recall: 0.49, f1-score: 0.49,\n","(Epoch 10), time: 8.7s, loss: 0.618\n","    Training Set - accuracy: 0.72, precision: 0.73, recall: 0.72, f1-score: 0.72,\n","    Validation Set - accuracy: 0.55, precision: 0.55, recall: 0.56, f1-score: 0.53,\n","(Epoch 11), time: 8.7s, loss: 0.594\n","    Training Set - accuracy: 0.75, precision: 0.75, recall: 0.75, f1-score: 0.75,\n","    Validation Set - accuracy: 0.60, precision: 0.60, recall: 0.62, f1-score: 0.58,\n","(Epoch 12), time: 8.8s, loss: 0.566\n","    Training Set - accuracy: 0.79, precision: 0.79, recall: 0.79, f1-score: 0.79,\n","    Validation Set - accuracy: 0.57, precision: 0.55, recall: 0.55, f1-score: 0.54,\n","(Epoch 13), time: 8.8s, loss: 0.548\n","    Training Set - accuracy: 0.78, precision: 0.78, recall: 0.78, f1-score: 0.78,\n","    Validation Set - accuracy: 0.57, precision: 0.53, recall: 0.53, f1-score: 0.52,\n","(Epoch 14), time: 8.8s, loss: 0.536\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.81, f1-score: 0.81,\n","    Validation Set - accuracy: 0.65, precision: 0.67, recall: 0.70, f1-score: 0.64,\n","(Epoch 15), time: 8.8s, loss: 0.511\n","    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.82, f1-score: 0.82,\n","    Validation Set - accuracy: 0.57, precision: 0.61, recall: 0.62, f1-score: 0.57,\n","(Epoch 16), time: 8.7s, loss: 0.494\n","    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.83, f1-score: 0.82,\n","    Validation Set - accuracy: 0.60, precision: 0.65, recall: 0.67, f1-score: 0.60,\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 (val 85 - 126)\n","(Epoch 0), time: 8.8s, loss: 0.694\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 1), time: 8.7s, loss: 0.690\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 2), time: 8.8s, loss: 0.689\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 3), time: 8.7s, loss: 0.695\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 4), time: 8.7s, loss: 0.689\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 5), time: 8.7s, loss: 0.690\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 6), time: 8.7s, loss: 0.687\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 7), time: 8.7s, loss: 0.686\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 8), time: 8.7s, loss: 0.687\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 9), time: 8.8s, loss: 0.682\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 10), time: 8.7s, loss: 0.674\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 11), time: 8.7s, loss: 0.667\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 12), time: 8.7s, loss: 0.638\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 13), time: 8.7s, loss: 0.614\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.42, precision: 0.70, recall: 0.54, f1-score: 0.36,\n","(Epoch 14), time: 8.7s, loss: 0.590\n","    Training Set - accuracy: 0.62, precision: 0.72, recall: 0.53, f1-score: 0.45,\n","    Validation Set - accuracy: 0.38, precision: 0.43, recall: 0.47, f1-score: 0.32,\n","(Epoch 15), time: 8.7s, loss: 0.569\n","    Training Set - accuracy: 0.66, precision: 0.73, recall: 0.59, f1-score: 0.56,\n","    Validation Set - accuracy: 0.57, precision: 0.68, recall: 0.65, f1-score: 0.57,\n","(Epoch 16), time: 8.8s, loss: 0.543\n","    Training Set - accuracy: 0.69, precision: 0.72, recall: 0.63, f1-score: 0.62,\n","    Validation Set - accuracy: 0.55, precision: 0.57, recall: 0.57, f1-score: 0.55,\n","(Epoch 17), time: 8.7s, loss: 0.504\n","    Training Set - accuracy: 0.76, precision: 0.77, recall: 0.73, f1-score: 0.74,\n","    Validation Set - accuracy: 0.57, precision: 0.59, recall: 0.59, f1-score: 0.57,\n","(Epoch 18), time: 8.7s, loss: 0.514\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.82, f1-score: 0.81,\n","    Validation Set - accuracy: 0.62, precision: 0.60, recall: 0.59, f1-score: 0.59,\n","(Epoch 19), time: 8.8s, loss: 0.506\n","    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.81, f1-score: 0.82,\n","    Validation Set - accuracy: 0.60, precision: 0.58, recall: 0.59, f1-score: 0.58,\n","(Epoch 20), time: 8.7s, loss: 0.488\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.81, f1-score: 0.81,\n","    Validation Set - accuracy: 0.53, precision: 0.55, recall: 0.55, f1-score: 0.52,\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 (val 127 - 168)\n","(Epoch 0), time: 8.8s, loss: 0.696\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 1), time: 8.8s, loss: 0.694\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 2), time: 8.7s, loss: 0.692\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 3), time: 8.8s, loss: 0.692\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 4), time: 8.7s, loss: 0.694\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 5), time: 8.7s, loss: 0.693\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 6), time: 8.8s, loss: 0.691\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 7), time: 8.8s, loss: 0.690\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 8), time: 8.8s, loss: 0.691\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 9), time: 8.7s, loss: 0.688\n","    Training Set - accuracy: 0.57, precision: 0.29, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.42, precision: 0.22, recall: 0.47, f1-score: 0.30,\n","(Epoch 10), time: 8.7s, loss: 0.686\n","    Training Set - accuracy: 0.57, precision: 0.54, recall: 0.50, f1-score: 0.38,\n","    Validation Set - accuracy: 0.50, precision: 0.74, recall: 0.55, f1-score: 0.40,\n","(Epoch 11), time: 8.8s, loss: 0.681\n","    Training Set - accuracy: 0.61, precision: 0.73, recall: 0.54, f1-score: 0.45,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 12), time: 8.7s, loss: 0.669\n","    Training Set - accuracy: 0.66, precision: 0.66, recall: 0.62, f1-score: 0.62,\n","    Validation Set - accuracy: 0.60, precision: 0.61, recall: 0.61, f1-score: 0.60,\n","(Epoch 13), time: 8.8s, loss: 0.654\n","    Training Set - accuracy: 0.69, precision: 0.68, recall: 0.67, f1-score: 0.67,\n","    Validation Set - accuracy: 0.78, precision: 0.78, recall: 0.77, f1-score: 0.77,\n","(Epoch 14), time: 8.7s, loss: 0.633\n","    Training Set - accuracy: 0.69, precision: 0.69, recall: 0.68, f1-score: 0.68,\n","    Validation Set - accuracy: 0.70, precision: 0.70, recall: 0.69, f1-score: 0.69,\n","(Epoch 15), time: 8.8s, loss: 0.592\n","    Training Set - accuracy: 0.75, precision: 0.75, recall: 0.75, f1-score: 0.75,\n","    Validation Set - accuracy: 0.68, precision: 0.67, recall: 0.67, f1-score: 0.67,\n","(Epoch 16), time: 8.7s, loss: 0.553\n","    Training Set - accuracy: 0.75, precision: 0.75, recall: 0.75, f1-score: 0.75,\n","    Validation Set - accuracy: 0.72, precision: 0.72, recall: 0.72, f1-score: 0.72,\n","(Epoch 17), time: 8.8s, loss: 0.513\n","    Training Set - accuracy: 0.79, precision: 0.79, recall: 0.80, f1-score: 0.79,\n","    Validation Set - accuracy: 0.78, precision: 0.78, recall: 0.77, f1-score: 0.77,\n","(Epoch 18), time: 8.7s, loss: 0.479\n","    Training Set - accuracy: 0.78, precision: 0.77, recall: 0.78, f1-score: 0.77,\n","    Validation Set - accuracy: 0.68, precision: 0.67, recall: 0.67, f1-score: 0.67,\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 (val 169 - 210)\n","(Epoch 0), time: 8.8s, loss: 0.696\n","    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n","(Epoch 1), time: 8.7s, loss: 0.694\n","    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n","(Epoch 2), time: 8.7s, loss: 0.691\n","    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n","(Epoch 3), time: 8.8s, loss: 0.691\n","    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n","(Epoch 4), time: 8.7s, loss: 0.689\n","    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.35, precision: 0.17, recall: 0.50, f1-score: 0.26,\n","(Epoch 5), time: 8.8s, loss: 0.687\n","    Training Set - accuracy: 0.60, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.68, recall: 0.52, f1-score: 0.30,\n","(Epoch 6), time: 8.8s, loss: 0.685\n","    Training Set - accuracy: 0.60, precision: 0.55, recall: 0.50, f1-score: 0.39,\n","    Validation Set - accuracy: 0.38, precision: 0.51, recall: 0.50, f1-score: 0.32,\n","(Epoch 7), time: 8.7s, loss: 0.681\n","    Training Set - accuracy: 0.62, precision: 0.81, recall: 0.52, f1-score: 0.42,\n","    Validation Set - accuracy: 0.33, precision: 0.33, recall: 0.45, f1-score: 0.27,\n","(Epoch 8), time: 8.7s, loss: 0.670\n","    Training Set - accuracy: 0.63, precision: 0.65, recall: 0.55, f1-score: 0.50,\n","    Validation Set - accuracy: 0.62, precision: 0.70, recall: 0.70, f1-score: 0.62,\n","(Epoch 9), time: 8.7s, loss: 0.655\n","    Training Set - accuracy: 0.71, precision: 0.70, recall: 0.67, f1-score: 0.68,\n","    Validation Set - accuracy: 0.68, precision: 0.64, recall: 0.63, f1-score: 0.64,\n","(Epoch 10), time: 8.7s, loss: 0.616\n","    Training Set - accuracy: 0.73, precision: 0.74, recall: 0.74, f1-score: 0.73,\n","    Validation Set - accuracy: 0.68, precision: 0.83, recall: 0.54, f1-score: 0.47,\n","(Epoch 11), time: 8.8s, loss: 0.589\n","    Training Set - accuracy: 0.71, precision: 0.71, recall: 0.72, f1-score: 0.71,\n","    Validation Set - accuracy: 0.78, precision: 0.81, recall: 0.70, f1-score: 0.71,\n","(Epoch 12), time: 8.8s, loss: 0.556\n","    Training Set - accuracy: 0.76, precision: 0.76, recall: 0.77, f1-score: 0.75,\n","    Validation Set - accuracy: 0.75, precision: 0.78, recall: 0.66, f1-score: 0.67,\n","(Epoch 13), time: 8.7s, loss: 0.502\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.82, f1-score: 0.80,\n","    Validation Set - accuracy: 0.72, precision: 0.70, recall: 0.66, f1-score: 0.66,\n","(Epoch 14), time: 8.7s, loss: 0.480\n","    Training Set - accuracy: 0.80, precision: 0.80, recall: 0.81, f1-score: 0.80,\n","    Validation Set - accuracy: 0.62, precision: 0.58, recall: 0.58, f1-score: 0.58,\n"]}],"source":["from dataset import YouTubeDataset\n","from model import SimpleBert\n","splits = [10]\n","num_classes = len(splits)+1\n","dataset = YouTubeDataset(splits)\n","model = SimpleBert(num_classes)\n","\n","hist = train_model_cv5(model, dataset)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"roberta_simple.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"54d3b53da97a4d5230a2d6a56d4dc057ea257b55156c1302576dbafca9234f1a"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"cd66edbd6d7c44969ebc631c2fe4075c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d29370d62ac44f78a6e2cc0c5307636a","IPY_MODEL_d8bde791f64642d78f93ba76192cc640","IPY_MODEL_4e377b69b4344192bdbe40a3813d9659"],"layout":"IPY_MODEL_b180502ed69d4e31978149c2b2206680"}},"d29370d62ac44f78a6e2cc0c5307636a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a379cefbaa9e4582a5e21cdbca56e069","placeholder":"​","style":"IPY_MODEL_cadd20b50c264e9fb5f8f916aea88dc9","value":"Downloading: 100%"}},"d8bde791f64642d78f93ba76192cc640":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede1f07546fb4ac9ac31db1404713a56","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cf8b510edc04528a9ac37b4d3f81a95","value":898823}},"4e377b69b4344192bdbe40a3813d9659":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e920714c7b204178aeed15281b1180e4","placeholder":"​","style":"IPY_MODEL_b5a86cc7ac68460b908b82e1445a1365","value":" 899k/899k [00:00&lt;00:00, 2.15MB/s]"}},"b180502ed69d4e31978149c2b2206680":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a379cefbaa9e4582a5e21cdbca56e069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cadd20b50c264e9fb5f8f916aea88dc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ede1f07546fb4ac9ac31db1404713a56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cf8b510edc04528a9ac37b4d3f81a95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e920714c7b204178aeed15281b1180e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5a86cc7ac68460b908b82e1445a1365":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dce48ab6b0a64446a16e4eff5fe8b5fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17a82e25a1874537a0db547e27c02ac5","IPY_MODEL_5d13558b56ff4f01b16bc047d978f499","IPY_MODEL_2fc52cf92ebc4924b2904a5d227263cb"],"layout":"IPY_MODEL_51b8300f519d425189c627f766943b78"}},"17a82e25a1874537a0db547e27c02ac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b9bbc1c1a8245c4b38a8fbb3d586d49","placeholder":"​","style":"IPY_MODEL_27b7a726ff094e84a6041b8edb2fcfb3","value":"Downloading: 100%"}},"5d13558b56ff4f01b16bc047d978f499":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e81e61c715946f6ac3e7596ba44e55a","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f649d86e6954b8abc7cd84417a8cfed","value":456318}},"2fc52cf92ebc4924b2904a5d227263cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9d34d9823f646fc9e4c853d13b6787e","placeholder":"​","style":"IPY_MODEL_fbc68c3c07e64c169094d6550045da5c","value":" 456k/456k [00:00&lt;00:00, 622kB/s]"}},"51b8300f519d425189c627f766943b78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9bbc1c1a8245c4b38a8fbb3d586d49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27b7a726ff094e84a6041b8edb2fcfb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e81e61c715946f6ac3e7596ba44e55a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f649d86e6954b8abc7cd84417a8cfed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9d34d9823f646fc9e4c853d13b6787e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc68c3c07e64c169094d6550045da5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c166ba293937447ba93630d8e6ce4251":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afbc33ba959343b195e0723e3c25d517","IPY_MODEL_25c514de3b6b4d51ae400df8df391f06","IPY_MODEL_50e8236d9524479e91d020302a2e157c"],"layout":"IPY_MODEL_7f86de4c995e4674abdaf9804a86a125"}},"afbc33ba959343b195e0723e3c25d517":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0ad6a4d9d0f4853887f92ed645350ad","placeholder":"​","style":"IPY_MODEL_1883ab1778ec46e9abdf8c016d88f9a1","value":"Downloading: 100%"}},"25c514de3b6b4d51ae400df8df391f06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_476d46c1da2647c3873d89a19ca9a717","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df0175e9af754a6780b2c7a68940c893","value":1355863}},"50e8236d9524479e91d020302a2e157c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05eda02912f54e24b4a2eccb1f5d1985","placeholder":"​","style":"IPY_MODEL_f510a7cee8f44d67b51baf234d583186","value":" 1.36M/1.36M [00:00&lt;00:00, 1.46MB/s]"}},"7f86de4c995e4674abdaf9804a86a125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ad6a4d9d0f4853887f92ed645350ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1883ab1778ec46e9abdf8c016d88f9a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"476d46c1da2647c3873d89a19ca9a717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df0175e9af754a6780b2c7a68940c893":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05eda02912f54e24b4a2eccb1f5d1985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f510a7cee8f44d67b51baf234d583186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce4cc25400bd41358ad23d6f7b02ed0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff2b5b2e574e49d78d2ef90430128e88","IPY_MODEL_13887f55b442474ea6971d5733ae99bc","IPY_MODEL_da8b5156c6f247829d3d96923b852b4e"],"layout":"IPY_MODEL_33b1d8be2ace4bc1a9415d67614c19e7"}},"ff2b5b2e574e49d78d2ef90430128e88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24614414bec54f4a9e16da0b4a76e332","placeholder":"​","style":"IPY_MODEL_e378819f52434b8caf3345a8101ba426","value":"Downloading: 100%"}},"13887f55b442474ea6971d5733ae99bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a99603efc14990b44f0cef9784ac97","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7524bcc23b384abea0b4158780bba922","value":481}},"da8b5156c6f247829d3d96923b852b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f55d57435049b9ac2b3016a5dde46b","placeholder":"​","style":"IPY_MODEL_355f43e3996849189748e707897ba985","value":" 481/481 [00:00&lt;00:00, 14.6kB/s]"}},"33b1d8be2ace4bc1a9415d67614c19e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24614414bec54f4a9e16da0b4a76e332":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e378819f52434b8caf3345a8101ba426":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1a99603efc14990b44f0cef9784ac97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7524bcc23b384abea0b4158780bba922":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8f55d57435049b9ac2b3016a5dde46b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"355f43e3996849189748e707897ba985":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d27cdc2976746699dc635008321c9d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a0050ddc85c42f6b6f1e3cb545f97bf","IPY_MODEL_3efb47bc5f874b6593343d0a656f7363","IPY_MODEL_0336d3e29a50406483ffb92365b60fb2"],"layout":"IPY_MODEL_0d0a5b569f5543a3aad0885b7ffc23b6"}},"7a0050ddc85c42f6b6f1e3cb545f97bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69cdef023ca54eba8ba67a31781f7a10","placeholder":"​","style":"IPY_MODEL_05a8ce378d33400396944a18ca453dfc","value":"Downloading: 100%"}},"3efb47bc5f874b6593343d0a656f7363":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ab7f2eb1b8847ca9c73bd212e448496","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3375bb1641e540598ccafb19a0a6c6f5","value":501200538}},"0336d3e29a50406483ffb92365b60fb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac6a517f1f14abd8f526c1554d26175","placeholder":"​","style":"IPY_MODEL_d97a8b732489475fbb6efa5382fc4bf8","value":" 501M/501M [00:12&lt;00:00, 57.4MB/s]"}},"0d0a5b569f5543a3aad0885b7ffc23b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69cdef023ca54eba8ba67a31781f7a10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a8ce378d33400396944a18ca453dfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ab7f2eb1b8847ca9c73bd212e448496":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3375bb1641e540598ccafb19a0a6c6f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ac6a517f1f14abd8f526c1554d26175":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d97a8b732489475fbb6efa5382fc4bf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}