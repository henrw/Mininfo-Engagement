{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1661792745469,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"qXW99pdz2Q5u","outputId":"041d8501-b316-4c0f-d0e4-6a855cbea01d"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1661792773343,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"iZyn4_broM2O"},"outputs":[],"source":["splits = [10,20,30]\n","num_classes = len(splits)+1"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cd66edbd6d7c44969ebc631c2fe4075c","d29370d62ac44f78a6e2cc0c5307636a","d8bde791f64642d78f93ba76192cc640","4e377b69b4344192bdbe40a3813d9659","b180502ed69d4e31978149c2b2206680","a379cefbaa9e4582a5e21cdbca56e069","cadd20b50c264e9fb5f8f916aea88dc9","ede1f07546fb4ac9ac31db1404713a56","7cf8b510edc04528a9ac37b4d3f81a95","e920714c7b204178aeed15281b1180e4","b5a86cc7ac68460b908b82e1445a1365","dce48ab6b0a64446a16e4eff5fe8b5fd","17a82e25a1874537a0db547e27c02ac5","5d13558b56ff4f01b16bc047d978f499","2fc52cf92ebc4924b2904a5d227263cb","51b8300f519d425189c627f766943b78","2b9bbc1c1a8245c4b38a8fbb3d586d49","27b7a726ff094e84a6041b8edb2fcfb3","1e81e61c715946f6ac3e7596ba44e55a","3f649d86e6954b8abc7cd84417a8cfed","e9d34d9823f646fc9e4c853d13b6787e","fbc68c3c07e64c169094d6550045da5c","c166ba293937447ba93630d8e6ce4251","afbc33ba959343b195e0723e3c25d517","25c514de3b6b4d51ae400df8df391f06","50e8236d9524479e91d020302a2e157c","7f86de4c995e4674abdaf9804a86a125","a0ad6a4d9d0f4853887f92ed645350ad","1883ab1778ec46e9abdf8c016d88f9a1","476d46c1da2647c3873d89a19ca9a717","df0175e9af754a6780b2c7a68940c893","05eda02912f54e24b4a2eccb1f5d1985","f510a7cee8f44d67b51baf234d583186"]},"executionInfo":{"elapsed":110504,"status":"ok","timestamp":1661792883844,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"qJhlLvN_2Q5w","outputId":"9b3d34ec-97a4-4308-cf3b-6b1cc3b96b30"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/henrw/anaconda3/envs/misinfo-engage/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from dataset import YouTubeDataset\n","dataset = YouTubeDataset(splits)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["ce4cc25400bd41358ad23d6f7b02ed0b","ff2b5b2e574e49d78d2ef90430128e88","13887f55b442474ea6971d5733ae99bc","da8b5156c6f247829d3d96923b852b4e","33b1d8be2ace4bc1a9415d67614c19e7","24614414bec54f4a9e16da0b4a76e332","e378819f52434b8caf3345a8101ba426","e1a99603efc14990b44f0cef9784ac97","7524bcc23b384abea0b4158780bba922","f8f55d57435049b9ac2b3016a5dde46b","355f43e3996849189748e707897ba985","2d27cdc2976746699dc635008321c9d0","7a0050ddc85c42f6b6f1e3cb545f97bf","3efb47bc5f874b6593343d0a656f7363","0336d3e29a50406483ffb92365b60fb2","0d0a5b569f5543a3aad0885b7ffc23b6","69cdef023ca54eba8ba67a31781f7a10","05a8ce378d33400396944a18ca453dfc","9ab7f2eb1b8847ca9c73bd212e448496","3375bb1641e540598ccafb19a0a6c6f5","5ac6a517f1f14abd8f526c1554d26175","d97a8b732489475fbb6efa5382fc4bf8"]},"executionInfo":{"elapsed":17873,"status":"ok","timestamp":1661792901707,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"8p-lRwh82Q5w","outputId":"eb578f74-214a-43bf-97e1-e376f97c01f9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Initialization success if you see a tensor: tensor([[ 0.1946,  0.2515, -0.0769,  0.0392]], grad_fn=<AddmmBackward0>).\n"]}],"source":["from models.single_modality_classifiers import RobertaClassifier\n","model = RobertaClassifier(num_classes)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1661792901708,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"uUElxqlG3odH"},"outputs":[],"source":["# import torch\n","# checkpoint = torch.load(\"checkpoints/epoch200.pt\",map_location=torch.device('cpu'))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":277,"status":"ok","timestamp":1661792901974,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"hFBPwWgpLOjG"},"outputs":[],"source":["# model.base.requires_grad = False"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["device = 'cuda:2'"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1381,"status":"ok","timestamp":1661792903353,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"ZvBMRR972Q5x"},"outputs":[],"source":["import torch\n","import math\n","import os\n","import time\n","import numpy as np\n","from sklearn.utils.class_weight import compute_class_weight\n","from inference import eval, get_scores\n","from torch.nn.functional import cross_entropy\n","\n","def train_model(model, dataset, learning_rate, lr_decay, weight_decay, batch_size, num_epochs, device, isCheckpoint=False, train_val_split = None, isVerbose=True):\n","    loss_history = []\n","\n","    model.to(device)\n","    dataset.label.to(device)\n","    dataset.tokens.to(device)\n","    model.train()\n","\n","    optimizer = torch.optim.AdamW(\n","        filter(lambda p: p.requires_grad, model.parameters()), learning_rate, weight_decay=weight_decay\n","    )\n","    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n","        optimizer, lambda epoch: lr_decay ** epoch\n","    )\n","\n","    # sample minibatch data\n","    if not train_val_split:\n","      train_ids = [i for i in range(len(dataset))]\n","      val_ids = None\n","    else:\n","      train_ids, val_ids = train_val_split\n","\n","    iter_per_epoch = math.ceil(len(train_ids) // batch_size)\n","    class_weights = torch.tensor(compute_class_weight(class_weight='balanced', classes=np.arange(model.num_classes), y=dataset.label[train_ids].numpy()), dtype=torch.float, device=device)\n","    loss_fn = torch.nn.NLLLoss(weight = class_weights)\n","    # loss_fn = cross_entropy\n","    \n","    for i in range(num_epochs):\n","        start_t = time.time()\n","        local_hist = []\n","        correct_cnt = 0\n","        y_preds = torch.empty((0,),device=device)\n","        y_trues = torch.empty((0,),device=device)\n","        for j in range(iter_per_epoch):\n","            tokens, y_true = dataset[train_ids[j * batch_size: (j + 1) * batch_size]]\n","\n","            # tokens = tokens.to(device)\n","            y_true = y_true.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            digits = model(tokens)\n","            y_preds = torch.hstack([y_preds,digits.argmax(dim=1)])\n","            y_trues = torch.hstack([y_trues,y_true])\n","\n","            probs = torch.nn.LogSoftmax(dim=1)(digits)\n","            loss = loss_fn(probs,y_true)\n","            loss.backward()\n","\n","            local_hist.append(loss.item())\n","            optimizer.step()\n","\n","        end_t = time.time()\n","\n","        loss_mean = np.array(local_hist).mean()\n","        loss_history.append(loss_mean)\n","            \n","        print(\n","            f\"(Epoch {i}), time: {end_t - start_t:.1f}s, loss: {loss_mean:.3f}\"\n","        )\n","        if isVerbose:\n","            train_accuracy, train_precision, train_recall, train_f1 = get_scores(y_trues.to('cpu'), y_preds.to('cpu'), model.num_classes) # This is an aggregated result due to GPU size limit\n","            print(f\"    Training Set - accuracy: {train_accuracy:.2f}, precision: {train_precision:.2f}, recall: {train_recall:.2f}, f1-score: {train_f1:.2f},\")\n","            if val_ids is not None:\n","                val_accuracy, val_precision, val_recall, val_f1 = eval(model, dataset, val_ids, num_classes, device, is_verbose = (loss_mean < 0.5))\n","                print(f\"    Validation Set - accuracy: {val_accuracy:.2f}, precision: {val_precision:.2f}, recall: {val_recall:.2f}, f1-score: {val_f1:.2f},\")\n","        if i%200 == 0 and isCheckpoint:\n","          dir = \"checkpoints\"\n","          if not os.path.exists(dir):\n","            os.mkdir(dir)\n","          file = f\"epoch{i}.pt\"\n","          path = dir+'/'+file\n","          torch.save({\n","                      'epoch': i,\n","                      'model_state_dict': model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss_mean,\n","                      }, path)\n","\n","        lr_scheduler.step()\n","\n","        if loss_mean < 0.5:\n","          break\n","    \n","    return loss_history"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NVaX4nbOTOi0"},"source":["## 5-fold CV"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661792903354,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"R8G3vHc48zoJ"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","import torch\n","\n","def train_model_cv5(model, dataset):\n","    loss_hist = []\n","    kf = KFold(n_splits=5)\n","    cnt = 1\n","    for train_index, val_index in kf.split(dataset):\n","        model.reset()\n","        print(\"Fold \"+str(cnt)+\" (val\", val_index[0],\"-\",str(val_index[-1])+\")\")\n","        loss_hist_fold = train_model(model, device = device, dataset=dataset, train_val_split=(train_index, val_index),learning_rate=3e-6, lr_decay=0.99, weight_decay=1e-4, batch_size=10, num_epochs=300, isCheckpoint = False, isVerbose = True)\n","        loss_hist.append(loss_hist_fold)\n","        cnt += 1\n","    return loss_hist"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21927,"status":"ok","timestamp":1661798082967,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"XN5fu6oeTOi1","outputId":"131caa2f-8ad8-46fc-aab7-2c007f6bafc0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 1 (val 0 - 42)\n","(Epoch 0), time: 6.2s, loss: 1.419\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 1), time: 6.0s, loss: 1.418\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 2), time: 6.0s, loss: 1.416\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 3), time: 5.9s, loss: 1.413\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 4), time: 6.0s, loss: 1.414\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 5), time: 6.0s, loss: 1.416\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 6), time: 6.0s, loss: 1.412\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 7), time: 6.0s, loss: 1.414\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 8), time: 6.0s, loss: 1.409\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 9), time: 6.0s, loss: 1.408\n","    Training Set - accuracy: 0.07, precision: 0.08, recall: 0.26, f1-score: 0.05,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 10), time: 6.0s, loss: 1.396\n","    Training Set - accuracy: 0.08, precision: 0.08, recall: 0.29, f1-score: 0.08,\n","    Validation Set - accuracy: 0.03, precision: 0.01, recall: 0.25, f1-score: 0.01,\n","(Epoch 11), time: 6.0s, loss: 1.393\n","    Training Set - accuracy: 0.11, precision: 0.11, recall: 0.34, f1-score: 0.12,\n","    Validation Set - accuracy: 0.03, precision: 0.02, recall: 0.25, f1-score: 0.03,\n","(Epoch 12), time: 6.0s, loss: 1.371\n","    Training Set - accuracy: 0.16, precision: 0.32, recall: 0.40, f1-score: 0.13,\n","    Validation Set - accuracy: 0.07, precision: 0.26, recall: 0.27, f1-score: 0.05,\n","(Epoch 13), time: 6.0s, loss: 1.349\n","    Training Set - accuracy: 0.22, precision: 0.22, recall: 0.37, f1-score: 0.19,\n","    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.36, f1-score: 0.18,\n","(Epoch 14), time: 6.0s, loss: 1.315\n","    Training Set - accuracy: 0.37, precision: 0.28, recall: 0.49, f1-score: 0.30,\n","    Validation Set - accuracy: 0.30, precision: 0.24, recall: 0.33, f1-score: 0.15,\n","(Epoch 15), time: 6.0s, loss: 1.272\n","    Training Set - accuracy: 0.42, precision: 0.55, recall: 0.56, f1-score: 0.38,\n","    Validation Set - accuracy: 0.47, precision: 0.23, recall: 0.39, f1-score: 0.20,\n","(Epoch 16), time: 6.0s, loss: 1.218\n","    Training Set - accuracy: 0.48, precision: 0.50, recall: 0.60, f1-score: 0.43,\n","    Validation Set - accuracy: 0.40, precision: 0.24, recall: 0.36, f1-score: 0.18,\n","(Epoch 17), time: 6.0s, loss: 1.167\n","    Training Set - accuracy: 0.42, precision: 0.44, recall: 0.59, f1-score: 0.38,\n","    Validation Set - accuracy: 0.53, precision: 0.25, recall: 0.40, f1-score: 0.22,\n","(Epoch 18), time: 6.0s, loss: 1.130\n","    Training Set - accuracy: 0.52, precision: 0.52, recall: 0.67, f1-score: 0.50,\n","    Validation Set - accuracy: 0.50, precision: 0.53, recall: 0.44, f1-score: 0.33,\n","(Epoch 19), time: 6.0s, loss: 1.069\n","    Training Set - accuracy: 0.59, precision: 0.56, recall: 0.72, f1-score: 0.57,\n","    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.16, f1-score: 0.20,\n","(Epoch 20), time: 6.0s, loss: 1.022\n","    Training Set - accuracy: 0.62, precision: 0.59, recall: 0.74, f1-score: 0.60,\n","    Validation Set - accuracy: 0.47, precision: 0.25, recall: 0.19, f1-score: 0.21,\n","(Epoch 21), time: 6.0s, loss: 0.995\n","    Training Set - accuracy: 0.59, precision: 0.59, recall: 0.74, f1-score: 0.57,\n","    Validation Set - accuracy: 0.53, precision: 0.26, recall: 0.20, f1-score: 0.22,\n","(Epoch 22), time: 6.0s, loss: 0.957\n","    Training Set - accuracy: 0.54, precision: 0.53, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.68, precision: 0.42, recall: 0.53, f1-score: 0.45,\n","(Epoch 23), time: 6.0s, loss: 0.960\n","    Training Set - accuracy: 0.59, precision: 0.56, recall: 0.73, f1-score: 0.57,\n","    Validation Set - accuracy: 0.60, precision: 0.38, recall: 0.55, f1-score: 0.36,\n","(Epoch 24), time: 6.0s, loss: 0.967\n","    Training Set - accuracy: 0.55, precision: 0.53, recall: 0.71, f1-score: 0.54,\n","    Validation Set - accuracy: 0.33, precision: 0.23, recall: 0.34, f1-score: 0.15,\n","(Epoch 25), time: 6.0s, loss: 0.966\n","    Training Set - accuracy: 0.62, precision: 0.60, recall: 0.71, f1-score: 0.62,\n","    Validation Set - accuracy: 0.65, precision: 0.39, recall: 0.52, f1-score: 0.38,\n","(Epoch 26), time: 6.0s, loss: 0.904\n","    Training Set - accuracy: 0.63, precision: 0.61, recall: 0.76, f1-score: 0.61,\n","    Validation Set - accuracy: 0.68, precision: 0.40, recall: 0.53, f1-score: 0.39,\n","(Epoch 27), time: 6.0s, loss: 0.846\n","    Training Set - accuracy: 0.74, precision: 0.70, recall: 0.83, f1-score: 0.73,\n","    Validation Set - accuracy: 0.65, precision: 0.25, recall: 0.24, f1-score: 0.24,\n","(Epoch 28), time: 6.0s, loss: 0.810\n","    Training Set - accuracy: 0.81, precision: 0.74, recall: 0.87, f1-score: 0.78,\n","    Validation Set - accuracy: 0.70, precision: 0.25, recall: 0.25, f1-score: 0.25,\n","(Epoch 29), time: 6.0s, loss: 0.790\n","    Training Set - accuracy: 0.86, precision: 0.80, recall: 0.91, f1-score: 0.84,\n","    Validation Set - accuracy: 0.68, precision: 0.25, recall: 0.25, f1-score: 0.25,\n","(Epoch 30), time: 6.0s, loss: 0.769\n","    Training Set - accuracy: 0.89, precision: 0.84, recall: 0.93, f1-score: 0.87,\n","    Validation Set - accuracy: 0.72, precision: 0.25, recall: 0.26, f1-score: 0.26,\n","(Epoch 31), time: 6.0s, loss: 0.750\n","    Training Set - accuracy: 0.90, precision: 0.85, recall: 0.93, f1-score: 0.88,\n","    Validation Set - accuracy: 0.75, precision: 0.32, recall: 0.35, f1-score: 0.32,\n","(Epoch 32), time: 6.0s, loss: 0.731\n","    Training Set - accuracy: 0.89, precision: 0.84, recall: 0.93, f1-score: 0.88,\n","    Validation Set - accuracy: 0.72, precision: 0.25, recall: 0.26, f1-score: 0.26,\n","(Epoch 33), time: 6.0s, loss: 0.707\n","    Training Set - accuracy: 0.93, precision: 0.89, recall: 0.95, f1-score: 0.91,\n","    Validation Set - accuracy: 0.70, precision: 0.25, recall: 0.25, f1-score: 0.25,\n","(Epoch 34), time: 6.0s, loss: 0.682\n","    Training Set - accuracy: 0.93, precision: 0.91, recall: 0.96, f1-score: 0.93,\n","    Validation Set - accuracy: 0.75, precision: 0.26, recall: 0.27, f1-score: 0.27,\n","(Epoch 35), time: 6.0s, loss: 0.654\n","    Training Set - accuracy: 0.94, precision: 0.92, recall: 0.95, f1-score: 0.93,\n","    Validation Set - accuracy: 0.72, precision: 0.27, recall: 0.26, f1-score: 0.27,\n","(Epoch 36), time: 6.0s, loss: 0.644\n","    Training Set - accuracy: 0.94, precision: 0.91, recall: 0.96, f1-score: 0.93,\n","    Validation Set - accuracy: 0.72, precision: 0.25, recall: 0.26, f1-score: 0.26,\n","(Epoch 37), time: 6.0s, loss: 0.626\n","    Training Set - accuracy: 0.92, precision: 0.88, recall: 0.94, f1-score: 0.90,\n","    Validation Set - accuracy: 0.72, precision: 0.27, recall: 0.26, f1-score: 0.27,\n","(Epoch 38), time: 6.0s, loss: 0.608\n","    Training Set - accuracy: 0.94, precision: 0.89, recall: 0.95, f1-score: 0.92,\n","    Validation Set - accuracy: 0.70, precision: 0.26, recall: 0.25, f1-score: 0.26,\n","(Epoch 39), time: 6.0s, loss: 0.580\n","    Training Set - accuracy: 0.97, precision: 0.94, recall: 0.98, f1-score: 0.96,\n","    Validation Set - accuracy: 0.65, precision: 0.28, recall: 0.32, f1-score: 0.28,\n","(Epoch 40), time: 6.0s, loss: 0.607\n","    Training Set - accuracy: 0.91, precision: 0.88, recall: 0.94, f1-score: 0.90,\n","    Validation Set - accuracy: 0.62, precision: 0.29, recall: 0.32, f1-score: 0.28,\n","(Epoch 41), time: 6.0s, loss: 0.580\n","    Training Set - accuracy: 0.94, precision: 0.92, recall: 0.97, f1-score: 0.94,\n","    Validation Set - accuracy: 0.65, precision: 0.26, recall: 0.24, f1-score: 0.25,\n","(Epoch 42), time: 6.0s, loss: 0.529\n","    Training Set - accuracy: 0.96, precision: 0.93, recall: 0.98, f1-score: 0.95,\n","    Validation Set - accuracy: 0.72, precision: 0.27, recall: 0.26, f1-score: 0.27,\n","(Epoch 43), time: 6.0s, loss: 0.500\n","    Training Set - accuracy: 0.97, precision: 0.97, recall: 0.98, f1-score: 0.98,\n","    Validation Set - accuracy: 0.75, precision: 0.26, recall: 0.27, f1-score: 0.27,\n","(Epoch 44), time: 6.0s, loss: 0.489\n","    Training Set - accuracy: 0.98, precision: 0.97, recall: 0.99, f1-score: 0.98,\n","Confusion Matrix:\n","[[29  3  0  1]\n"," [ 4  1  0  0]\n"," [ 0  1  0  0]\n"," [ 1  0  0  0]]\n","    Validation Set - accuracy: 0.75, precision: 0.26, recall: 0.27, f1-score: 0.27,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2 (val 43 - 84)\n","(Epoch 0), time: 6.0s, loss: 1.434\n","    Training Set - accuracy: 0.31, precision: 0.08, recall: 0.25, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 1), time: 6.0s, loss: 1.434\n","    Training Set - accuracy: 0.31, precision: 0.08, recall: 0.25, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 2), time: 6.0s, loss: 1.431\n","    Training Set - accuracy: 0.31, precision: 0.08, recall: 0.25, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 3), time: 6.0s, loss: 1.430\n","    Training Set - accuracy: 0.31, precision: 0.08, recall: 0.25, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 4), time: 6.0s, loss: 1.429\n","    Training Set - accuracy: 0.31, precision: 0.08, recall: 0.25, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 5), time: 6.0s, loss: 1.427\n","    Training Set - accuracy: 0.31, precision: 0.08, recall: 0.25, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 6), time: 6.0s, loss: 1.425\n","    Training Set - accuracy: 0.31, precision: 0.08, recall: 0.25, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 7), time: 6.0s, loss: 1.422\n","    Training Set - accuracy: 0.32, precision: 0.20, recall: 0.28, f1-score: 0.16,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 8), time: 6.0s, loss: 1.417\n","    Training Set - accuracy: 0.28, precision: 0.12, recall: 0.33, f1-score: 0.17,\n","    Validation Set - accuracy: 0.17, precision: 0.07, recall: 0.19, f1-score: 0.10,\n","(Epoch 9), time: 6.0s, loss: 1.398\n","    Training Set - accuracy: 0.29, precision: 0.13, recall: 0.42, f1-score: 0.19,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.19, f1-score: 0.09,\n","(Epoch 10), time: 6.0s, loss: 1.377\n","    Training Set - accuracy: 0.34, precision: 0.41, recall: 0.48, f1-score: 0.27,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 11), time: 6.0s, loss: 1.370\n","    Training Set - accuracy: 0.34, precision: 0.18, recall: 0.40, f1-score: 0.25,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 12), time: 6.0s, loss: 1.329\n","    Training Set - accuracy: 0.36, precision: 0.19, recall: 0.48, f1-score: 0.28,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 13), time: 6.0s, loss: 1.299\n","    Training Set - accuracy: 0.36, precision: 0.45, recall: 0.50, f1-score: 0.33,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 14), time: 6.0s, loss: 1.271\n","    Training Set - accuracy: 0.38, precision: 0.41, recall: 0.56, f1-score: 0.43,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.19, f1-score: 0.09,\n","(Epoch 15), time: 6.0s, loss: 1.247\n","    Training Set - accuracy: 0.40, precision: 0.42, recall: 0.56, f1-score: 0.44,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 16), time: 6.0s, loss: 1.213\n","    Training Set - accuracy: 0.39, precision: 0.40, recall: 0.59, f1-score: 0.46,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 17), time: 6.0s, loss: 1.185\n","    Training Set - accuracy: 0.42, precision: 0.41, recall: 0.66, f1-score: 0.49,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 18), time: 6.0s, loss: 1.160\n","    Training Set - accuracy: 0.44, precision: 0.47, recall: 0.65, f1-score: 0.52,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 19), time: 6.0s, loss: 1.134\n","    Training Set - accuracy: 0.44, precision: 0.47, recall: 0.66, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 20), time: 6.0s, loss: 1.099\n","    Training Set - accuracy: 0.43, precision: 0.44, recall: 0.68, f1-score: 0.52,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 21), time: 6.0s, loss: 1.066\n","    Training Set - accuracy: 0.46, precision: 0.49, recall: 0.72, f1-score: 0.57,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 22), time: 6.0s, loss: 1.032\n","    Training Set - accuracy: 0.46, precision: 0.50, recall: 0.70, f1-score: 0.57,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 23), time: 6.0s, loss: 1.001\n","    Training Set - accuracy: 0.45, precision: 0.49, recall: 0.71, f1-score: 0.57,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 24), time: 6.0s, loss: 0.997\n","    Training Set - accuracy: 0.46, precision: 0.49, recall: 0.71, f1-score: 0.56,\n","    Validation Set - accuracy: 0.20, precision: 0.05, recall: 0.22, f1-score: 0.09,\n","(Epoch 25), time: 6.0s, loss: 0.960\n","    Training Set - accuracy: 0.47, precision: 0.55, recall: 0.74, f1-score: 0.61,\n","    Validation Set - accuracy: 0.17, precision: 0.05, recall: 0.19, f1-score: 0.08,\n","(Epoch 26), time: 6.0s, loss: 0.920\n","    Training Set - accuracy: 0.48, precision: 0.54, recall: 0.72, f1-score: 0.60,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 27), time: 6.0s, loss: 0.914\n","    Training Set - accuracy: 0.47, precision: 0.52, recall: 0.74, f1-score: 0.59,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 28), time: 6.0s, loss: 0.902\n","    Training Set - accuracy: 0.47, precision: 0.52, recall: 0.74, f1-score: 0.59,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 29), time: 6.0s, loss: 0.871\n","    Training Set - accuracy: 0.47, precision: 0.51, recall: 0.73, f1-score: 0.59,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 30), time: 6.0s, loss: 0.838\n","    Training Set - accuracy: 0.49, precision: 0.58, recall: 0.75, f1-score: 0.63,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 31), time: 6.0s, loss: 0.833\n","    Training Set - accuracy: 0.47, precision: 0.56, recall: 0.74, f1-score: 0.61,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 32), time: 6.0s, loss: 0.841\n","    Training Set - accuracy: 0.47, precision: 0.54, recall: 0.73, f1-score: 0.60,\n","    Validation Set - accuracy: 0.20, precision: 0.05, recall: 0.22, f1-score: 0.09,\n","(Epoch 33), time: 6.0s, loss: 0.806\n","    Training Set - accuracy: 0.49, precision: 0.55, recall: 0.75, f1-score: 0.62,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 34), time: 6.0s, loss: 0.784\n","    Training Set - accuracy: 0.49, precision: 0.59, recall: 0.75, f1-score: 0.64,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 35), time: 6.0s, loss: 0.757\n","    Training Set - accuracy: 0.49, precision: 0.56, recall: 0.75, f1-score: 0.62,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 36), time: 6.0s, loss: 0.735\n","    Training Set - accuracy: 0.49, precision: 0.59, recall: 0.75, f1-score: 0.64,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 37), time: 6.0s, loss: 0.725\n","    Training Set - accuracy: 0.49, precision: 0.57, recall: 0.75, f1-score: 0.63,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 38), time: 6.0s, loss: 0.709\n","    Training Set - accuracy: 0.49, precision: 0.54, recall: 0.75, f1-score: 0.61,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 39), time: 6.0s, loss: 0.689\n","    Training Set - accuracy: 0.49, precision: 0.55, recall: 0.75, f1-score: 0.62,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 40), time: 6.0s, loss: 0.694\n","    Training Set - accuracy: 0.48, precision: 0.48, recall: 0.74, f1-score: 0.57,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 41), time: 5.8s, loss: 0.661\n","    Training Set - accuracy: 0.49, precision: 0.51, recall: 0.75, f1-score: 0.59,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 42), time: 5.8s, loss: 0.660\n","    Training Set - accuracy: 0.49, precision: 0.51, recall: 0.75, f1-score: 0.58,\n","    Validation Set - accuracy: 0.20, precision: 0.05, recall: 0.22, f1-score: 0.09,\n","(Epoch 43), time: 5.8s, loss: 0.643\n","    Training Set - accuracy: 0.49, precision: 0.50, recall: 0.75, f1-score: 0.58,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 44), time: 5.8s, loss: 0.628\n","    Training Set - accuracy: 0.49, precision: 0.47, recall: 0.75, f1-score: 0.55,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 45), time: 5.8s, loss: 0.622\n","    Training Set - accuracy: 0.49, precision: 0.48, recall: 0.75, f1-score: 0.57,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 46), time: 5.8s, loss: 0.607\n","    Training Set - accuracy: 0.49, precision: 0.47, recall: 0.75, f1-score: 0.55,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 47), time: 6.0s, loss: 0.599\n","    Training Set - accuracy: 0.49, precision: 0.45, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 48), time: 6.0s, loss: 0.590\n","    Training Set - accuracy: 0.49, precision: 0.45, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 49), time: 6.0s, loss: 0.586\n","    Training Set - accuracy: 0.49, precision: 0.44, recall: 0.75, f1-score: 0.52,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 50), time: 6.0s, loss: 0.576\n","    Training Set - accuracy: 0.49, precision: 0.70, recall: 0.75, f1-score: 0.55,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.09,\n","(Epoch 51), time: 6.0s, loss: 0.565\n","    Training Set - accuracy: 0.49, precision: 0.70, recall: 0.75, f1-score: 0.54,\n","    Validation Set - accuracy: 0.23, precision: 0.06, recall: 0.25, f1-score: 0.10,\n","(Epoch 52), time: 5.8s, loss: 0.560\n","    Training Set - accuracy: 0.54, precision: 0.70, recall: 0.78, f1-score: 0.58,\n","    Validation Set - accuracy: 0.28, precision: 0.31, recall: 0.27, f1-score: 0.14,\n","(Epoch 53), time: 5.8s, loss: 0.559\n","    Training Set - accuracy: 0.56, precision: 0.70, recall: 0.79, f1-score: 0.59,\n","    Validation Set - accuracy: 0.25, precision: 0.31, recall: 0.26, f1-score: 0.12,\n","(Epoch 54), time: 5.8s, loss: 0.546\n","    Training Set - accuracy: 0.56, precision: 0.72, recall: 0.79, f1-score: 0.62,\n","    Validation Set - accuracy: 0.28, precision: 0.31, recall: 0.27, f1-score: 0.14,\n","(Epoch 55), time: 5.8s, loss: 0.541\n","    Training Set - accuracy: 0.58, precision: 0.72, recall: 0.80, f1-score: 0.63,\n","    Validation Set - accuracy: 0.35, precision: 0.32, recall: 0.29, f1-score: 0.19,\n","(Epoch 56), time: 5.8s, loss: 0.536\n","    Training Set - accuracy: 0.64, precision: 0.72, recall: 0.82, f1-score: 0.67,\n","    Validation Set - accuracy: 0.35, precision: 0.32, recall: 0.29, f1-score: 0.18,\n","(Epoch 57), time: 5.8s, loss: 0.529\n","    Training Set - accuracy: 0.68, precision: 0.75, recall: 0.84, f1-score: 0.72,\n","    Validation Set - accuracy: 0.33, precision: 0.32, recall: 0.29, f1-score: 0.17,\n","(Epoch 58), time: 5.8s, loss: 0.523\n","    Training Set - accuracy: 0.69, precision: 0.75, recall: 0.85, f1-score: 0.72,\n","    Validation Set - accuracy: 0.28, precision: 0.31, recall: 0.27, f1-score: 0.14,\n","(Epoch 59), time: 5.8s, loss: 0.517\n","    Training Set - accuracy: 0.76, precision: 0.78, recall: 0.88, f1-score: 0.78,\n","    Validation Set - accuracy: 0.33, precision: 0.32, recall: 0.29, f1-score: 0.17,\n","(Epoch 60), time: 5.8s, loss: 0.510\n","    Training Set - accuracy: 0.74, precision: 0.78, recall: 0.87, f1-score: 0.77,\n","    Validation Set - accuracy: 0.33, precision: 0.32, recall: 0.29, f1-score: 0.17,\n","(Epoch 61), time: 5.8s, loss: 0.514\n","    Training Set - accuracy: 0.75, precision: 0.79, recall: 0.88, f1-score: 0.79,\n","    Validation Set - accuracy: 0.33, precision: 0.32, recall: 0.29, f1-score: 0.17,\n","(Epoch 62), time: 6.0s, loss: 0.509\n","    Training Set - accuracy: 0.82, precision: 0.83, recall: 0.91, f1-score: 0.84,\n","    Validation Set - accuracy: 0.40, precision: 0.32, recall: 0.31, f1-score: 0.21,\n","(Epoch 63), time: 6.0s, loss: 0.502\n","    Training Set - accuracy: 0.84, precision: 0.84, recall: 0.92, f1-score: 0.86,\n","    Validation Set - accuracy: 0.40, precision: 0.32, recall: 0.31, f1-score: 0.21,\n","(Epoch 64), time: 6.0s, loss: 0.498\n","    Training Set - accuracy: 0.90, precision: 0.87, recall: 0.95, f1-score: 0.90,\n","Confusion Matrix:\n","[[ 5 21  0  2]\n"," [ 0  9  0  0]\n"," [ 0  2  0  0]\n"," [ 0  1  0  0]]\n","    Validation Set - accuracy: 0.35, precision: 0.32, recall: 0.29, f1-score: 0.18,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3 (val 85 - 126)\n","(Epoch 0), time: 6.0s, loss: 1.456\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 1), time: 6.0s, loss: 1.442\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 2), time: 6.0s, loss: 1.444\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 3), time: 6.0s, loss: 1.435\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 4), time: 6.0s, loss: 1.438\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 5), time: 6.0s, loss: 1.436\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 6), time: 6.0s, loss: 1.436\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 7), time: 6.0s, loss: 1.437\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 8), time: 6.0s, loss: 1.437\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 9), time: 6.0s, loss: 1.437\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 10), time: 6.0s, loss: 1.440\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 11), time: 6.0s, loss: 1.438\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 12), time: 6.0s, loss: 1.434\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 13), time: 6.1s, loss: 1.433\n","    Training Set - accuracy: 0.04, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","    Validation Set - accuracy: 0.10, precision: 0.03, recall: 0.25, f1-score: 0.05,\n","(Epoch 14), time: 6.1s, loss: 1.430\n","    Training Set - accuracy: 0.05, precision: 0.18, recall: 0.26, f1-score: 0.03,\n","    Validation Set - accuracy: 0.12, precision: 0.15, recall: 0.27, f1-score: 0.08,\n","(Epoch 15), time: 6.0s, loss: 1.432\n","    Training Set - accuracy: 0.06, precision: 0.10, recall: 0.18, f1-score: 0.04,\n","    Validation Set - accuracy: 0.12, precision: 0.15, recall: 0.27, f1-score: 0.08,\n","(Epoch 16), time: 6.0s, loss: 1.405\n","    Training Set - accuracy: 0.19, precision: 0.22, recall: 0.28, f1-score: 0.12,\n","    Validation Set - accuracy: 0.23, precision: 0.28, recall: 0.33, f1-score: 0.18,\n","(Epoch 17), time: 5.8s, loss: 1.379\n","    Training Set - accuracy: 0.46, precision: 0.19, recall: 0.24, f1-score: 0.20,\n","    Validation Set - accuracy: 0.42, precision: 0.29, recall: 0.28, f1-score: 0.22,\n","(Epoch 18), time: 5.8s, loss: 1.346\n","    Training Set - accuracy: 0.58, precision: 0.24, recall: 0.25, f1-score: 0.21,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 19), time: 5.8s, loss: 1.314\n","    Training Set - accuracy: 0.59, precision: 0.15, recall: 0.25, f1-score: 0.19,\n","    Validation Set - accuracy: 0.38, precision: 0.09, recall: 0.25, f1-score: 0.14,\n","(Epoch 20), time: 5.8s, loss: 1.260\n","    Training Set - accuracy: 0.62, precision: 0.44, recall: 0.38, f1-score: 0.36,\n","    Validation Set - accuracy: 0.38, precision: 0.10, recall: 0.25, f1-score: 0.14,\n","(Epoch 21), time: 5.8s, loss: 1.185\n","    Training Set - accuracy: 0.66, precision: 0.53, recall: 0.62, f1-score: 0.56,\n","    Validation Set - accuracy: 0.38, precision: 0.23, recall: 0.25, f1-score: 0.17,\n","(Epoch 22), time: 5.8s, loss: 1.109\n","    Training Set - accuracy: 0.63, precision: 0.45, recall: 0.60, f1-score: 0.50,\n","    Validation Set - accuracy: 0.35, precision: 0.09, recall: 0.23, f1-score: 0.13,\n","(Epoch 23), time: 5.8s, loss: 1.039\n","    Training Set - accuracy: 0.68, precision: 0.65, recall: 0.68, f1-score: 0.57,\n","    Validation Set - accuracy: 0.38, precision: 0.34, recall: 0.25, f1-score: 0.16,\n","(Epoch 24), time: 5.8s, loss: 0.964\n","    Training Set - accuracy: 0.71, precision: 0.74, recall: 0.70, f1-score: 0.59,\n","    Validation Set - accuracy: 0.40, precision: 0.23, recall: 0.27, f1-score: 0.17,\n","(Epoch 25), time: 5.8s, loss: 0.905\n","    Training Set - accuracy: 0.74, precision: 0.73, recall: 0.75, f1-score: 0.67,\n","    Validation Set - accuracy: 0.38, precision: 0.20, recall: 0.25, f1-score: 0.20,\n","(Epoch 26), time: 5.8s, loss: 0.853\n","    Training Set - accuracy: 0.72, precision: 0.73, recall: 0.75, f1-score: 0.67,\n","    Validation Set - accuracy: 0.35, precision: 0.24, recall: 0.28, f1-score: 0.23,\n","(Epoch 27), time: 5.8s, loss: 0.814\n","    Training Set - accuracy: 0.72, precision: 0.79, recall: 0.76, f1-score: 0.71,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.33, f1-score: 0.28,\n","(Epoch 28), time: 5.8s, loss: 0.806\n","    Training Set - accuracy: 0.72, precision: 0.78, recall: 0.75, f1-score: 0.72,\n","    Validation Set - accuracy: 0.38, precision: 0.18, recall: 0.25, f1-score: 0.16,\n","(Epoch 29), time: 5.8s, loss: 0.755\n","    Training Set - accuracy: 0.74, precision: 0.76, recall: 0.78, f1-score: 0.72,\n","    Validation Set - accuracy: 0.35, precision: 0.09, recall: 0.23, f1-score: 0.13,\n","(Epoch 30), time: 5.8s, loss: 0.715\n","    Training Set - accuracy: 0.81, precision: 0.84, recall: 0.82, f1-score: 0.77,\n","    Validation Set - accuracy: 0.38, precision: 0.18, recall: 0.25, f1-score: 0.19,\n","(Epoch 31), time: 5.8s, loss: 0.680\n","    Training Set - accuracy: 0.79, precision: 0.93, recall: 0.81, f1-score: 0.80,\n","    Validation Set - accuracy: 0.40, precision: 0.20, recall: 0.26, f1-score: 0.20,\n","(Epoch 32), time: 5.8s, loss: 0.644\n","    Training Set - accuracy: 0.84, precision: 0.94, recall: 0.86, f1-score: 0.87,\n","    Validation Set - accuracy: 0.40, precision: 0.19, recall: 0.26, f1-score: 0.21,\n","(Epoch 33), time: 5.8s, loss: 0.616\n","    Training Set - accuracy: 0.84, precision: 0.94, recall: 0.86, f1-score: 0.87,\n","    Validation Set - accuracy: 0.47, precision: 0.24, recall: 0.31, f1-score: 0.27,\n","(Epoch 34), time: 5.8s, loss: 0.591\n","    Training Set - accuracy: 0.89, precision: 0.96, recall: 0.91, f1-score: 0.92,\n","    Validation Set - accuracy: 0.47, precision: 0.24, recall: 0.31, f1-score: 0.27,\n","(Epoch 35), time: 5.8s, loss: 0.563\n","    Training Set - accuracy: 0.89, precision: 0.94, recall: 0.91, f1-score: 0.92,\n","    Validation Set - accuracy: 0.50, precision: 0.25, recall: 0.32, f1-score: 0.28,\n","(Epoch 36), time: 5.8s, loss: 0.548\n","    Training Set - accuracy: 0.89, precision: 0.93, recall: 0.91, f1-score: 0.91,\n","    Validation Set - accuracy: 0.42, precision: 0.22, recall: 0.28, f1-score: 0.24,\n","(Epoch 37), time: 5.8s, loss: 0.535\n","    Training Set - accuracy: 0.89, precision: 0.94, recall: 0.91, f1-score: 0.92,\n","    Validation Set - accuracy: 0.40, precision: 0.19, recall: 0.26, f1-score: 0.21,\n","(Epoch 38), time: 5.8s, loss: 0.505\n","    Training Set - accuracy: 0.91, precision: 0.95, recall: 0.93, f1-score: 0.94,\n","    Validation Set - accuracy: 0.42, precision: 0.23, recall: 0.28, f1-score: 0.23,\n","(Epoch 39), time: 5.8s, loss: 0.476\n","    Training Set - accuracy: 0.93, precision: 0.96, recall: 0.94, f1-score: 0.95,\n","Confusion Matrix:\n","[[12  3  0  0]\n"," [12  4  0  0]\n"," [ 3  2  0  0]\n"," [ 3  1  0  0]]\n","    Validation Set - accuracy: 0.40, precision: 0.20, recall: 0.26, f1-score: 0.21,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4 (val 127 - 168)\n","(Epoch 0), time: 6.0s, loss: 1.413\n","    Training Set - accuracy: 0.06, precision: 0.02, recall: 0.23, f1-score: 0.03,\n","    Validation Set - accuracy: 0.20, precision: 0.05, recall: 0.25, f1-score: 0.08,\n","(Epoch 1), time: 6.0s, loss: 1.405\n","    Training Set - accuracy: 0.08, precision: 0.27, recall: 0.26, f1-score: 0.05,\n","    Validation Set - accuracy: 0.23, precision: 0.18, recall: 0.27, f1-score: 0.12,\n","(Epoch 2), time: 6.0s, loss: 1.402\n","    Training Set - accuracy: 0.13, precision: 0.12, recall: 0.27, f1-score: 0.11,\n","    Validation Set - accuracy: 0.25, precision: 0.12, recall: 0.23, f1-score: 0.15,\n","(Epoch 3), time: 6.0s, loss: 1.399\n","    Training Set - accuracy: 0.29, precision: 0.15, recall: 0.23, f1-score: 0.13,\n","    Validation Set - accuracy: 0.30, precision: 0.18, recall: 0.23, f1-score: 0.16,\n","(Epoch 4), time: 6.0s, loss: 1.383\n","    Training Set - accuracy: 0.34, precision: 0.25, recall: 0.25, f1-score: 0.16,\n","    Validation Set - accuracy: 0.33, precision: 0.20, recall: 0.26, f1-score: 0.14,\n","(Epoch 5), time: 6.0s, loss: 1.382\n","    Training Set - accuracy: 0.36, precision: 0.21, recall: 0.23, f1-score: 0.19,\n","    Validation Set - accuracy: 0.47, precision: 0.24, recall: 0.33, f1-score: 0.27,\n","(Epoch 6), time: 5.8s, loss: 1.362\n","    Training Set - accuracy: 0.50, precision: 0.21, recall: 0.25, f1-score: 0.23,\n","    Validation Set - accuracy: 0.40, precision: 0.19, recall: 0.24, f1-score: 0.19,\n","(Epoch 7), time: 5.8s, loss: 1.334\n","    Training Set - accuracy: 0.57, precision: 0.25, recall: 0.26, f1-score: 0.23,\n","    Validation Set - accuracy: 0.38, precision: 0.11, recall: 0.21, f1-score: 0.14,\n","(Epoch 8), time: 5.8s, loss: 1.318\n","    Training Set - accuracy: 0.61, precision: 0.28, recall: 0.29, f1-score: 0.26,\n","    Validation Set - accuracy: 0.50, precision: 0.25, recall: 0.29, f1-score: 0.23,\n","(Epoch 9), time: 5.8s, loss: 1.301\n","    Training Set - accuracy: 0.56, precision: 0.21, recall: 0.26, f1-score: 0.22,\n","    Validation Set - accuracy: 0.42, precision: 0.18, recall: 0.25, f1-score: 0.20,\n","(Epoch 10), time: 5.8s, loss: 1.275\n","    Training Set - accuracy: 0.56, precision: 0.22, recall: 0.26, f1-score: 0.23,\n","    Validation Set - accuracy: 0.47, precision: 0.28, recall: 0.28, f1-score: 0.22,\n","(Epoch 11), time: 5.8s, loss: 1.260\n","    Training Set - accuracy: 0.58, precision: 0.23, recall: 0.27, f1-score: 0.23,\n","    Validation Set - accuracy: 0.42, precision: 0.19, recall: 0.24, f1-score: 0.18,\n","(Epoch 12), time: 5.8s, loss: 1.261\n","    Training Set - accuracy: 0.61, precision: 0.27, recall: 0.29, f1-score: 0.27,\n","    Validation Set - accuracy: 0.53, precision: 0.29, recall: 0.32, f1-score: 0.27,\n","(Epoch 13), time: 5.8s, loss: 1.249\n","    Training Set - accuracy: 0.56, precision: 0.22, recall: 0.26, f1-score: 0.23,\n","    Validation Set - accuracy: 0.45, precision: 0.24, recall: 0.26, f1-score: 0.21,\n","(Epoch 14), time: 5.8s, loss: 1.223\n","    Training Set - accuracy: 0.61, precision: 0.27, recall: 0.29, f1-score: 0.27,\n","    Validation Set - accuracy: 0.53, precision: 0.27, recall: 0.33, f1-score: 0.28,\n","(Epoch 15), time: 5.8s, loss: 1.217\n","    Training Set - accuracy: 0.60, precision: 0.39, recall: 0.31, f1-score: 0.31,\n","    Validation Set - accuracy: 0.47, precision: 0.28, recall: 0.28, f1-score: 0.22,\n","(Epoch 16), time: 5.8s, loss: 1.187\n","    Training Set - accuracy: 0.59, precision: 0.33, recall: 0.32, f1-score: 0.31,\n","    Validation Set - accuracy: 0.50, precision: 0.29, recall: 0.29, f1-score: 0.23,\n","(Epoch 17), time: 5.8s, loss: 1.179\n","    Training Set - accuracy: 0.57, precision: 0.28, recall: 0.30, f1-score: 0.28,\n","    Validation Set - accuracy: 0.50, precision: 0.27, recall: 0.30, f1-score: 0.25,\n","(Epoch 18), time: 5.8s, loss: 1.158\n","    Training Set - accuracy: 0.56, precision: 0.25, recall: 0.27, f1-score: 0.25,\n","    Validation Set - accuracy: 0.45, precision: 0.24, recall: 0.26, f1-score: 0.21,\n","(Epoch 19), time: 5.8s, loss: 1.143\n","    Training Set - accuracy: 0.57, precision: 0.26, recall: 0.28, f1-score: 0.26,\n","    Validation Set - accuracy: 0.38, precision: 0.11, recall: 0.21, f1-score: 0.14,\n","(Epoch 20), time: 5.8s, loss: 1.119\n","    Training Set - accuracy: 0.59, precision: 0.32, recall: 0.35, f1-score: 0.32,\n","    Validation Set - accuracy: 0.42, precision: 0.18, recall: 0.24, f1-score: 0.19,\n","(Epoch 21), time: 5.8s, loss: 1.099\n","    Training Set - accuracy: 0.58, precision: 0.31, recall: 0.39, f1-score: 0.33,\n","    Validation Set - accuracy: 0.53, precision: 0.28, recall: 0.32, f1-score: 0.28,\n","(Epoch 22), time: 5.8s, loss: 1.089\n","    Training Set - accuracy: 0.64, precision: 0.39, recall: 0.45, f1-score: 0.37,\n","    Validation Set - accuracy: 0.47, precision: 0.32, recall: 0.28, f1-score: 0.26,\n","(Epoch 23), time: 5.8s, loss: 1.100\n","    Training Set - accuracy: 0.59, precision: 0.32, recall: 0.39, f1-score: 0.33,\n","    Validation Set - accuracy: 0.45, precision: 0.24, recall: 0.26, f1-score: 0.19,\n","(Epoch 24), time: 5.8s, loss: 1.069\n","    Training Set - accuracy: 0.59, precision: 0.34, recall: 0.41, f1-score: 0.33,\n","    Validation Set - accuracy: 0.45, precision: 0.12, recall: 0.25, f1-score: 0.16,\n","(Epoch 25), time: 5.8s, loss: 1.055\n","    Training Set - accuracy: 0.62, precision: 0.36, recall: 0.45, f1-score: 0.34,\n","    Validation Set - accuracy: 0.40, precision: 0.13, recall: 0.22, f1-score: 0.16,\n","(Epoch 26), time: 5.8s, loss: 1.031\n","    Training Set - accuracy: 0.63, precision: 0.43, recall: 0.47, f1-score: 0.37,\n","    Validation Set - accuracy: 0.47, precision: 0.25, recall: 0.28, f1-score: 0.22,\n","(Epoch 27), time: 5.8s, loss: 1.050\n","    Training Set - accuracy: 0.60, precision: 0.58, recall: 0.42, f1-score: 0.38,\n","    Validation Set - accuracy: 0.50, precision: 0.32, recall: 0.34, f1-score: 0.32,\n","(Epoch 28), time: 5.8s, loss: 1.042\n","    Training Set - accuracy: 0.61, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","    Validation Set - accuracy: 0.47, precision: 0.25, recall: 0.28, f1-score: 0.23,\n","(Epoch 29), time: 5.8s, loss: 1.029\n","    Training Set - accuracy: 0.66, precision: 0.49, recall: 0.52, f1-score: 0.41,\n","    Validation Set - accuracy: 0.47, precision: 0.30, recall: 0.30, f1-score: 0.28,\n","(Epoch 30), time: 5.8s, loss: 0.997\n","    Training Set - accuracy: 0.62, precision: 0.37, recall: 0.44, f1-score: 0.37,\n","    Validation Set - accuracy: 0.50, precision: 0.24, recall: 0.29, f1-score: 0.24,\n","(Epoch 31), time: 5.8s, loss: 1.001\n","    Training Set - accuracy: 0.66, precision: 0.46, recall: 0.52, f1-score: 0.43,\n","    Validation Set - accuracy: 0.50, precision: 0.24, recall: 0.31, f1-score: 0.26,\n","(Epoch 32), time: 5.8s, loss: 0.957\n","    Training Set - accuracy: 0.66, precision: 0.43, recall: 0.49, f1-score: 0.43,\n","    Validation Set - accuracy: 0.45, precision: 0.20, recall: 0.26, f1-score: 0.21,\n","(Epoch 33), time: 5.8s, loss: 0.945\n","    Training Set - accuracy: 0.68, precision: 0.71, recall: 0.57, f1-score: 0.53,\n","    Validation Set - accuracy: 0.50, precision: 0.31, recall: 0.30, f1-score: 0.25,\n","(Epoch 34), time: 5.8s, loss: 0.915\n","    Training Set - accuracy: 0.68, precision: 0.47, recall: 0.52, f1-score: 0.44,\n","    Validation Set - accuracy: 0.47, precision: 0.23, recall: 0.28, f1-score: 0.23,\n","(Epoch 35), time: 5.8s, loss: 0.903\n","    Training Set - accuracy: 0.66, precision: 0.68, recall: 0.50, f1-score: 0.47,\n","    Validation Set - accuracy: 0.45, precision: 0.27, recall: 0.28, f1-score: 0.26,\n","(Epoch 36), time: 5.8s, loss: 0.877\n","    Training Set - accuracy: 0.68, precision: 0.71, recall: 0.55, f1-score: 0.50,\n","    Validation Set - accuracy: 0.53, precision: 0.25, recall: 0.32, f1-score: 0.27,\n","(Epoch 37), time: 5.8s, loss: 0.870\n","    Training Set - accuracy: 0.71, precision: 0.75, recall: 0.57, f1-score: 0.52,\n","    Validation Set - accuracy: 0.50, precision: 0.31, recall: 0.32, f1-score: 0.29,\n","(Epoch 38), time: 5.8s, loss: 0.847\n","    Training Set - accuracy: 0.72, precision: 0.75, recall: 0.59, f1-score: 0.55,\n","    Validation Set - accuracy: 0.47, precision: 0.21, recall: 0.28, f1-score: 0.24,\n","(Epoch 39), time: 5.8s, loss: 0.842\n","    Training Set - accuracy: 0.72, precision: 0.75, recall: 0.59, f1-score: 0.55,\n","    Validation Set - accuracy: 0.42, precision: 0.24, recall: 0.27, f1-score: 0.25,\n","(Epoch 40), time: 5.8s, loss: 0.809\n","    Training Set - accuracy: 0.75, precision: 0.79, recall: 0.63, f1-score: 0.62,\n","    Validation Set - accuracy: 0.60, precision: 0.54, recall: 0.40, f1-score: 0.38,\n","(Epoch 41), time: 5.8s, loss: 0.802\n","    Training Set - accuracy: 0.74, precision: 0.77, recall: 0.67, f1-score: 0.66,\n","    Validation Set - accuracy: 0.53, precision: 0.50, recall: 0.36, f1-score: 0.34,\n","(Epoch 42), time: 5.8s, loss: 0.791\n","    Training Set - accuracy: 0.76, precision: 0.80, recall: 0.71, f1-score: 0.71,\n","    Validation Set - accuracy: 0.47, precision: 0.31, recall: 0.31, f1-score: 0.29,\n","(Epoch 43), time: 5.8s, loss: 0.772\n","    Training Set - accuracy: 0.78, precision: 0.81, recall: 0.70, f1-score: 0.70,\n","    Validation Set - accuracy: 0.68, precision: 0.49, recall: 0.47, f1-score: 0.46,\n","(Epoch 44), time: 5.8s, loss: 0.756\n","    Training Set - accuracy: 0.76, precision: 0.79, recall: 0.66, f1-score: 0.64,\n","    Validation Set - accuracy: 0.55, precision: 0.26, recall: 0.34, f1-score: 0.29,\n","(Epoch 45), time: 5.8s, loss: 0.731\n","    Training Set - accuracy: 0.80, precision: 0.83, recall: 0.74, f1-score: 0.74,\n","    Validation Set - accuracy: 0.55, precision: 0.27, recall: 0.35, f1-score: 0.30,\n","(Epoch 46), time: 5.8s, loss: 0.727\n","    Training Set - accuracy: 0.82, precision: 0.83, recall: 0.79, f1-score: 0.79,\n","    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.34, f1-score: 0.32,\n","(Epoch 47), time: 5.8s, loss: 0.725\n","    Training Set - accuracy: 0.81, precision: 0.84, recall: 0.80, f1-score: 0.81,\n","    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.35, f1-score: 0.35,\n","(Epoch 48), time: 5.8s, loss: 0.707\n","    Training Set - accuracy: 0.83, precision: 0.86, recall: 0.84, f1-score: 0.85,\n","    Validation Set - accuracy: 0.50, precision: 0.36, recall: 0.36, f1-score: 0.36,\n","(Epoch 49), time: 5.8s, loss: 0.695\n","    Training Set - accuracy: 0.82, precision: 0.85, recall: 0.84, f1-score: 0.84,\n","    Validation Set - accuracy: 0.53, precision: 0.24, recall: 0.33, f1-score: 0.28,\n","(Epoch 50), time: 5.8s, loss: 0.660\n","    Training Set - accuracy: 0.88, precision: 0.91, recall: 0.90, f1-score: 0.90,\n","    Validation Set - accuracy: 0.50, precision: 0.37, recall: 0.35, f1-score: 0.34,\n","(Epoch 51), time: 5.8s, loss: 0.651\n","    Training Set - accuracy: 0.87, precision: 0.90, recall: 0.89, f1-score: 0.90,\n","    Validation Set - accuracy: 0.55, precision: 0.42, recall: 0.42, f1-score: 0.41,\n","(Epoch 52), time: 5.8s, loss: 0.632\n","    Training Set - accuracy: 0.89, precision: 0.91, recall: 0.91, f1-score: 0.91,\n","    Validation Set - accuracy: 0.50, precision: 0.39, recall: 0.36, f1-score: 0.37,\n","(Epoch 53), time: 5.8s, loss: 0.605\n","    Training Set - accuracy: 0.86, precision: 0.90, recall: 0.89, f1-score: 0.89,\n","    Validation Set - accuracy: 0.60, precision: 0.47, recall: 0.43, f1-score: 0.43,\n","(Epoch 54), time: 5.8s, loss: 0.577\n","    Training Set - accuracy: 0.89, precision: 0.91, recall: 0.90, f1-score: 0.91,\n","    Validation Set - accuracy: 0.50, precision: 0.39, recall: 0.36, f1-score: 0.37,\n","(Epoch 55), time: 5.8s, loss: 0.554\n","    Training Set - accuracy: 0.89, precision: 0.90, recall: 0.91, f1-score: 0.90,\n","    Validation Set - accuracy: 0.53, precision: 0.37, recall: 0.34, f1-score: 0.32,\n","(Epoch 56), time: 5.8s, loss: 0.541\n","    Training Set - accuracy: 0.90, precision: 0.92, recall: 0.92, f1-score: 0.92,\n","    Validation Set - accuracy: 0.53, precision: 0.51, recall: 0.36, f1-score: 0.34,\n","(Epoch 57), time: 5.8s, loss: 0.528\n","    Training Set - accuracy: 0.91, precision: 0.93, recall: 0.91, f1-score: 0.92,\n","    Validation Set - accuracy: 0.45, precision: 0.35, recall: 0.33, f1-score: 0.33,\n","(Epoch 58), time: 5.8s, loss: 0.497\n","    Training Set - accuracy: 0.94, precision: 0.95, recall: 0.94, f1-score: 0.94,\n","Confusion Matrix:\n","[[12  6  0  0]\n"," [ 4  6  2  0]\n"," [ 2  4  2  0]\n"," [ 0  2  0  0]]\n","    Validation Set - accuracy: 0.50, precision: 0.38, recall: 0.35, f1-score: 0.35,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5 (val 169 - 210)\n","(Epoch 0), time: 6.0s, loss: 1.419\n","    Training Set - accuracy: 0.07, precision: 0.12, recall: 0.26, f1-score: 0.04,\n","    Validation Set - accuracy: 0.07, precision: 0.26, recall: 0.27, f1-score: 0.06,\n","(Epoch 1), time: 6.0s, loss: 1.410\n","    Training Set - accuracy: 0.07, precision: 0.14, recall: 0.26, f1-score: 0.04,\n","    Validation Set - accuracy: 0.07, precision: 0.26, recall: 0.27, f1-score: 0.06,\n","(Epoch 2), time: 6.0s, loss: 1.408\n","    Training Set - accuracy: 0.14, precision: 0.17, recall: 0.26, f1-score: 0.09,\n","    Validation Set - accuracy: 0.15, precision: 0.14, recall: 0.32, f1-score: 0.12,\n","(Epoch 3), time: 6.0s, loss: 1.409\n","    Training Set - accuracy: 0.12, precision: 0.17, recall: 0.23, f1-score: 0.08,\n","    Validation Set - accuracy: 0.10, precision: 0.14, recall: 0.29, f1-score: 0.08,\n","(Epoch 4), time: 6.0s, loss: 1.412\n","    Training Set - accuracy: 0.07, precision: 0.11, recall: 0.18, f1-score: 0.05,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 5), time: 6.0s, loss: 1.407\n","    Training Set - accuracy: 0.09, precision: 0.17, recall: 0.24, f1-score: 0.06,\n","    Validation Set - accuracy: 0.05, precision: 0.01, recall: 0.25, f1-score: 0.02,\n","(Epoch 6), time: 6.0s, loss: 1.403\n","    Training Set - accuracy: 0.14, precision: 0.16, recall: 0.26, f1-score: 0.09,\n","    Validation Set - accuracy: 0.10, precision: 0.11, recall: 0.18, f1-score: 0.09,\n","(Epoch 7), time: 6.0s, loss: 1.401\n","    Training Set - accuracy: 0.17, precision: 0.19, recall: 0.27, f1-score: 0.11,\n","    Validation Set - accuracy: 0.07, precision: 0.06, recall: 0.27, f1-score: 0.05,\n","(Epoch 8), time: 6.0s, loss: 1.405\n","    Training Set - accuracy: 0.11, precision: 0.12, recall: 0.17, f1-score: 0.07,\n","    Validation Set - accuracy: 0.17, precision: 0.17, recall: 0.34, f1-score: 0.14,\n","(Epoch 9), time: 6.0s, loss: 1.401\n","    Training Set - accuracy: 0.25, precision: 0.20, recall: 0.33, f1-score: 0.15,\n","    Validation Set - accuracy: 0.07, precision: 0.06, recall: 0.27, f1-score: 0.05,\n","(Epoch 10), time: 6.0s, loss: 1.397\n","    Training Set - accuracy: 0.42, precision: 0.19, recall: 0.40, f1-score: 0.21,\n","    Validation Set - accuracy: 0.23, precision: 0.11, recall: 0.27, f1-score: 0.14,\n","(Epoch 11), time: 6.0s, loss: 1.390\n","    Training Set - accuracy: 0.50, precision: 0.19, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.25, precision: 0.09, recall: 0.18, f1-score: 0.12,\n","(Epoch 12), time: 6.0s, loss: 1.378\n","    Training Set - accuracy: 0.56, precision: 0.17, recall: 0.26, f1-score: 0.21,\n","    Validation Set - accuracy: 0.35, precision: 0.15, recall: 0.36, f1-score: 0.21,\n","(Epoch 13), time: 6.0s, loss: 1.346\n","    Training Set - accuracy: 0.61, precision: 0.26, recall: 0.36, f1-score: 0.30,\n","    Validation Set - accuracy: 0.35, precision: 0.28, recall: 0.39, f1-score: 0.28,\n","(Epoch 14), time: 6.0s, loss: 1.322\n","    Training Set - accuracy: 0.62, precision: 0.41, recall: 0.41, f1-score: 0.35,\n","    Validation Set - accuracy: 0.38, precision: 0.27, recall: 0.41, f1-score: 0.28,\n","(Epoch 15), time: 6.0s, loss: 1.288\n","    Training Set - accuracy: 0.61, precision: 0.32, recall: 0.41, f1-score: 0.35,\n","    Validation Set - accuracy: 0.38, precision: 0.24, recall: 0.50, f1-score: 0.32,\n","(Epoch 16), time: 6.0s, loss: 1.274\n","    Training Set - accuracy: 0.65, precision: 0.40, recall: 0.51, f1-score: 0.43,\n","    Validation Set - accuracy: 0.35, precision: 0.21, recall: 0.35, f1-score: 0.26,\n","(Epoch 17), time: 6.0s, loss: 1.225\n","    Training Set - accuracy: 0.62, precision: 0.35, recall: 0.57, f1-score: 0.42,\n","    Validation Set - accuracy: 0.30, precision: 0.20, recall: 0.45, f1-score: 0.26,\n","(Epoch 18), time: 6.0s, loss: 1.195\n","    Training Set - accuracy: 0.61, precision: 0.34, recall: 0.54, f1-score: 0.41,\n","    Validation Set - accuracy: 0.33, precision: 0.21, recall: 0.44, f1-score: 0.27,\n","(Epoch 19), time: 6.0s, loss: 1.135\n","    Training Set - accuracy: 0.66, precision: 0.63, recall: 0.66, f1-score: 0.47,\n","    Validation Set - accuracy: 0.33, precision: 0.23, recall: 0.47, f1-score: 0.30,\n","(Epoch 20), time: 6.0s, loss: 1.101\n","    Training Set - accuracy: 0.65, precision: 0.63, recall: 0.67, f1-score: 0.50,\n","    Validation Set - accuracy: 0.35, precision: 0.25, recall: 0.59, f1-score: 0.35,\n","(Epoch 21), time: 6.0s, loss: 1.029\n","    Training Set - accuracy: 0.72, precision: 0.68, recall: 0.73, f1-score: 0.59,\n","    Validation Set - accuracy: 0.30, precision: 0.27, recall: 0.45, f1-score: 0.32,\n","(Epoch 22), time: 6.0s, loss: 0.989\n","    Training Set - accuracy: 0.68, precision: 0.56, recall: 0.70, f1-score: 0.53,\n","    Validation Set - accuracy: 0.38, precision: 0.50, recall: 0.61, f1-score: 0.36,\n","(Epoch 23), time: 6.0s, loss: 0.934\n","    Training Set - accuracy: 0.75, precision: 0.69, recall: 0.76, f1-score: 0.62,\n","    Validation Set - accuracy: 0.33, precision: 0.41, recall: 0.36, f1-score: 0.23,\n","(Epoch 24), time: 6.0s, loss: 0.898\n","    Training Set - accuracy: 0.73, precision: 0.69, recall: 0.74, f1-score: 0.60,\n","    Validation Set - accuracy: 0.33, precision: 0.41, recall: 0.36, f1-score: 0.24,\n","(Epoch 25), time: 6.0s, loss: 0.845\n","    Training Set - accuracy: 0.79, precision: 0.72, recall: 0.80, f1-score: 0.71,\n","    Validation Set - accuracy: 0.33, precision: 0.41, recall: 0.36, f1-score: 0.24,\n","(Epoch 26), time: 6.0s, loss: 0.821\n","    Training Set - accuracy: 0.80, precision: 0.71, recall: 0.80, f1-score: 0.71,\n","    Validation Set - accuracy: 0.40, precision: 0.41, recall: 0.36, f1-score: 0.30,\n","(Epoch 27), time: 6.0s, loss: 0.791\n","    Training Set - accuracy: 0.82, precision: 0.73, recall: 0.82, f1-score: 0.72,\n","    Validation Set - accuracy: 0.38, precision: 0.41, recall: 0.35, f1-score: 0.26,\n","(Epoch 28), time: 6.0s, loss: 0.735\n","    Training Set - accuracy: 0.81, precision: 0.70, recall: 0.83, f1-score: 0.70,\n","    Validation Set - accuracy: 0.40, precision: 0.44, recall: 0.37, f1-score: 0.29,\n","(Epoch 29), time: 6.0s, loss: 0.715\n","    Training Set - accuracy: 0.84, precision: 0.74, recall: 0.85, f1-score: 0.74,\n","    Validation Set - accuracy: 0.33, precision: 0.28, recall: 0.32, f1-score: 0.23,\n","(Epoch 30), time: 6.0s, loss: 0.680\n","    Training Set - accuracy: 0.89, precision: 0.80, recall: 0.90, f1-score: 0.82,\n","    Validation Set - accuracy: 0.42, precision: 0.34, recall: 0.37, f1-score: 0.32,\n","(Epoch 31), time: 6.0s, loss: 0.674\n","    Training Set - accuracy: 0.85, precision: 0.75, recall: 0.86, f1-score: 0.76,\n","    Validation Set - accuracy: 0.38, precision: 0.30, recall: 0.34, f1-score: 0.29,\n","(Epoch 32), time: 6.0s, loss: 0.677\n","    Training Set - accuracy: 0.89, precision: 0.81, recall: 0.89, f1-score: 0.83,\n","    Validation Set - accuracy: 0.42, precision: 0.35, recall: 0.38, f1-score: 0.32,\n","(Epoch 33), time: 6.0s, loss: 0.646\n","    Training Set - accuracy: 0.88, precision: 0.79, recall: 0.89, f1-score: 0.82,\n","    Validation Set - accuracy: 0.42, precision: 0.39, recall: 0.35, f1-score: 0.31,\n","(Epoch 34), time: 6.0s, loss: 0.605\n","    Training Set - accuracy: 0.94, precision: 0.86, recall: 0.94, f1-score: 0.89,\n","    Validation Set - accuracy: 0.40, precision: 0.38, recall: 0.34, f1-score: 0.29,\n","(Epoch 35), time: 6.0s, loss: 0.575\n","    Training Set - accuracy: 0.93, precision: 0.85, recall: 0.93, f1-score: 0.88,\n","    Validation Set - accuracy: 0.42, precision: 0.35, recall: 0.38, f1-score: 0.33,\n","(Epoch 36), time: 6.0s, loss: 0.563\n","    Training Set - accuracy: 0.94, precision: 0.88, recall: 0.94, f1-score: 0.90,\n","    Validation Set - accuracy: 0.47, precision: 0.44, recall: 0.51, f1-score: 0.45,\n","(Epoch 37), time: 6.0s, loss: 0.550\n","    Training Set - accuracy: 0.96, precision: 0.91, recall: 0.96, f1-score: 0.93,\n","    Validation Set - accuracy: 0.42, precision: 0.37, recall: 0.38, f1-score: 0.34,\n","(Epoch 38), time: 6.0s, loss: 0.528\n","    Training Set - accuracy: 0.97, precision: 0.92, recall: 0.97, f1-score: 0.94,\n","    Validation Set - accuracy: 0.40, precision: 0.36, recall: 0.34, f1-score: 0.30,\n","(Epoch 39), time: 6.0s, loss: 0.501\n","    Training Set - accuracy: 0.97, precision: 0.94, recall: 0.97, f1-score: 0.96,\n","    Validation Set - accuracy: 0.47, precision: 0.46, recall: 0.41, f1-score: 0.39,\n","(Epoch 40), time: 5.9s, loss: 0.501\n","    Training Set - accuracy: 0.98, precision: 0.96, recall: 0.98, f1-score: 0.97,\n","    Validation Set - accuracy: 0.45, precision: 0.39, recall: 0.40, f1-score: 0.36,\n","(Epoch 41), time: 5.8s, loss: 0.483\n","    Training Set - accuracy: 0.98, precision: 0.96, recall: 0.98, f1-score: 0.97,\n","Confusion Matrix:\n","[[ 9  2  3  0]\n"," [12  5  2  0]\n"," [ 2  0  3  0]\n"," [ 1  1  0  0]]\n","    Validation Set - accuracy: 0.42, precision: 0.34, recall: 0.38, f1-score: 0.33,\n"]}],"source":["lost_hist_folds = train_model_cv5(model, dataset)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZazCaiIwQNM","outputId":"24afdd77-2848-4cd2-9958-aba3642047a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Initialization success if you see a tensor: tensor([[0.0302, 0.0080, 0.0226]], grad_fn=<AddmmBackward0>).\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 1 (val 0 - 42)\n","(Epoch 0), time: 5.8s, loss: 1.107\n","    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n","(Epoch 1), time: 5.8s, loss: 1.105\n","    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n","(Epoch 2), time: 5.8s, loss: 1.106\n","    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n","(Epoch 3), time: 5.8s, loss: 1.104\n","    Training Set - accuracy: 0.18, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","    Validation Set - accuracy: 0.05, precision: 0.02, recall: 0.33, f1-score: 0.03,\n","(Epoch 4), time: 5.8s, loss: 1.102\n","    Training Set - accuracy: 0.25, precision: 0.24, recall: 0.37, f1-score: 0.20,\n","    Validation Set - accuracy: 0.12, precision: 0.22, recall: 0.36, f1-score: 0.09,\n","(Epoch 5), time: 5.8s, loss: 1.105\n","    Training Set - accuracy: 0.33, precision: 0.32, recall: 0.43, f1-score: 0.27,\n","    Validation Set - accuracy: 0.20, precision: 0.31, recall: 0.39, f1-score: 0.14,\n","(Epoch 6), time: 5.8s, loss: 1.103\n","    Training Set - accuracy: 0.34, precision: 0.30, recall: 0.42, f1-score: 0.28,\n","    Validation Set - accuracy: 0.33, precision: 0.27, recall: 0.44, f1-score: 0.20,\n","(Epoch 7), time: 5.8s, loss: 1.105\n","    Training Set - accuracy: 0.38, precision: 0.27, recall: 0.42, f1-score: 0.30,\n","    Validation Set - accuracy: 0.42, precision: 0.31, recall: 0.48, f1-score: 0.25,\n","(Epoch 8), time: 5.8s, loss: 1.103\n","    Training Set - accuracy: 0.42, precision: 0.29, recall: 0.46, f1-score: 0.33,\n","    Validation Set - accuracy: 0.45, precision: 0.33, recall: 0.49, f1-score: 0.26,\n","(Epoch 9), time: 5.8s, loss: 1.102\n","    Training Set - accuracy: 0.41, precision: 0.27, recall: 0.43, f1-score: 0.32,\n","    Validation Set - accuracy: 0.53, precision: 0.32, recall: 0.53, f1-score: 0.30,\n","(Epoch 10), time: 5.8s, loss: 1.101\n","    Training Set - accuracy: 0.41, precision: 0.29, recall: 0.44, f1-score: 0.32,\n","    Validation Set - accuracy: 0.40, precision: 0.32, recall: 0.47, f1-score: 0.24,\n","(Epoch 11), time: 5.8s, loss: 1.099\n","    Training Set - accuracy: 0.45, precision: 0.31, recall: 0.49, f1-score: 0.35,\n","    Validation Set - accuracy: 0.40, precision: 0.32, recall: 0.47, f1-score: 0.24,\n","(Epoch 12), time: 5.8s, loss: 1.098\n","    Training Set - accuracy: 0.42, precision: 0.29, recall: 0.46, f1-score: 0.33,\n","    Validation Set - accuracy: 0.45, precision: 0.33, recall: 0.49, f1-score: 0.26,\n","(Epoch 13), time: 5.8s, loss: 1.098\n","    Training Set - accuracy: 0.44, precision: 0.32, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.55, precision: 0.33, recall: 0.54, f1-score: 0.31,\n","(Epoch 14), time: 5.8s, loss: 1.096\n","    Training Set - accuracy: 0.47, precision: 0.32, recall: 0.51, f1-score: 0.37,\n","    Validation Set - accuracy: 0.47, precision: 0.35, recall: 0.51, f1-score: 0.28,\n","(Epoch 15), time: 5.8s, loss: 1.089\n","    Training Set - accuracy: 0.42, precision: 0.31, recall: 0.48, f1-score: 0.34,\n","    Validation Set - accuracy: 0.50, precision: 0.33, recall: 0.52, f1-score: 0.29,\n","(Epoch 16), time: 5.8s, loss: 1.077\n","    Training Set - accuracy: 0.47, precision: 0.30, recall: 0.48, f1-score: 0.36,\n","    Validation Set - accuracy: 0.53, precision: 0.49, recall: 0.58, f1-score: 0.39,\n","(Epoch 17), time: 5.8s, loss: 1.067\n","    Training Set - accuracy: 0.53, precision: 0.50, recall: 0.53, f1-score: 0.48,\n","    Validation Set - accuracy: 0.50, precision: 0.41, recall: 0.57, f1-score: 0.36,\n","(Epoch 18), time: 5.8s, loss: 1.041\n","    Training Set - accuracy: 0.61, precision: 0.61, recall: 0.63, f1-score: 0.59,\n","    Validation Set - accuracy: 0.57, precision: 0.41, recall: 0.50, f1-score: 0.40,\n","(Epoch 19), time: 5.8s, loss: 1.015\n","    Training Set - accuracy: 0.64, precision: 0.63, recall: 0.67, f1-score: 0.63,\n","    Validation Set - accuracy: 0.60, precision: 0.42, recall: 0.51, f1-score: 0.41,\n","(Epoch 20), time: 5.8s, loss: 0.967\n","    Training Set - accuracy: 0.59, precision: 0.58, recall: 0.62, f1-score: 0.56,\n","    Validation Set - accuracy: 0.57, precision: 0.38, recall: 0.45, f1-score: 0.36,\n","(Epoch 21), time: 5.8s, loss: 0.941\n","    Training Set - accuracy: 0.64, precision: 0.62, recall: 0.65, f1-score: 0.62,\n","    Validation Set - accuracy: 0.55, precision: 0.38, recall: 0.44, f1-score: 0.35,\n","(Epoch 22), time: 5.8s, loss: 0.885\n","    Training Set - accuracy: 0.72, precision: 0.71, recall: 0.73, f1-score: 0.71,\n","    Validation Set - accuracy: 0.45, precision: 0.36, recall: 0.39, f1-score: 0.30,\n","(Epoch 23), time: 5.8s, loss: 0.837\n","    Training Set - accuracy: 0.74, precision: 0.73, recall: 0.77, f1-score: 0.75,\n","    Validation Set - accuracy: 0.45, precision: 0.38, recall: 0.45, f1-score: 0.33,\n","(Epoch 24), time: 5.8s, loss: 0.818\n","    Training Set - accuracy: 0.69, precision: 0.69, recall: 0.72, f1-score: 0.70,\n","    Validation Set - accuracy: 0.50, precision: 0.39, recall: 0.47, f1-score: 0.36,\n","(Epoch 25), time: 5.8s, loss: 0.821\n","    Training Set - accuracy: 0.64, precision: 0.67, recall: 0.67, f1-score: 0.65,\n","    Validation Set - accuracy: 0.62, precision: 0.37, recall: 0.42, f1-score: 0.36,\n","(Epoch 26), time: 5.8s, loss: 0.802\n","    Training Set - accuracy: 0.68, precision: 0.69, recall: 0.73, f1-score: 0.68,\n","    Validation Set - accuracy: 0.62, precision: 0.53, recall: 0.58, f1-score: 0.52,\n","(Epoch 27), time: 5.8s, loss: 0.733\n","    Training Set - accuracy: 0.74, precision: 0.81, recall: 0.77, f1-score: 0.78,\n","    Validation Set - accuracy: 0.38, precision: 0.36, recall: 0.42, f1-score: 0.29,\n","(Epoch 28), time: 5.8s, loss: 0.672\n","    Training Set - accuracy: 0.79, precision: 0.82, recall: 0.83, f1-score: 0.81,\n","    Validation Set - accuracy: 0.55, precision: 0.37, recall: 0.39, f1-score: 0.33,\n","(Epoch 29), time: 5.8s, loss: 0.626\n","    Training Set - accuracy: 0.82, precision: 0.87, recall: 0.86, f1-score: 0.85,\n","    Validation Set - accuracy: 0.53, precision: 0.46, recall: 0.54, f1-score: 0.44,\n","(Epoch 30), time: 5.8s, loss: 0.594\n","    Training Set - accuracy: 0.83, precision: 0.88, recall: 0.87, f1-score: 0.86,\n","    Validation Set - accuracy: 0.50, precision: 0.36, recall: 0.37, f1-score: 0.31,\n","(Epoch 31), time: 5.8s, loss: 0.558\n","    Training Set - accuracy: 0.84, precision: 0.89, recall: 0.88, f1-score: 0.87,\n","    Validation Set - accuracy: 0.55, precision: 0.40, recall: 0.49, f1-score: 0.38,\n","(Epoch 32), time: 5.8s, loss: 0.526\n","    Training Set - accuracy: 0.88, precision: 0.91, recall: 0.90, f1-score: 0.90,\n","    Validation Set - accuracy: 0.60, precision: 0.45, recall: 0.57, f1-score: 0.45,\n","(Epoch 33), time: 5.8s, loss: 0.501\n","    Training Set - accuracy: 0.89, precision: 0.91, recall: 0.91, f1-score: 0.91,\n","    Validation Set - accuracy: 0.62, precision: 0.46, recall: 0.58, f1-score: 0.47,\n","(Epoch 34), time: 5.8s, loss: 0.471\n","    Training Set - accuracy: 0.91, precision: 0.93, recall: 0.93, f1-score: 0.92,\n","Confusion Matrix:\n","[[21  8  4]\n"," [ 3  2  0]\n"," [ 1  1  0]]\n","    Validation Set - accuracy: 0.57, precision: 0.34, recall: 0.35, f1-score: 0.32,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2 (val 43 - 84)\n","(Epoch 0), time: 5.8s, loss: 1.098\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 1), time: 5.8s, loss: 1.096\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 2), time: 5.8s, loss: 1.094\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 3), time: 5.8s, loss: 1.094\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 4), time: 5.8s, loss: 1.094\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 5), time: 5.8s, loss: 1.093\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 6), time: 5.8s, loss: 1.089\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 7), time: 5.8s, loss: 1.085\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 8), time: 5.8s, loss: 1.082\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 9), time: 5.8s, loss: 1.068\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 10), time: 5.8s, loss: 1.054\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 11), time: 5.8s, loss: 1.046\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 12), time: 5.8s, loss: 1.030\n","    Training Set - accuracy: 0.51, precision: 0.17, recall: 0.33, f1-score: 0.23,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 13), time: 5.8s, loss: 1.013\n","    Training Set - accuracy: 0.53, precision: 0.40, recall: 0.35, f1-score: 0.25,\n","    Validation Set - accuracy: 0.70, precision: 0.23, recall: 0.33, f1-score: 0.27,\n","(Epoch 14), time: 5.8s, loss: 0.995\n","    Training Set - accuracy: 0.53, precision: 0.51, recall: 0.35, f1-score: 0.25,\n","    Validation Set - accuracy: 0.68, precision: 0.23, recall: 0.32, f1-score: 0.27,\n","(Epoch 15), time: 5.8s, loss: 0.970\n","    Training Set - accuracy: 0.54, precision: 0.40, recall: 0.37, f1-score: 0.30,\n","    Validation Set - accuracy: 0.60, precision: 0.22, recall: 0.29, f1-score: 0.25,\n","(Epoch 16), time: 5.8s, loss: 0.966\n","    Training Set - accuracy: 0.51, precision: 0.28, recall: 0.34, f1-score: 0.26,\n","    Validation Set - accuracy: 0.57, precision: 0.30, recall: 0.32, f1-score: 0.31,\n","(Epoch 17), time: 5.8s, loss: 0.932\n","    Training Set - accuracy: 0.61, precision: 0.46, recall: 0.44, f1-score: 0.40,\n","    Validation Set - accuracy: 0.60, precision: 0.22, recall: 0.29, f1-score: 0.25,\n","(Epoch 18), time: 5.8s, loss: 0.905\n","    Training Set - accuracy: 0.60, precision: 0.48, recall: 0.43, f1-score: 0.38,\n","    Validation Set - accuracy: 0.60, precision: 0.23, recall: 0.29, f1-score: 0.25,\n","(Epoch 19), time: 5.8s, loss: 0.908\n","    Training Set - accuracy: 0.59, precision: 0.40, recall: 0.44, f1-score: 0.41,\n","    Validation Set - accuracy: 0.60, precision: 0.39, recall: 0.44, f1-score: 0.39,\n","(Epoch 20), time: 5.9s, loss: 0.886\n","    Training Set - accuracy: 0.63, precision: 0.42, recall: 0.49, f1-score: 0.45,\n","    Validation Set - accuracy: 0.62, precision: 0.40, recall: 0.45, f1-score: 0.40,\n","(Epoch 21), time: 6.0s, loss: 0.874\n","    Training Set - accuracy: 0.68, precision: 0.46, recall: 0.53, f1-score: 0.49,\n","    Validation Set - accuracy: 0.68, precision: 0.41, recall: 0.47, f1-score: 0.43,\n","(Epoch 22), time: 6.0s, loss: 0.858\n","    Training Set - accuracy: 0.69, precision: 0.47, recall: 0.54, f1-score: 0.50,\n","    Validation Set - accuracy: 0.60, precision: 0.31, recall: 0.34, f1-score: 0.32,\n","(Epoch 23), time: 5.8s, loss: 0.848\n","    Training Set - accuracy: 0.71, precision: 0.49, recall: 0.56, f1-score: 0.51,\n","    Validation Set - accuracy: 0.60, precision: 0.35, recall: 0.39, f1-score: 0.36,\n","(Epoch 24), time: 5.8s, loss: 0.834\n","    Training Set - accuracy: 0.67, precision: 0.45, recall: 0.52, f1-score: 0.48,\n","    Validation Set - accuracy: 0.60, precision: 0.38, recall: 0.44, f1-score: 0.39,\n","(Epoch 25), time: 5.8s, loss: 0.804\n","    Training Set - accuracy: 0.69, precision: 0.46, recall: 0.55, f1-score: 0.50,\n","    Validation Set - accuracy: 0.57, precision: 0.34, recall: 0.37, f1-score: 0.35,\n","(Epoch 26), time: 5.8s, loss: 0.770\n","    Training Set - accuracy: 0.72, precision: 0.49, recall: 0.58, f1-score: 0.53,\n","    Validation Set - accuracy: 0.57, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","(Epoch 27), time: 5.8s, loss: 0.756\n","    Training Set - accuracy: 0.70, precision: 0.46, recall: 0.56, f1-score: 0.51,\n","    Validation Set - accuracy: 0.53, precision: 0.31, recall: 0.33, f1-score: 0.31,\n","(Epoch 28), time: 5.8s, loss: 0.729\n","    Training Set - accuracy: 0.72, precision: 0.49, recall: 0.58, f1-score: 0.53,\n","    Validation Set - accuracy: 0.57, precision: 0.32, recall: 0.35, f1-score: 0.33,\n","(Epoch 29), time: 5.8s, loss: 0.702\n","    Training Set - accuracy: 0.76, precision: 0.80, recall: 0.66, f1-score: 0.67,\n","    Validation Set - accuracy: 0.55, precision: 0.35, recall: 0.39, f1-score: 0.35,\n","(Epoch 30), time: 5.8s, loss: 0.686\n","    Training Set - accuracy: 0.81, precision: 0.80, recall: 0.75, f1-score: 0.76,\n","    Validation Set - accuracy: 0.57, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","(Epoch 31), time: 5.8s, loss: 0.660\n","    Training Set - accuracy: 0.79, precision: 0.82, recall: 0.72, f1-score: 0.73,\n","    Validation Set - accuracy: 0.55, precision: 0.33, recall: 0.36, f1-score: 0.34,\n","(Epoch 32), time: 5.8s, loss: 0.646\n","    Training Set - accuracy: 0.84, precision: 0.84, recall: 0.80, f1-score: 0.82,\n","    Validation Set - accuracy: 0.53, precision: 0.36, recall: 0.40, f1-score: 0.35,\n","(Epoch 33), time: 5.8s, loss: 0.628\n","    Training Set - accuracy: 0.83, precision: 0.84, recall: 0.80, f1-score: 0.82,\n","    Validation Set - accuracy: 0.62, precision: 0.39, recall: 0.45, f1-score: 0.40,\n","(Epoch 34), time: 5.8s, loss: 0.613\n","    Training Set - accuracy: 0.86, precision: 0.87, recall: 0.83, f1-score: 0.85,\n","    Validation Set - accuracy: 0.53, precision: 0.37, recall: 0.38, f1-score: 0.35,\n","(Epoch 35), time: 5.8s, loss: 0.587\n","    Training Set - accuracy: 0.88, precision: 0.87, recall: 0.86, f1-score: 0.86,\n","    Validation Set - accuracy: 0.55, precision: 0.38, recall: 0.41, f1-score: 0.36,\n","(Epoch 36), time: 5.8s, loss: 0.575\n","    Training Set - accuracy: 0.88, precision: 0.89, recall: 0.87, f1-score: 0.88,\n","    Validation Set - accuracy: 0.53, precision: 0.39, recall: 0.40, f1-score: 0.36,\n","(Epoch 37), time: 5.8s, loss: 0.599\n","    Training Set - accuracy: 0.84, precision: 0.81, recall: 0.82, f1-score: 0.82,\n","    Validation Set - accuracy: 0.53, precision: 0.38, recall: 0.38, f1-score: 0.36,\n","(Epoch 38), time: 5.8s, loss: 0.624\n","    Training Set - accuracy: 0.86, precision: 0.83, recall: 0.86, f1-score: 0.84,\n","    Validation Set - accuracy: 0.62, precision: 0.38, recall: 0.42, f1-score: 0.39,\n","(Epoch 39), time: 5.8s, loss: 0.577\n","    Training Set - accuracy: 0.86, precision: 0.86, recall: 0.86, f1-score: 0.86,\n","    Validation Set - accuracy: 0.65, precision: 0.39, recall: 0.44, f1-score: 0.40,\n","(Epoch 40), time: 5.8s, loss: 0.585\n","    Training Set - accuracy: 0.88, precision: 0.86, recall: 0.88, f1-score: 0.87,\n","    Validation Set - accuracy: 0.55, precision: 0.36, recall: 0.39, f1-score: 0.35,\n","(Epoch 41), time: 5.8s, loss: 0.518\n","    Training Set - accuracy: 0.89, precision: 0.90, recall: 0.89, f1-score: 0.89,\n","    Validation Set - accuracy: 0.50, precision: 0.34, recall: 0.34, f1-score: 0.32,\n","(Epoch 42), time: 5.8s, loss: 0.510\n","    Training Set - accuracy: 0.92, precision: 0.90, recall: 0.93, f1-score: 0.91,\n","    Validation Set - accuracy: 0.57, precision: 0.38, recall: 0.42, f1-score: 0.38,\n","(Epoch 43), time: 5.8s, loss: 0.484\n","    Training Set - accuracy: 0.91, precision: 0.90, recall: 0.93, f1-score: 0.91,\n","Confusion Matrix:\n","[[18 10  0]\n"," [ 2  7  0]\n"," [ 1  2  0]]\n","    Validation Set - accuracy: 0.62, precision: 0.41, recall: 0.47, f1-score: 0.41,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3 (val 85 - 126)\n","(Epoch 0), time: 5.8s, loss: 1.149\n","    Training Set - accuracy: 0.13, precision: 0.04, recall: 0.33, f1-score: 0.08,\n","    Validation Set - accuracy: 0.25, precision: 0.41, recall: 0.35, f1-score: 0.16,\n","(Epoch 1), time: 5.8s, loss: 1.134\n","    Training Set - accuracy: 0.18, precision: 0.18, recall: 0.39, f1-score: 0.17,\n","    Validation Set - accuracy: 0.28, precision: 0.22, recall: 0.36, f1-score: 0.21,\n","(Epoch 2), time: 5.8s, loss: 1.133\n","    Training Set - accuracy: 0.14, precision: 0.11, recall: 0.31, f1-score: 0.13,\n","    Validation Set - accuracy: 0.23, precision: 0.20, recall: 0.30, f1-score: 0.17,\n","(Epoch 3), time: 5.8s, loss: 1.124\n","    Training Set - accuracy: 0.15, precision: 0.11, recall: 0.28, f1-score: 0.14,\n","    Validation Set - accuracy: 0.30, precision: 0.20, recall: 0.31, f1-score: 0.24,\n","(Epoch 4), time: 5.9s, loss: 1.116\n","    Training Set - accuracy: 0.29, precision: 0.17, recall: 0.38, f1-score: 0.22,\n","    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.35, f1-score: 0.24,\n","(Epoch 5), time: 6.0s, loss: 1.099\n","    Training Set - accuracy: 0.28, precision: 0.37, recall: 0.33, f1-score: 0.18,\n","    Validation Set - accuracy: 0.40, precision: 0.25, recall: 0.33, f1-score: 0.23,\n","(Epoch 6), time: 6.0s, loss: 1.080\n","    Training Set - accuracy: 0.37, precision: 0.34, recall: 0.36, f1-score: 0.26,\n","    Validation Set - accuracy: 0.47, precision: 0.35, recall: 0.40, f1-score: 0.34,\n","(Epoch 7), time: 6.0s, loss: 1.100\n","    Training Set - accuracy: 0.42, precision: 0.25, recall: 0.28, f1-score: 0.26,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.37, f1-score: 0.31,\n","(Epoch 8), time: 6.0s, loss: 1.056\n","    Training Set - accuracy: 0.57, precision: 0.32, recall: 0.37, f1-score: 0.34,\n","    Validation Set - accuracy: 0.40, precision: 0.26, recall: 0.35, f1-score: 0.30,\n","(Epoch 9), time: 6.0s, loss: 1.040\n","    Training Set - accuracy: 0.55, precision: 0.32, recall: 0.37, f1-score: 0.34,\n","    Validation Set - accuracy: 0.42, precision: 0.29, recall: 0.37, f1-score: 0.32,\n","(Epoch 10), time: 6.0s, loss: 1.048\n","    Training Set - accuracy: 0.57, precision: 0.69, recall: 0.42, f1-score: 0.41,\n","    Validation Set - accuracy: 0.28, precision: 0.20, recall: 0.24, f1-score: 0.22,\n","(Epoch 11), time: 6.0s, loss: 1.021\n","    Training Set - accuracy: 0.64, precision: 0.73, recall: 0.49, f1-score: 0.48,\n","    Validation Set - accuracy: 0.42, precision: 0.38, recall: 0.38, f1-score: 0.37,\n","(Epoch 12), time: 6.0s, loss: 1.010\n","    Training Set - accuracy: 0.58, precision: 0.67, recall: 0.40, f1-score: 0.39,\n","    Validation Set - accuracy: 0.38, precision: 0.27, recall: 0.33, f1-score: 0.28,\n","(Epoch 13), time: 6.0s, loss: 0.972\n","    Training Set - accuracy: 0.61, precision: 0.53, recall: 0.43, f1-score: 0.42,\n","    Validation Set - accuracy: 0.47, precision: 0.42, recall: 0.43, f1-score: 0.41,\n","(Epoch 14), time: 6.0s, loss: 0.964\n","    Training Set - accuracy: 0.65, precision: 0.62, recall: 0.50, f1-score: 0.52,\n","    Validation Set - accuracy: 0.38, precision: 0.32, recall: 0.34, f1-score: 0.32,\n","(Epoch 15), time: 6.0s, loss: 0.931\n","    Training Set - accuracy: 0.68, precision: 0.67, recall: 0.56, f1-score: 0.59,\n","    Validation Set - accuracy: 0.33, precision: 0.28, recall: 0.30, f1-score: 0.29,\n","(Epoch 16), time: 6.0s, loss: 0.914\n","    Training Set - accuracy: 0.64, precision: 0.61, recall: 0.53, f1-score: 0.56,\n","    Validation Set - accuracy: 0.40, precision: 0.35, recall: 0.36, f1-score: 0.34,\n","(Epoch 17), time: 6.0s, loss: 0.887\n","    Training Set - accuracy: 0.70, precision: 0.69, recall: 0.59, f1-score: 0.62,\n","    Validation Set - accuracy: 0.40, precision: 0.35, recall: 0.38, f1-score: 0.33,\n","(Epoch 18), time: 6.0s, loss: 0.868\n","    Training Set - accuracy: 0.73, precision: 0.73, recall: 0.68, f1-score: 0.69,\n","    Validation Set - accuracy: 0.45, precision: 0.43, recall: 0.41, f1-score: 0.36,\n","(Epoch 19), time: 6.0s, loss: 0.837\n","    Training Set - accuracy: 0.76, precision: 0.72, recall: 0.71, f1-score: 0.70,\n","    Validation Set - accuracy: 0.45, precision: 0.47, recall: 0.44, f1-score: 0.43,\n","(Epoch 20), time: 6.0s, loss: 0.833\n","    Training Set - accuracy: 0.68, precision: 0.56, recall: 0.65, f1-score: 0.54,\n","    Validation Set - accuracy: 0.42, precision: 0.37, recall: 0.44, f1-score: 0.37,\n","(Epoch 21), time: 5.8s, loss: 0.810\n","    Training Set - accuracy: 0.76, precision: 0.72, recall: 0.70, f1-score: 0.69,\n","    Validation Set - accuracy: 0.33, precision: 0.29, recall: 0.33, f1-score: 0.29,\n","(Epoch 22), time: 5.8s, loss: 0.799\n","    Training Set - accuracy: 0.73, precision: 0.67, recall: 0.69, f1-score: 0.64,\n","    Validation Set - accuracy: 0.35, precision: 0.32, recall: 0.34, f1-score: 0.32,\n","(Epoch 23), time: 5.8s, loss: 0.781\n","    Training Set - accuracy: 0.76, precision: 0.74, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.35, precision: 0.37, recall: 0.35, f1-score: 0.35,\n","(Epoch 24), time: 5.8s, loss: 0.762\n","    Training Set - accuracy: 0.78, precision: 0.77, recall: 0.74, f1-score: 0.70,\n","    Validation Set - accuracy: 0.38, precision: 0.30, recall: 0.35, f1-score: 0.27,\n","(Epoch 25), time: 5.8s, loss: 0.752\n","    Training Set - accuracy: 0.76, precision: 0.73, recall: 0.73, f1-score: 0.66,\n","    Validation Set - accuracy: 0.35, precision: 0.32, recall: 0.34, f1-score: 0.29,\n","(Epoch 26), time: 5.9s, loss: 0.736\n","    Training Set - accuracy: 0.76, precision: 0.71, recall: 0.74, f1-score: 0.69,\n","    Validation Set - accuracy: 0.35, precision: 0.30, recall: 0.32, f1-score: 0.29,\n","(Epoch 27), time: 5.9s, loss: 0.732\n","    Training Set - accuracy: 0.77, precision: 0.72, recall: 0.73, f1-score: 0.67,\n","    Validation Set - accuracy: 0.38, precision: 0.34, recall: 0.34, f1-score: 0.33,\n","(Epoch 28), time: 5.8s, loss: 0.694\n","    Training Set - accuracy: 0.81, precision: 0.84, recall: 0.78, f1-score: 0.77,\n","    Validation Set - accuracy: 0.40, precision: 0.42, recall: 0.36, f1-score: 0.34,\n","(Epoch 29), time: 5.8s, loss: 0.691\n","    Training Set - accuracy: 0.84, precision: 0.87, recall: 0.80, f1-score: 0.82,\n","    Validation Set - accuracy: 0.35, precision: 0.33, recall: 0.34, f1-score: 0.31,\n","(Epoch 30), time: 5.8s, loss: 0.664\n","    Training Set - accuracy: 0.82, precision: 0.81, recall: 0.80, f1-score: 0.78,\n","    Validation Set - accuracy: 0.42, precision: 0.41, recall: 0.39, f1-score: 0.35,\n","(Epoch 31), time: 5.8s, loss: 0.612\n","    Training Set - accuracy: 0.85, precision: 0.83, recall: 0.84, f1-score: 0.83,\n","    Validation Set - accuracy: 0.38, precision: 0.34, recall: 0.34, f1-score: 0.31,\n","(Epoch 32), time: 6.0s, loss: 0.582\n","    Training Set - accuracy: 0.86, precision: 0.84, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.35, precision: 0.26, recall: 0.30, f1-score: 0.27,\n","(Epoch 33), time: 6.0s, loss: 0.564\n","    Training Set - accuracy: 0.85, precision: 0.81, recall: 0.84, f1-score: 0.81,\n","    Validation Set - accuracy: 0.38, precision: 0.28, recall: 0.33, f1-score: 0.26,\n","(Epoch 34), time: 6.0s, loss: 0.543\n","    Training Set - accuracy: 0.86, precision: 0.85, recall: 0.83, f1-score: 0.82,\n","    Validation Set - accuracy: 0.33, precision: 0.22, recall: 0.28, f1-score: 0.24,\n","(Epoch 35), time: 6.0s, loss: 0.520\n","    Training Set - accuracy: 0.89, precision: 0.89, recall: 0.87, f1-score: 0.86,\n","    Validation Set - accuracy: 0.42, precision: 0.33, recall: 0.37, f1-score: 0.33,\n","(Epoch 36), time: 6.0s, loss: 0.503\n","    Training Set - accuracy: 0.89, precision: 0.89, recall: 0.87, f1-score: 0.87,\n","    Validation Set - accuracy: 0.45, precision: 0.41, recall: 0.41, f1-score: 0.38,\n","(Epoch 37), time: 6.0s, loss: 0.471\n","    Training Set - accuracy: 0.90, precision: 0.93, recall: 0.88, f1-score: 0.90,\n","Confusion Matrix:\n","[[13  1  1]\n"," [10  4  2]\n"," [ 7  2  0]]\n","    Validation Set - accuracy: 0.42, precision: 0.33, recall: 0.37, f1-score: 0.31,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4 (val 127 - 168)\n","(Epoch 0), time: 6.0s, loss: 1.106\n","    Training Set - accuracy: 0.31, precision: 0.43, recall: 0.34, f1-score: 0.16,\n","    Validation Set - accuracy: 0.28, precision: 0.10, recall: 0.31, f1-score: 0.15,\n","(Epoch 1), time: 6.0s, loss: 1.103\n","    Training Set - accuracy: 0.31, precision: 0.21, recall: 0.32, f1-score: 0.18,\n","    Validation Set - accuracy: 0.33, precision: 0.24, recall: 0.34, f1-score: 0.21,\n","(Epoch 2), time: 6.0s, loss: 1.099\n","    Training Set - accuracy: 0.33, precision: 0.29, recall: 0.33, f1-score: 0.21,\n","    Validation Set - accuracy: 0.38, precision: 0.36, recall: 0.39, f1-score: 0.26,\n","(Epoch 3), time: 6.0s, loss: 1.098\n","    Training Set - accuracy: 0.36, precision: 0.32, recall: 0.36, f1-score: 0.24,\n","    Validation Set - accuracy: 0.33, precision: 0.22, recall: 0.34, f1-score: 0.21,\n","(Epoch 4), time: 6.0s, loss: 1.090\n","    Training Set - accuracy: 0.36, precision: 0.32, recall: 0.35, f1-score: 0.25,\n","    Validation Set - accuracy: 0.38, precision: 0.29, recall: 0.36, f1-score: 0.28,\n","(Epoch 5), time: 6.0s, loss: 1.089\n","    Training Set - accuracy: 0.33, precision: 0.27, recall: 0.30, f1-score: 0.23,\n","    Validation Set - accuracy: 0.45, precision: 0.38, recall: 0.44, f1-score: 0.34,\n","(Epoch 6), time: 6.0s, loss: 1.080\n","    Training Set - accuracy: 0.47, precision: 0.31, recall: 0.35, f1-score: 0.32,\n","    Validation Set - accuracy: 0.40, precision: 0.22, recall: 0.31, f1-score: 0.25,\n","(Epoch 7), time: 6.0s, loss: 1.078\n","    Training Set - accuracy: 0.55, precision: 0.27, recall: 0.33, f1-score: 0.27,\n","    Validation Set - accuracy: 0.42, precision: 0.15, recall: 0.31, f1-score: 0.20,\n","(Epoch 8), time: 6.0s, loss: 1.060\n","    Training Set - accuracy: 0.56, precision: 0.25, recall: 0.33, f1-score: 0.25,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 9), time: 6.0s, loss: 1.037\n","    Training Set - accuracy: 0.57, precision: 0.19, recall: 0.33, f1-score: 0.24,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 10), time: 6.0s, loss: 1.016\n","    Training Set - accuracy: 0.60, precision: 0.41, recall: 0.44, f1-score: 0.39,\n","    Validation Set - accuracy: 0.45, precision: 0.22, recall: 0.35, f1-score: 0.26,\n","(Epoch 11), time: 6.0s, loss: 1.010\n","    Training Set - accuracy: 0.56, precision: 0.45, recall: 0.37, f1-score: 0.33,\n","    Validation Set - accuracy: 0.45, precision: 0.15, recall: 0.33, f1-score: 0.21,\n","(Epoch 12), time: 6.0s, loss: 0.981\n","    Training Set - accuracy: 0.59, precision: 0.33, recall: 0.46, f1-score: 0.39,\n","    Validation Set - accuracy: 0.45, precision: 0.25, recall: 0.36, f1-score: 0.29,\n","(Epoch 13), time: 6.0s, loss: 0.953\n","    Training Set - accuracy: 0.59, precision: 0.35, recall: 0.51, f1-score: 0.42,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.35, f1-score: 0.26,\n","(Epoch 14), time: 6.0s, loss: 0.920\n","    Training Set - accuracy: 0.62, precision: 0.37, recall: 0.57, f1-score: 0.44,\n","    Validation Set - accuracy: 0.42, precision: 0.24, recall: 0.34, f1-score: 0.27,\n","(Epoch 15), time: 6.0s, loss: 0.895\n","    Training Set - accuracy: 0.62, precision: 0.71, recall: 0.58, f1-score: 0.46,\n","    Validation Set - accuracy: 0.47, precision: 0.27, recall: 0.38, f1-score: 0.30,\n","(Epoch 16), time: 6.0s, loss: 0.849\n","    Training Set - accuracy: 0.64, precision: 0.40, recall: 0.61, f1-score: 0.48,\n","    Validation Set - accuracy: 0.50, precision: 0.30, recall: 0.41, f1-score: 0.34,\n","(Epoch 17), time: 6.0s, loss: 0.807\n","    Training Set - accuracy: 0.66, precision: 0.42, recall: 0.62, f1-score: 0.50,\n","    Validation Set - accuracy: 0.55, precision: 0.35, recall: 0.50, f1-score: 0.41,\n","(Epoch 18), time: 5.8s, loss: 0.772\n","    Training Set - accuracy: 0.67, precision: 0.45, recall: 0.60, f1-score: 0.51,\n","    Validation Set - accuracy: 0.53, precision: 0.35, recall: 0.51, f1-score: 0.41,\n","(Epoch 19), time: 5.8s, loss: 0.848\n","    Training Set - accuracy: 0.59, precision: 0.35, recall: 0.55, f1-score: 0.42,\n","    Validation Set - accuracy: 0.45, precision: 0.48, recall: 0.34, f1-score: 0.25,\n","(Epoch 20), time: 5.8s, loss: 0.761\n","    Training Set - accuracy: 0.64, precision: 0.63, recall: 0.63, f1-score: 0.50,\n","    Validation Set - accuracy: 0.42, precision: 0.26, recall: 0.34, f1-score: 0.29,\n","(Epoch 21), time: 5.8s, loss: 0.693\n","    Training Set - accuracy: 0.69, precision: 0.71, recall: 0.65, f1-score: 0.60,\n","    Validation Set - accuracy: 0.47, precision: 0.42, recall: 0.38, f1-score: 0.31,\n","(Epoch 22), time: 5.8s, loss: 0.654\n","    Training Set - accuracy: 0.68, precision: 0.68, recall: 0.65, f1-score: 0.56,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.35, f1-score: 0.26,\n","(Epoch 23), time: 5.8s, loss: 0.616\n","    Training Set - accuracy: 0.71, precision: 0.84, recall: 0.67, f1-score: 0.60,\n","    Validation Set - accuracy: 0.47, precision: 0.42, recall: 0.38, f1-score: 0.31,\n","(Epoch 24), time: 5.8s, loss: 0.599\n","    Training Set - accuracy: 0.71, precision: 0.85, recall: 0.67, f1-score: 0.61,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.35, f1-score: 0.26,\n","(Epoch 25), time: 5.8s, loss: 0.573\n","    Training Set - accuracy: 0.70, precision: 0.73, recall: 0.67, f1-score: 0.63,\n","    Validation Set - accuracy: 0.50, precision: 0.42, recall: 0.40, f1-score: 0.36,\n","(Epoch 26), time: 5.8s, loss: 0.568\n","    Training Set - accuracy: 0.73, precision: 0.81, recall: 0.70, f1-score: 0.68,\n","    Validation Set - accuracy: 0.50, precision: 0.40, recall: 0.39, f1-score: 0.33,\n","(Epoch 27), time: 5.8s, loss: 0.548\n","    Training Set - accuracy: 0.74, precision: 0.84, recall: 0.70, f1-score: 0.67,\n","    Validation Set - accuracy: 0.50, precision: 0.36, recall: 0.40, f1-score: 0.36,\n","(Epoch 28), time: 5.8s, loss: 0.537\n","    Training Set - accuracy: 0.75, precision: 0.82, recall: 0.73, f1-score: 0.73,\n","    Validation Set - accuracy: 0.57, precision: 0.55, recall: 0.49, f1-score: 0.46,\n","(Epoch 29), time: 5.8s, loss: 0.528\n","    Training Set - accuracy: 0.76, precision: 0.83, recall: 0.73, f1-score: 0.73,\n","    Validation Set - accuracy: 0.55, precision: 0.48, recall: 0.48, f1-score: 0.47,\n","(Epoch 30), time: 5.8s, loss: 0.520\n","    Training Set - accuracy: 0.76, precision: 0.76, recall: 0.77, f1-score: 0.76,\n","    Validation Set - accuracy: 0.53, precision: 0.49, recall: 0.44, f1-score: 0.41,\n","(Epoch 31), time: 5.8s, loss: 0.504\n","    Training Set - accuracy: 0.81, precision: 0.87, recall: 0.79, f1-score: 0.81,\n","    Validation Set - accuracy: 0.50, precision: 0.42, recall: 0.43, f1-score: 0.41,\n","(Epoch 32), time: 5.8s, loss: 0.511\n","    Training Set - accuracy: 0.76, precision: 0.77, recall: 0.77, f1-score: 0.77,\n","    Validation Set - accuracy: 0.57, precision: 0.53, recall: 0.48, f1-score: 0.44,\n","(Epoch 33), time: 5.8s, loss: 0.480\n","    Training Set - accuracy: 0.81, precision: 0.85, recall: 0.81, f1-score: 0.82,\n","Confusion Matrix:\n","[[14  4  0]\n"," [ 5  5  2]\n"," [ 2  7  1]]\n","    Validation Set - accuracy: 0.50, precision: 0.44, recall: 0.43, f1-score: 0.41,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5 (val 169 - 210)\n","(Epoch 0), time: 6.0s, loss: 1.122\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 1), time: 6.0s, loss: 1.120\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 2), time: 6.0s, loss: 1.118\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 3), time: 6.0s, loss: 1.117\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 4), time: 5.9s, loss: 1.117\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 5), time: 6.0s, loss: 1.118\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 6), time: 5.9s, loss: 1.117\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 7), time: 5.9s, loss: 1.117\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 8), time: 6.0s, loss: 1.117\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 9), time: 6.0s, loss: 1.116\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 10), time: 6.0s, loss: 1.116\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 11), time: 6.0s, loss: 1.116\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 12), time: 6.0s, loss: 1.116\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 13), time: 5.9s, loss: 1.115\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 14), time: 5.8s, loss: 1.113\n","    Training Set - accuracy: 0.15, precision: 0.05, recall: 0.33, f1-score: 0.09,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 15), time: 5.8s, loss: 1.109\n","    Training Set - accuracy: 0.16, precision: 0.38, recall: 0.34, f1-score: 0.10,\n","    Validation Set - accuracy: 0.20, precision: 0.39, recall: 0.36, f1-score: 0.15,\n","(Epoch 16), time: 5.8s, loss: 1.104\n","    Training Set - accuracy: 0.17, precision: 0.27, recall: 0.35, f1-score: 0.12,\n","    Validation Set - accuracy: 0.17, precision: 0.06, recall: 0.33, f1-score: 0.10,\n","(Epoch 17), time: 5.8s, loss: 1.085\n","    Training Set - accuracy: 0.43, precision: 0.31, recall: 0.46, f1-score: 0.32,\n","    Validation Set - accuracy: 0.30, precision: 0.35, recall: 0.45, f1-score: 0.28,\n","(Epoch 18), time: 5.8s, loss: 1.069\n","    Training Set - accuracy: 0.56, precision: 0.33, recall: 0.47, f1-score: 0.38,\n","    Validation Set - accuracy: 0.33, precision: 0.21, recall: 0.43, f1-score: 0.28,\n","(Epoch 19), time: 5.8s, loss: 1.023\n","    Training Set - accuracy: 0.58, precision: 0.36, recall: 0.54, f1-score: 0.41,\n","    Validation Set - accuracy: 0.33, precision: 0.30, recall: 0.48, f1-score: 0.30,\n","(Epoch 20), time: 5.8s, loss: 1.009\n","    Training Set - accuracy: 0.64, precision: 0.38, recall: 0.53, f1-score: 0.45,\n","    Validation Set - accuracy: 0.33, precision: 0.22, recall: 0.43, f1-score: 0.28,\n","(Epoch 21), time: 5.8s, loss: 0.976\n","    Training Set - accuracy: 0.66, precision: 0.39, recall: 0.57, f1-score: 0.46,\n","    Validation Set - accuracy: 0.42, precision: 0.28, recall: 0.55, f1-score: 0.36,\n","(Epoch 22), time: 5.8s, loss: 0.938\n","    Training Set - accuracy: 0.66, precision: 0.73, recall: 0.59, f1-score: 0.48,\n","    Validation Set - accuracy: 0.33, precision: 0.24, recall: 0.45, f1-score: 0.29,\n","(Epoch 23), time: 5.8s, loss: 0.914\n","    Training Set - accuracy: 0.68, precision: 0.74, recall: 0.59, f1-score: 0.50,\n","    Validation Set - accuracy: 0.38, precision: 0.42, recall: 0.49, f1-score: 0.35,\n","(Epoch 24), time: 5.8s, loss: 0.877\n","    Training Set - accuracy: 0.71, precision: 0.76, recall: 0.64, f1-score: 0.54,\n","    Validation Set - accuracy: 0.35, precision: 0.23, recall: 0.43, f1-score: 0.30,\n","(Epoch 25), time: 5.8s, loss: 0.828\n","    Training Set - accuracy: 0.76, precision: 0.75, recall: 0.69, f1-score: 0.63,\n","    Validation Set - accuracy: 0.40, precision: 0.59, recall: 0.49, f1-score: 0.37,\n","(Epoch 26), time: 5.8s, loss: 0.793\n","    Training Set - accuracy: 0.78, precision: 0.80, recall: 0.72, f1-score: 0.66,\n","    Validation Set - accuracy: 0.45, precision: 0.50, recall: 0.52, f1-score: 0.45,\n","(Epoch 27), time: 5.8s, loss: 0.753\n","    Training Set - accuracy: 0.79, precision: 0.73, recall: 0.74, f1-score: 0.70,\n","    Validation Set - accuracy: 0.42, precision: 0.45, recall: 0.49, f1-score: 0.43,\n","(Epoch 28), time: 5.8s, loss: 0.730\n","    Training Set - accuracy: 0.82, precision: 0.80, recall: 0.77, f1-score: 0.73,\n","    Validation Set - accuracy: 0.40, precision: 0.41, recall: 0.45, f1-score: 0.40,\n","(Epoch 29), time: 5.8s, loss: 0.698\n","    Training Set - accuracy: 0.85, precision: 0.84, recall: 0.81, f1-score: 0.79,\n","    Validation Set - accuracy: 0.53, precision: 0.54, recall: 0.58, f1-score: 0.53,\n","(Epoch 30), time: 5.8s, loss: 0.655\n","    Training Set - accuracy: 0.87, precision: 0.83, recall: 0.83, f1-score: 0.81,\n","    Validation Set - accuracy: 0.45, precision: 0.45, recall: 0.48, f1-score: 0.45,\n","(Epoch 31), time: 5.8s, loss: 0.614\n","    Training Set - accuracy: 0.88, precision: 0.84, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.38, precision: 0.45, recall: 0.39, f1-score: 0.33,\n","(Epoch 32), time: 5.8s, loss: 0.596\n","    Training Set - accuracy: 0.89, precision: 0.85, recall: 0.87, f1-score: 0.85,\n","    Validation Set - accuracy: 0.40, precision: 0.42, recall: 0.43, f1-score: 0.39,\n","(Epoch 33), time: 5.8s, loss: 0.573\n","    Training Set - accuracy: 0.91, precision: 0.89, recall: 0.88, f1-score: 0.87,\n","    Validation Set - accuracy: 0.38, precision: 0.36, recall: 0.37, f1-score: 0.36,\n","(Epoch 34), time: 5.8s, loss: 0.570\n","    Training Set - accuracy: 0.88, precision: 0.85, recall: 0.86, f1-score: 0.83,\n","    Validation Set - accuracy: 0.35, precision: 0.32, recall: 0.34, f1-score: 0.28,\n","(Epoch 35), time: 5.8s, loss: 0.539\n","    Training Set - accuracy: 0.90, precision: 0.87, recall: 0.88, f1-score: 0.86,\n","    Validation Set - accuracy: 0.38, precision: 0.45, recall: 0.39, f1-score: 0.33,\n","(Epoch 36), time: 6.0s, loss: 0.500\n","    Training Set - accuracy: 0.92, precision: 0.90, recall: 0.89, f1-score: 0.88,\n","    Validation Set - accuracy: 0.45, precision: 0.45, recall: 0.43, f1-score: 0.43,\n","(Epoch 37), time: 6.0s, loss: 0.513\n","    Training Set - accuracy: 0.89, precision: 0.84, recall: 0.86, f1-score: 0.85,\n","    Validation Set - accuracy: 0.40, precision: 0.46, recall: 0.47, f1-score: 0.40,\n","(Epoch 38), time: 6.0s, loss: 0.490\n","    Training Set - accuracy: 0.92, precision: 0.91, recall: 0.90, f1-score: 0.89,\n","Confusion Matrix:\n","[[ 6  4  4]\n"," [ 3  6 10]\n"," [ 1  1  5]]\n","    Validation Set - accuracy: 0.42, precision: 0.47, recall: 0.49, f1-score: 0.43,\n"]}],"source":["from dataset import YouTubeDataset\n","from models.single_modality_classifiers import RobertaClassifier\n","splits = [10,20]\n","num_classes = len(splits)+1\n","dataset = YouTubeDataset(splits)\n","model = RobertaClassifier(num_classes)\n","\n","hist = train_model_cv5(model, dataset)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495818,"status":"ok","timestamp":1661801454322,"user":{"displayName":"Muzhe Wu","userId":"01183471528445165597"},"user_tz":240},"id":"sraz31H1wSih","outputId":"07438c30-fe24-4c7e-fcd0-ac82b9dd9ac4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Initialization success if you see a tensor: tensor([[0.0514, 0.0068]], grad_fn=<AddmmBackward0>).\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 1 (val 0 - 42)\n","(Epoch 0), time: 5.8s, loss: 0.704\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 1), time: 5.8s, loss: 0.695\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 2), time: 5.9s, loss: 0.695\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 3), time: 5.9s, loss: 0.697\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 4), time: 5.9s, loss: 0.696\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 5), time: 5.9s, loss: 0.695\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 6), time: 5.9s, loss: 0.694\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 7), time: 5.9s, loss: 0.693\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 8), time: 5.9s, loss: 0.691\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 9), time: 6.0s, loss: 0.690\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 10), time: 6.0s, loss: 0.685\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 11), time: 6.0s, loss: 0.684\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 12), time: 6.0s, loss: 0.682\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 13), time: 5.9s, loss: 0.672\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 14), time: 6.0s, loss: 0.663\n","    Training Set - accuracy: 0.53, precision: 0.27, recall: 0.50, f1-score: 0.35,\n","    Validation Set - accuracy: 0.17, precision: 0.09, recall: 0.50, f1-score: 0.15,\n","(Epoch 15), time: 6.0s, loss: 0.640\n","    Training Set - accuracy: 0.60, precision: 0.70, recall: 0.58, f1-score: 0.51,\n","    Validation Set - accuracy: 0.38, precision: 0.55, recall: 0.56, f1-score: 0.37,\n","(Epoch 16), time: 6.0s, loss: 0.607\n","    Training Set - accuracy: 0.76, precision: 0.81, recall: 0.74, f1-score: 0.74,\n","    Validation Set - accuracy: 0.40, precision: 0.52, recall: 0.52, f1-score: 0.39,\n","(Epoch 17), time: 6.0s, loss: 0.575\n","    Training Set - accuracy: 0.75, precision: 0.77, recall: 0.74, f1-score: 0.74,\n","    Validation Set - accuracy: 0.53, precision: 0.56, recall: 0.60, f1-score: 0.49,\n","(Epoch 18), time: 6.0s, loss: 0.508\n","    Training Set - accuracy: 0.82, precision: 0.84, recall: 0.81, f1-score: 0.81,\n","    Validation Set - accuracy: 0.65, precision: 0.57, recall: 0.62, f1-score: 0.56,\n","(Epoch 19), time: 6.0s, loss: 0.449\n","    Training Set - accuracy: 0.87, precision: 0.88, recall: 0.86, f1-score: 0.87,\n","Confusion Matrix:\n","[[22 11]\n"," [ 3  4]]\n","    Validation Set - accuracy: 0.65, precision: 0.57, recall: 0.62, f1-score: 0.56,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2 (val 43 - 84)\n","(Epoch 0), time: 5.9s, loss: 0.712\n","    Training Set - accuracy: 0.49, precision: 0.24, recall: 0.50, f1-score: 0.33,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.50, f1-score: 0.23,\n","(Epoch 1), time: 5.7s, loss: 0.709\n","    Training Set - accuracy: 0.49, precision: 0.24, recall: 0.50, f1-score: 0.33,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.50, f1-score: 0.23,\n","(Epoch 2), time: 5.8s, loss: 0.706\n","    Training Set - accuracy: 0.49, precision: 0.24, recall: 0.50, f1-score: 0.33,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.50, f1-score: 0.23,\n","(Epoch 3), time: 5.8s, loss: 0.704\n","    Training Set - accuracy: 0.49, precision: 0.24, recall: 0.50, f1-score: 0.33,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.50, f1-score: 0.23,\n","(Epoch 4), time: 5.8s, loss: 0.699\n","    Training Set - accuracy: 0.48, precision: 0.24, recall: 0.49, f1-score: 0.32,\n","    Validation Set - accuracy: 0.30, precision: 0.15, recall: 0.50, f1-score: 0.23,\n","(Epoch 5), time: 5.8s, loss: 0.688\n","    Training Set - accuracy: 0.52, precision: 0.64, recall: 0.53, f1-score: 0.41,\n","    Validation Set - accuracy: 0.45, precision: 0.61, recall: 0.58, f1-score: 0.44,\n","(Epoch 6), time: 5.8s, loss: 0.665\n","    Training Set - accuracy: 0.65, precision: 0.68, recall: 0.66, f1-score: 0.64,\n","    Validation Set - accuracy: 0.45, precision: 0.49, recall: 0.49, f1-score: 0.44,\n","(Epoch 7), time: 5.8s, loss: 0.652\n","    Training Set - accuracy: 0.67, precision: 0.67, recall: 0.67, f1-score: 0.67,\n","    Validation Set - accuracy: 0.45, precision: 0.51, recall: 0.51, f1-score: 0.45,\n","(Epoch 8), time: 5.8s, loss: 0.638\n","    Training Set - accuracy: 0.72, precision: 0.73, recall: 0.73, f1-score: 0.72,\n","    Validation Set - accuracy: 0.45, precision: 0.45, recall: 0.44, f1-score: 0.43,\n","(Epoch 9), time: 5.8s, loss: 0.619\n","    Training Set - accuracy: 0.75, precision: 0.75, recall: 0.75, f1-score: 0.75,\n","    Validation Set - accuracy: 0.42, precision: 0.49, recall: 0.49, f1-score: 0.42,\n","(Epoch 10), time: 5.8s, loss: 0.605\n","    Training Set - accuracy: 0.78, precision: 0.78, recall: 0.78, f1-score: 0.77,\n","    Validation Set - accuracy: 0.47, precision: 0.48, recall: 0.48, f1-score: 0.46,\n","(Epoch 11), time: 5.8s, loss: 0.586\n","    Training Set - accuracy: 0.78, precision: 0.79, recall: 0.78, f1-score: 0.78,\n","    Validation Set - accuracy: 0.57, precision: 0.61, recall: 0.62, f1-score: 0.57,\n","(Epoch 12), time: 5.8s, loss: 0.574\n","    Training Set - accuracy: 0.79, precision: 0.79, recall: 0.79, f1-score: 0.79,\n","    Validation Set - accuracy: 0.45, precision: 0.47, recall: 0.46, f1-score: 0.44,\n","(Epoch 13), time: 5.8s, loss: 0.562\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.81, f1-score: 0.81,\n","    Validation Set - accuracy: 0.50, precision: 0.54, recall: 0.55, f1-score: 0.49,\n","(Epoch 14), time: 5.8s, loss: 0.540\n","    Training Set - accuracy: 0.84, precision: 0.84, recall: 0.84, f1-score: 0.84,\n","    Validation Set - accuracy: 0.57, precision: 0.61, recall: 0.62, f1-score: 0.57,\n","(Epoch 15), time: 5.8s, loss: 0.505\n","    Training Set - accuracy: 0.86, precision: 0.87, recall: 0.86, f1-score: 0.86,\n","    Validation Set - accuracy: 0.55, precision: 0.53, recall: 0.54, f1-score: 0.52,\n","(Epoch 16), time: 5.8s, loss: 0.492\n","    Training Set - accuracy: 0.87, precision: 0.88, recall: 0.87, f1-score: 0.87,\n","Confusion Matrix:\n","[[14 14]\n"," [ 3  9]]\n","    Validation Set - accuracy: 0.57, precision: 0.61, recall: 0.62, f1-score: 0.57,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3 (val 85 - 126)\n","(Epoch 0), time: 6.0s, loss: 0.700\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 1), time: 6.0s, loss: 0.699\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 2), time: 6.0s, loss: 0.699\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 3), time: 6.0s, loss: 0.697\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 4), time: 6.0s, loss: 0.699\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 5), time: 6.0s, loss: 0.700\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 6), time: 6.0s, loss: 0.697\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 7), time: 6.0s, loss: 0.695\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 8), time: 6.0s, loss: 0.693\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 9), time: 6.0s, loss: 0.693\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 10), time: 6.0s, loss: 0.689\n","    Training Set - accuracy: 0.59, precision: 0.30, recall: 0.50, f1-score: 0.37,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 11), time: 6.0s, loss: 0.680\n","    Training Set - accuracy: 0.59, precision: 0.55, recall: 0.50, f1-score: 0.39,\n","    Validation Set - accuracy: 0.38, precision: 0.19, recall: 0.50, f1-score: 0.27,\n","(Epoch 12), time: 6.0s, loss: 0.667\n","    Training Set - accuracy: 0.63, precision: 0.62, recall: 0.57, f1-score: 0.55,\n","    Validation Set - accuracy: 0.65, precision: 0.63, recall: 0.63, f1-score: 0.63,\n","(Epoch 13), time: 6.0s, loss: 0.655\n","    Training Set - accuracy: 0.64, precision: 0.64, recall: 0.64, f1-score: 0.63,\n","    Validation Set - accuracy: 0.65, precision: 0.62, recall: 0.61, f1-score: 0.62,\n","(Epoch 14), time: 6.0s, loss: 0.635\n","    Training Set - accuracy: 0.67, precision: 0.67, recall: 0.67, f1-score: 0.66,\n","    Validation Set - accuracy: 0.65, precision: 0.62, recall: 0.60, f1-score: 0.60,\n","(Epoch 15), time: 6.0s, loss: 0.630\n","    Training Set - accuracy: 0.70, precision: 0.72, recall: 0.72, f1-score: 0.70,\n","    Validation Set - accuracy: 0.60, precision: 0.57, recall: 0.57, f1-score: 0.57,\n","(Epoch 16), time: 6.0s, loss: 0.598\n","    Training Set - accuracy: 0.76, precision: 0.75, recall: 0.76, f1-score: 0.75,\n","    Validation Set - accuracy: 0.62, precision: 0.58, recall: 0.55, f1-score: 0.54,\n","(Epoch 17), time: 6.0s, loss: 0.578\n","    Training Set - accuracy: 0.77, precision: 0.78, recall: 0.79, f1-score: 0.77,\n","    Validation Set - accuracy: 0.68, precision: 0.65, recall: 0.65, f1-score: 0.65,\n","(Epoch 18), time: 6.0s, loss: 0.551\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.82, f1-score: 0.81,\n","    Validation Set - accuracy: 0.60, precision: 0.55, recall: 0.55, f1-score: 0.54,\n","(Epoch 19), time: 6.0s, loss: 0.510\n","    Training Set - accuracy: 0.82, precision: 0.83, recall: 0.84, f1-score: 0.82,\n","    Validation Set - accuracy: 0.68, precision: 0.65, recall: 0.63, f1-score: 0.64,\n","(Epoch 20), time: 6.0s, loss: 0.475\n","    Training Set - accuracy: 0.86, precision: 0.86, recall: 0.87, f1-score: 0.85,\n","Confusion Matrix:\n","[[ 5 10]\n"," [ 6 19]]\n","    Validation Set - accuracy: 0.60, precision: 0.55, recall: 0.55, f1-score: 0.54,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4 (val 127 - 168)\n","(Epoch 0), time: 6.0s, loss: 0.705\n","    Training Set - accuracy: 0.42, precision: 0.21, recall: 0.49, f1-score: 0.30,\n","    Validation Set - accuracy: 0.55, precision: 0.28, recall: 0.50, f1-score: 0.35,\n","(Epoch 1), time: 6.0s, loss: 0.696\n","    Training Set - accuracy: 0.42, precision: 0.38, recall: 0.49, f1-score: 0.30,\n","    Validation Set - accuracy: 0.60, precision: 0.79, recall: 0.56, f1-score: 0.47,\n","(Epoch 2), time: 6.0s, loss: 0.695\n","    Training Set - accuracy: 0.42, precision: 0.46, recall: 0.49, f1-score: 0.35,\n","    Validation Set - accuracy: 0.55, precision: 0.53, recall: 0.51, f1-score: 0.40,\n","(Epoch 3), time: 6.0s, loss: 0.693\n","    Training Set - accuracy: 0.49, precision: 0.60, recall: 0.54, f1-score: 0.44,\n","    Validation Set - accuracy: 0.55, precision: 0.53, recall: 0.52, f1-score: 0.46,\n","(Epoch 4), time: 6.0s, loss: 0.693\n","    Training Set - accuracy: 0.58, precision: 0.60, recall: 0.60, f1-score: 0.58,\n","    Validation Set - accuracy: 0.53, precision: 0.52, recall: 0.52, f1-score: 0.52,\n","(Epoch 5), time: 6.0s, loss: 0.694\n","    Training Set - accuracy: 0.59, precision: 0.57, recall: 0.57, f1-score: 0.57,\n","    Validation Set - accuracy: 0.65, precision: 0.67, recall: 0.66, f1-score: 0.65,\n","(Epoch 6), time: 6.0s, loss: 0.689\n","    Training Set - accuracy: 0.64, precision: 0.64, recall: 0.61, f1-score: 0.61,\n","    Validation Set - accuracy: 0.53, precision: 0.56, recall: 0.55, f1-score: 0.51,\n","(Epoch 7), time: 6.0s, loss: 0.688\n","    Training Set - accuracy: 0.58, precision: 0.56, recall: 0.52, f1-score: 0.46,\n","    Validation Set - accuracy: 0.45, precision: 0.47, recall: 0.49, f1-score: 0.35,\n","(Epoch 8), time: 6.0s, loss: 0.683\n","    Training Set - accuracy: 0.58, precision: 0.59, recall: 0.51, f1-score: 0.41,\n","    Validation Set - accuracy: 0.45, precision: 0.23, recall: 0.50, f1-score: 0.31,\n","(Epoch 9), time: 6.0s, loss: 0.673\n","    Training Set - accuracy: 0.59, precision: 0.63, recall: 0.52, f1-score: 0.42,\n","    Validation Set - accuracy: 0.47, precision: 0.73, recall: 0.52, f1-score: 0.36,\n","(Epoch 10), time: 6.0s, loss: 0.664\n","    Training Set - accuracy: 0.62, precision: 0.70, recall: 0.56, f1-score: 0.51,\n","    Validation Set - accuracy: 0.53, precision: 0.64, recall: 0.56, f1-score: 0.47,\n","(Epoch 11), time: 6.0s, loss: 0.638\n","    Training Set - accuracy: 0.71, precision: 0.74, recall: 0.68, f1-score: 0.68,\n","    Validation Set - accuracy: 0.55, precision: 0.57, recall: 0.57, f1-score: 0.55,\n","(Epoch 12), time: 6.0s, loss: 0.614\n","    Training Set - accuracy: 0.71, precision: 0.72, recall: 0.68, f1-score: 0.68,\n","    Validation Set - accuracy: 0.53, precision: 0.56, recall: 0.55, f1-score: 0.51,\n","(Epoch 13), time: 6.0s, loss: 0.592\n","    Training Set - accuracy: 0.71, precision: 0.71, recall: 0.68, f1-score: 0.69,\n","    Validation Set - accuracy: 0.75, precision: 0.75, recall: 0.75, f1-score: 0.75,\n","(Epoch 14), time: 6.0s, loss: 0.560\n","    Training Set - accuracy: 0.74, precision: 0.74, recall: 0.73, f1-score: 0.74,\n","    Validation Set - accuracy: 0.65, precision: 0.65, recall: 0.64, f1-score: 0.64,\n","(Epoch 15), time: 6.0s, loss: 0.527\n","    Training Set - accuracy: 0.75, precision: 0.74, recall: 0.74, f1-score: 0.74,\n","    Validation Set - accuracy: 0.70, precision: 0.70, recall: 0.70, f1-score: 0.70,\n","(Epoch 16), time: 6.0s, loss: 0.507\n","    Training Set - accuracy: 0.82, precision: 0.82, recall: 0.82, f1-score: 0.82,\n","    Validation Set - accuracy: 0.65, precision: 0.65, recall: 0.65, f1-score: 0.65,\n","(Epoch 17), time: 6.0s, loss: 0.492\n","    Training Set - accuracy: 0.81, precision: 0.81, recall: 0.82, f1-score: 0.81,\n","Confusion Matrix:\n","[[12  6]\n"," [ 8 14]]\n","    Validation Set - accuracy: 0.65, precision: 0.65, recall: 0.65, f1-score: 0.65,\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5 (val 169 - 210)\n","(Epoch 0), time: 6.0s, loss: 0.715\n","    Training Set - accuracy: 0.40, precision: 0.20, recall: 0.50, f1-score: 0.29,\n","    Validation Set - accuracy: 0.65, precision: 0.33, recall: 0.50, f1-score: 0.39,\n","(Epoch 1), time: 6.0s, loss: 0.708\n","    Training Set - accuracy: 0.40, precision: 0.20, recall: 0.50, f1-score: 0.29,\n","    Validation Set - accuracy: 0.65, precision: 0.33, recall: 0.50, f1-score: 0.39,\n","(Epoch 2), time: 6.0s, loss: 0.704\n","    Training Set - accuracy: 0.41, precision: 0.70, recall: 0.51, f1-score: 0.30,\n","    Validation Set - accuracy: 0.65, precision: 0.33, recall: 0.50, f1-score: 0.39,\n","(Epoch 3), time: 6.0s, loss: 0.703\n","    Training Set - accuracy: 0.40, precision: 0.45, recall: 0.50, f1-score: 0.29,\n","    Validation Set - accuracy: 0.68, precision: 0.83, recall: 0.54, f1-score: 0.47,\n","(Epoch 4), time: 6.0s, loss: 0.701\n","    Training Set - accuracy: 0.37, precision: 0.34, recall: 0.45, f1-score: 0.30,\n","    Validation Set - accuracy: 0.70, precision: 0.84, recall: 0.57, f1-score: 0.53,\n","(Epoch 5), time: 6.0s, loss: 0.692\n","    Training Set - accuracy: 0.49, precision: 0.65, recall: 0.57, f1-score: 0.45,\n","    Validation Set - accuracy: 0.62, precision: 0.49, recall: 0.50, f1-score: 0.44,\n","(Epoch 6), time: 6.0s, loss: 0.678\n","    Training Set - accuracy: 0.62, precision: 0.67, recall: 0.66, f1-score: 0.62,\n","    Validation Set - accuracy: 0.65, precision: 0.60, recall: 0.58, f1-score: 0.58,\n","(Epoch 7), time: 6.0s, loss: 0.676\n","    Training Set - accuracy: 0.61, precision: 0.59, recall: 0.58, f1-score: 0.58,\n","    Validation Set - accuracy: 0.55, precision: 0.49, recall: 0.49, f1-score: 0.49,\n","(Epoch 8), time: 6.0s, loss: 0.655\n","    Training Set - accuracy: 0.68, precision: 0.67, recall: 0.67, f1-score: 0.67,\n","    Validation Set - accuracy: 0.62, precision: 0.56, recall: 0.55, f1-score: 0.54,\n","(Epoch 9), time: 6.0s, loss: 0.643\n","    Training Set - accuracy: 0.71, precision: 0.69, recall: 0.68, f1-score: 0.69,\n","    Validation Set - accuracy: 0.62, precision: 0.58, recall: 0.58, f1-score: 0.58,\n","(Epoch 10), time: 6.0s, loss: 0.635\n","    Training Set - accuracy: 0.71, precision: 0.69, recall: 0.69, f1-score: 0.69,\n","    Validation Set - accuracy: 0.68, precision: 0.66, recall: 0.67, f1-score: 0.66,\n","(Epoch 11), time: 6.0s, loss: 0.611\n","    Training Set - accuracy: 0.71, precision: 0.69, recall: 0.69, f1-score: 0.69,\n","    Validation Set - accuracy: 0.72, precision: 0.70, recall: 0.69, f1-score: 0.69,\n","(Epoch 12), time: 6.0s, loss: 0.596\n","    Training Set - accuracy: 0.74, precision: 0.73, recall: 0.74, f1-score: 0.73,\n","    Validation Set - accuracy: 0.72, precision: 0.70, recall: 0.67, f1-score: 0.68,\n","(Epoch 13), time: 6.0s, loss: 0.568\n","    Training Set - accuracy: 0.76, precision: 0.75, recall: 0.76, f1-score: 0.75,\n","    Validation Set - accuracy: 0.70, precision: 0.67, recall: 0.64, f1-score: 0.64,\n","(Epoch 14), time: 6.0s, loss: 0.553\n","    Training Set - accuracy: 0.78, precision: 0.77, recall: 0.77, f1-score: 0.77,\n","    Validation Set - accuracy: 0.65, precision: 0.61, recall: 0.60, f1-score: 0.60,\n","(Epoch 15), time: 6.0s, loss: 0.527\n","    Training Set - accuracy: 0.84, precision: 0.84, recall: 0.85, f1-score: 0.84,\n","    Validation Set - accuracy: 0.57, precision: 0.55, recall: 0.56, f1-score: 0.55,\n","(Epoch 16), time: 6.0s, loss: 0.510\n","    Training Set - accuracy: 0.84, precision: 0.84, recall: 0.85, f1-score: 0.84,\n","    Validation Set - accuracy: 0.55, precision: 0.51, recall: 0.51, f1-score: 0.51,\n","(Epoch 17), time: 6.0s, loss: 0.472\n","    Training Set - accuracy: 0.86, precision: 0.85, recall: 0.87, f1-score: 0.85,\n","Confusion Matrix:\n","[[ 9  5]\n"," [ 9 17]]\n","    Validation Set - accuracy: 0.65, precision: 0.64, recall: 0.65, f1-score: 0.64,\n"]}],"source":["from dataset import YouTubeDataset\n","splits = [10]\n","num_classes = len(splits)+1\n","dataset = YouTubeDataset(splits)\n","model = RobertaClassifier(num_classes)\n","\n","hist = train_model_cv5(model, dataset)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"roberta_simple.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('misinfoengage')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"54d3b53da97a4d5230a2d6a56d4dc057ea257b55156c1302576dbafca9234f1a"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0336d3e29a50406483ffb92365b60fb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac6a517f1f14abd8f526c1554d26175","placeholder":"","style":"IPY_MODEL_d97a8b732489475fbb6efa5382fc4bf8","value":" 501M/501M [00:12&lt;00:00, 57.4MB/s]"}},"05a8ce378d33400396944a18ca453dfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05eda02912f54e24b4a2eccb1f5d1985":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d0a5b569f5543a3aad0885b7ffc23b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13887f55b442474ea6971d5733ae99bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a99603efc14990b44f0cef9784ac97","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7524bcc23b384abea0b4158780bba922","value":481}},"17a82e25a1874537a0db547e27c02ac5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b9bbc1c1a8245c4b38a8fbb3d586d49","placeholder":"","style":"IPY_MODEL_27b7a726ff094e84a6041b8edb2fcfb3","value":"Downloading: 100%"}},"1883ab1778ec46e9abdf8c016d88f9a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e81e61c715946f6ac3e7596ba44e55a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24614414bec54f4a9e16da0b4a76e332":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25c514de3b6b4d51ae400df8df391f06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_476d46c1da2647c3873d89a19ca9a717","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df0175e9af754a6780b2c7a68940c893","value":1355863}},"27b7a726ff094e84a6041b8edb2fcfb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b9bbc1c1a8245c4b38a8fbb3d586d49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d27cdc2976746699dc635008321c9d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a0050ddc85c42f6b6f1e3cb545f97bf","IPY_MODEL_3efb47bc5f874b6593343d0a656f7363","IPY_MODEL_0336d3e29a50406483ffb92365b60fb2"],"layout":"IPY_MODEL_0d0a5b569f5543a3aad0885b7ffc23b6"}},"2fc52cf92ebc4924b2904a5d227263cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9d34d9823f646fc9e4c853d13b6787e","placeholder":"","style":"IPY_MODEL_fbc68c3c07e64c169094d6550045da5c","value":" 456k/456k [00:00&lt;00:00, 622kB/s]"}},"3375bb1641e540598ccafb19a0a6c6f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33b1d8be2ace4bc1a9415d67614c19e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"355f43e3996849189748e707897ba985":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3efb47bc5f874b6593343d0a656f7363":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ab7f2eb1b8847ca9c73bd212e448496","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3375bb1641e540598ccafb19a0a6c6f5","value":501200538}},"3f649d86e6954b8abc7cd84417a8cfed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"476d46c1da2647c3873d89a19ca9a717":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e377b69b4344192bdbe40a3813d9659":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e920714c7b204178aeed15281b1180e4","placeholder":"","style":"IPY_MODEL_b5a86cc7ac68460b908b82e1445a1365","value":" 899k/899k [00:00&lt;00:00, 2.15MB/s]"}},"50e8236d9524479e91d020302a2e157c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05eda02912f54e24b4a2eccb1f5d1985","placeholder":"","style":"IPY_MODEL_f510a7cee8f44d67b51baf234d583186","value":" 1.36M/1.36M [00:00&lt;00:00, 1.46MB/s]"}},"51b8300f519d425189c627f766943b78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ac6a517f1f14abd8f526c1554d26175":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d13558b56ff4f01b16bc047d978f499":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e81e61c715946f6ac3e7596ba44e55a","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f649d86e6954b8abc7cd84417a8cfed","value":456318}},"69cdef023ca54eba8ba67a31781f7a10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7524bcc23b384abea0b4158780bba922":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a0050ddc85c42f6b6f1e3cb545f97bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69cdef023ca54eba8ba67a31781f7a10","placeholder":"","style":"IPY_MODEL_05a8ce378d33400396944a18ca453dfc","value":"Downloading: 100%"}},"7cf8b510edc04528a9ac37b4d3f81a95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f86de4c995e4674abdaf9804a86a125":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ab7f2eb1b8847ca9c73bd212e448496":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ad6a4d9d0f4853887f92ed645350ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a379cefbaa9e4582a5e21cdbca56e069":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afbc33ba959343b195e0723e3c25d517":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0ad6a4d9d0f4853887f92ed645350ad","placeholder":"","style":"IPY_MODEL_1883ab1778ec46e9abdf8c016d88f9a1","value":"Downloading: 100%"}},"b180502ed69d4e31978149c2b2206680":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5a86cc7ac68460b908b82e1445a1365":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c166ba293937447ba93630d8e6ce4251":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afbc33ba959343b195e0723e3c25d517","IPY_MODEL_25c514de3b6b4d51ae400df8df391f06","IPY_MODEL_50e8236d9524479e91d020302a2e157c"],"layout":"IPY_MODEL_7f86de4c995e4674abdaf9804a86a125"}},"cadd20b50c264e9fb5f8f916aea88dc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd66edbd6d7c44969ebc631c2fe4075c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d29370d62ac44f78a6e2cc0c5307636a","IPY_MODEL_d8bde791f64642d78f93ba76192cc640","IPY_MODEL_4e377b69b4344192bdbe40a3813d9659"],"layout":"IPY_MODEL_b180502ed69d4e31978149c2b2206680"}},"ce4cc25400bd41358ad23d6f7b02ed0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff2b5b2e574e49d78d2ef90430128e88","IPY_MODEL_13887f55b442474ea6971d5733ae99bc","IPY_MODEL_da8b5156c6f247829d3d96923b852b4e"],"layout":"IPY_MODEL_33b1d8be2ace4bc1a9415d67614c19e7"}},"d29370d62ac44f78a6e2cc0c5307636a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a379cefbaa9e4582a5e21cdbca56e069","placeholder":"","style":"IPY_MODEL_cadd20b50c264e9fb5f8f916aea88dc9","value":"Downloading: 100%"}},"d8bde791f64642d78f93ba76192cc640":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede1f07546fb4ac9ac31db1404713a56","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cf8b510edc04528a9ac37b4d3f81a95","value":898823}},"d97a8b732489475fbb6efa5382fc4bf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da8b5156c6f247829d3d96923b852b4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f55d57435049b9ac2b3016a5dde46b","placeholder":"","style":"IPY_MODEL_355f43e3996849189748e707897ba985","value":" 481/481 [00:00&lt;00:00, 14.6kB/s]"}},"dce48ab6b0a64446a16e4eff5fe8b5fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17a82e25a1874537a0db547e27c02ac5","IPY_MODEL_5d13558b56ff4f01b16bc047d978f499","IPY_MODEL_2fc52cf92ebc4924b2904a5d227263cb"],"layout":"IPY_MODEL_51b8300f519d425189c627f766943b78"}},"df0175e9af754a6780b2c7a68940c893":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1a99603efc14990b44f0cef9784ac97":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e378819f52434b8caf3345a8101ba426":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e920714c7b204178aeed15281b1180e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d34d9823f646fc9e4c853d13b6787e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ede1f07546fb4ac9ac31db1404713a56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f510a7cee8f44d67b51baf234d583186":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8f55d57435049b9ac2b3016a5dde46b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc68c3c07e64c169094d6550045da5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff2b5b2e574e49d78d2ef90430128e88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24614414bec54f4a9e16da0b4a76e332","placeholder":"","style":"IPY_MODEL_e378819f52434b8caf3345a8101ba426","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
